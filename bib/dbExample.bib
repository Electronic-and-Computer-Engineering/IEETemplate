@phdthesis{mythesis,
author = {Mowlaee, P.},
title = {New Stategies for Single-channel Speech Separation},
school = {Institut for Elektroniske Systemer, Aalborg Universitet},
year = {2010},
}

@ARTICLE{WilliamsonJASA2014, 
author={Williamson, D.~S. and Wang, Y. and Wang, D.}, 
journal={Journal of Acoustic Society of America}, 
title={Reconstruction techniques for improving the perceptual quality of binary masked speech}, 
volume={136}, 
number={2}, 
year={2014}, 
pages={892-902}, 
}

@InProceedings{Erdogan2015ICASSP04,
  author =	 {Erdogan, H. and Hershey, J.~R. and Watanabe, S. and {Le Roux}, J.},
  title =	 {Phase-sensitive and recognition-boosted speech separation using deep recurrent neural networks},
  booktitle =	 {Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
  year =	 2015,
  month =	 Apr.,
}

@INPROCEEDINGS{Wang05onideal,
    author = {Deliang Wang},
    title = {On ideal binary mask as the computational goal of auditory scene analysis},
    booktitle = {in Speech Separation by Humans and Machines},
    year = {2005},
    pages = {181--197},
    publisher = {Kluwer}
}

@ARTICLE{KaranMPE2013, 
author={Nathwani, K. and Pandit, P. and Hegde, R.M.}, 
journal={IEEE Transactions on Multimedia}, 
title={Group Delay Based Methods for Speaker Segregation and its Application in Multimedia Information Retrieval}, 
year={2013}, 
month={Oct}, 
volume={15}, 
number={6}, 
pages={1326-1339}, 
}

@ARTICLE{Vincent2006,
author={Vincent, E. and Gribonval, R. and Fevotte, C.},
journal={IEEE Trans. on Audio, Speech, and Language Processing},
title={Performance measurement in blind audio source separation},
year={2006},
month={July},
volume={14},
number={4},
pages={1462 -1469},
}

@ARTICLE{Harris1978, 
author={Harris, F.J.}, 
journal={Proceedings of the IEEE}, 
title={On the use of windows for harmonic analysis with the discrete Fourier transform}, 
year={1978}, 
month={Jan}, 
volume={66}, 
number={1}, 
pages={51-83}, 
}

 @ARTICLE {DegottexG2014jhmpd,
    author = {Degottex, G. and Erro, D.},
    TITLE = { A uniform phase representation for the harmonic model in speech synthesis applications },
    JOURNAL = { EURASIP, Journal on Audio, Speech, and Music Processing - Special Issue: Models of Speech - In Search of Better Representations },
    year = { 2014 },
}

@INPROCEEDINGS{ICASSP2012, 
author={Mowlaee, P. and Saeidi, R. and Christensen, M. G. and Martin, R.}, 
booktitle={Proc.\ IEEE Int.\ Conf.\ Acoust., Speech, Signal Processing},
title={Subjective and Objective Quality Assessment of Single-channel Speech Separation Algorithms}, 
year={2012}, 
month={March}, 
pages={69-72}, 
}

@inproceedings{weningerhal01163493,
  TITLE = {{Speech enhancement with LSTM recurrent neural networks and its application to noise-robust ASR}},
  author = {Weninger, F. and Erdogan, H. and Watanabe, S. and Vincent, E. and Le Roux, J. and Hershey, J.~R. and Schuller, B.},
  BOOKTITLE = {{12th International Conference on Latent Variable Analysis and Signal Separation (LVA/ICA)}},
  ADDRESS = {Liberec, Czech Republic},
  year = {2015},
  MONTH = Aug,
}

@INPROCEEDINGS{SCSSIS2015,
	author = "Mayer, F. and Mowlaee, P.", 
	title = "Improved Phase Reconstruction in Single-Channel Speech Separation",
	booktitle = {15th Annual Conference of the International Speech Communication Association {(INTERSPEECH)}, Dresden, Germany},
	year = "2015",
	pages = "",
}
@INPROCEEDINGS{WangQuality, 
author={Williamson, D.~S. and Wang, Y. and Wang, D.}, 
booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
title={A two-stage approach for improving the perceptual quality of separated speech}, 
year={2014}, 
month={May}, 
pages={7034-7038}, 
}
@INPROCEEDINGS{Boldt2010, 
author={Boldt, J.~B. and Pedersen, M.~S. and Kjems, U. and Christensen, M.~G. and Jensen, S.~H.}, 
booktitle={IEEE International Conference on Acoustics Speech and Signal Processing (ICASSP)}, 
title={Error-correction of binary masks using hidden Markov models}, 
year={2010}, 
month={March}, 
pages={4722-4725}, 
}

@article{wang2005ideal,
  title={On ideal binary mask as the computational goal of auditory scene analysis},
  author={Wang, D.L.},
  journal={Speech separation by humans and machines},
  pages={181--197},
  year={2005},
  publisher={Springer}
}

@book{WangCASA2006,
 author = {Wang, D. and Brown, G. J.},
 title = {Computational Auditory Scene Analysis: Principles, Algorithms, and Applications},
 year = {2006},
 publisher = {Wiley-IEEE Press},
} 
@ARTICLE{Wohlmayr2011, 
author={Wohlmayr, M. and Stark, M. and Pernkopf, F.}, 
journal={IEEE Transactions on Audio, Speech, and Language Processing,}, 
title={A Probabilistic Interaction Model for Multipitch Tracking With Factorial Hidden {Markov} Models}, 
year={2011}, 
month={May}, 
volume={19}, 
number={4}, 
pages={799-810}, 
}
@ARTICLE{Wang2014MPE, 
author={Han, K. and Wang, D.}, 
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
title={Neural Network Based Pitch Tracking in Very Noisy Speech}, 
year={2014}, 
month={Dec}, 
volume={22}, 
number={12}, 
pages={2158-2168}, 
}
@article {pep_SpecialIssue,
	title = {Special Issue on Phase-Aware Signal Processing in Speech Communication},
	journal = {European Association for Signal Processing (EURASIP)},
	volume = {},
	number = {},
	year = {2016},
	month = {Jan.},
	pages = {},
	attachments = {http://www.journals.elsevier.com/speech-communication/call-for-papers/special-issue-on-phase-aware-signal-processing-in-speech-co/},
	author = {Mowlaee, P. and Saeidi, R. and Stylianou, Y.}
}

@ARTICLE{GerkmannMagazine, 
author={Gerkmann, T. and Krawczyk-Becker, M. and Le Roux, J.}, 
journal={IEEE Signal Processing Magazine}, 
title={Phase Processing for Single-Channel Speech Enhancement: History and recent advances}, 
year={2015}, 
month={March}, 
volume={32}, 
number={2}, 
pages={55-66},
}

@ARTICLE{MowlaaeTASL2015SNR, 
author={Mowlaee, P. and Kulmer, J.}, 
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
title={Harmonic Phase Estimation in Single-Channel Speech Enhancement Using Phase Decomposition and SNR Information}, 
year={2015}, 
month={Sept}, 
volume={23}, 
number={9}, 
pages={1521-1532}, 
}
@inproceedings{MLSP2014,
	author = {Kulmer, J. and Mowlaee, P. and Watanabe, M.},
	booktitle = {IEEE Workshop on Machine Learning for Signal Processing},
	title = {A Probabilistic Approach For Phase Estimation in Single-Channel Speech Enhancement Using Von Mises Phase Priors},
	year = {2014},
	month = {Sept.},
	pages = {},
}
@ARTICLE{PejmanJosefSPL2014, 
	author = {Kulmer, J. and Mowlaee, P.},
	journal = {IEEE Signal Processing Letters},
 	title = {Phase Estimation in Single Channel Speech Enhancement Using Phase Decomposition},
	volume = {22},
	number = {5},
	year = {2015},
	month = {May.},
	pages = {598-602},
}

@INPROCEEDINGS{IntelligibilityIS2015,
	author = "Gaich, A. and Mowlaee, P.", 
	title = "On Speech Intelligibility Estimation of Phase-Aware Single-Channel Speech Enhancement",
	booktitle = {15th Annual Conference of the International Speech Communication Association {(INTERSPEECH)}, Dresden, Germany},
	year = "2015",
	pages = "",
}
@INPROCEEDINGS{Qualityicassp2015,
	author = "Gaich, A. and Mowlaee, P.", 
	title = "On Speech Quality Estimation of Phase-Aware Single-Channel Speech Enhancement",
	booktitle = "in Proc. ICASSP, Brisbane, Australia, April",
	year = "2015",
	pages = "216-220",
}
@INPROCEEDINGS{SCSSIS2015,
	author = "Mayer, A. and Mowlaee, P.", 
	title = "Improved Phase Reconstruction in Single-Channel Speech Separation",
	booktitle = {15th Annual Conference of the International Speech Communication Association {(INTERSPEECH)}, Dresden, Germany},
	year = "2015",
	pages = "",
}

 @INPROCEEDINGS{MAPicassp2015,
	author = "Kulmer, J. and Mowlaee, P.", 
	title = "Harmonic Phase Estimation in Single-Channel Speech Enhancement Using Von Mises Distribution and Prior SNR",
	booktitle = "in Proc. ICASSP, Brisbane, Australia, April",
	year = "2015",
	pages = "5063--5067",
}

@ARTICLE{MowlaaeTASL2015, 
author={Mowlaee, P. and Kulmer, J.}, 
journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
title={Phase Estimation in Single-Channel Speech Enhancement: Limits-Potential}, 
year={2015}, 
month={August}, 
volume={23}, 
number={8}, 
pages={1283-1294}, 
}


@phdthesis{Luipinithesis,
	address = "Canada",
	author = "Luipini, P.",
	school = "Simon Fraser Univerity",
	title = "{Harmonic Coding of Speech at Low Bit Rates}",
	year = 1985,
}
@ARTICLE{Oppenheim1981, 
author={Oppenheim, A. V. and Lim, J. S.}, 
journal={Proceedings of the IEEE}, 
title={The importance of phase in signals}, 
year={1981}, 
month={May}, 
volume={69}, 
number={5}, 
pages={ 529 - 541}, 
}
@ARTICLE{Lim1982, 
author={Wang, D. and Lim, J.}, 
journal={IEEE Trans. on Acoustics, Speech and Signal Processing}, 
title={The unimportance of phase in speech enhancement}, 
volume={30}, 
number={4}, 
year={1982}, 
pages={679-681}, 
}
@ARTICLE{Taal2011, 
author={Taal, C. H. and Hendriks, R. C. and Heusdens, R. and Jensen, J.}, 
journal={IEEE Trans. on Audio, Speech, and Language Processing}, 
title={An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech}, 
year={2011}, 
month={}, 
volume={19}, 
number={7}, 
pages={2125-2136}, 
}
@article{Drullman_JASA,
author = {Drullman, R.},
title = {Temporal envelope and fine structure cues for speech intelligibility},
year = {2013},
journal = {The Journal of the Acoustical Society of America},
volume = {97},
number = {1},
pages = {585-592},
}
@ARTICLE{Gunawan2010, 
author={Gunawan, D. and Sen, D.}, 
journal={IEEE signal processing letters}, 
title={Iterative Phase Estimation for the Synthesis of Separated Sources From Single-Channel Mixtures}, 
year={2010}, 
month={May}, 
volume={17}, 
number={5}, 
pages={421 -424}, 
}
@article{MagronTechnicalReport,
    author = {Magron, P. and Badeau, R. and David, B.},
    journal = {Telecom ParisTech, Paris, France},
    title = {Phase reconstruction of spectrograms with linear unwrapping: application to audio signal restoration, 2015},
    year = {2015}
}

@INPROCEEDINGS{MorganICASSP2015, 
author={Magron, P. and Badeau, B. and David, B.}, 
booktitle={International Conference on Acoustics Speech, Signal Processing (ICASSP)},
title={Phase recovery in \textsc{NMF} for audio source separation: an insightful benchmark}, 
year={2015}, 
pages={81-85}, 
}
@inproceedings{BraunschweilerN2011sentselect,
	author = "Braunschweiler, N. and Buchholz, S.",
	booktitle = "{Proc. Interspeech}",
	crossref = "DBLP:conf/interspeech/2011",
	pages = "1821--1824",
	title = "{Automatic Sentence Selection from Speech Corpora Including Diverse Speech for Improved HMM-TTS Synthesis Quality}",
	year = "2011"
}
@BOOK{GershoGrayVectorQuantization,
  title = {Vector quantization and signal compression},
  publisher = {Kluwer Academic Publishers},
  year = {1991},
  author = {Gersho, A. and Gray, R. M.},
  address = {Norwell, MA, USA},
}
@ARTICLE{PejmanRahimSPL2013, 
	author = {Mowlaee, P. and Saeidi, R.},
	journal = {IEEE Signal Processing Letters},
 	title = {Iterative Closed-Loop Phase-Aware Single-Channel Speech Enhancement},
	volume = {20},
	number = {12},
	year = {2013},
	month = {Dec.},
	pages = {1235-1239},
}

@ARTICLE{Loizou2008, 
author={Hu, Y. and Loizou, P. C.}, 
journal={IEEE Trans. on Audio, Speech, and Language Processing}, 
title={Evaluation of Objective Quality Measures for Speech Enhancement}, 
year={2008}, 
volume={16}, 
number={1}, 
pages={229-238}, 
}

@article{christensen_JASA,
author = {Christensen, M. G.},
title = {Metrics for vector quantization-based parametric speech enhancement and separation},
publisher = {ASA},
year = {2013},
journal = {The Journal of the Acoustical Society of America},
volume = {133},
number = {5},
pages = {3062-3071},
}

@inproceedings{MaiaR2011multiseq,
	author = "Maia, R. and Zen, Heiga and Knill, K. and Gales, M. J. F. and Buchholz, S.",
	booktitle = "{Proc. Interspeech}",
	pages = "1833--1836",
	title = "{Multipulse Sequences for Residual Signal Modeling}",
	year = "2011"
}

@inproceedings{ICASSP2011,
	author = {Christensen, M.G. and Mowlaee, P.},
	booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing },
	title = {A new metric for {VQ}-based speech enhancement and separation},
	year = {2011},
	month = {may},
	pages = {4764 -4767},
}
@ARTICLE{PEFAC, 
author={Gonzalez, S. and Brookes, M.}, 
journal={IEEE/ACM Trans. on Audio, Speech, and Language Processing}, 
title={{PEFAC} - A Pitch Estimation Algorithm Robust to High Levels of Noise}, 
year={2014}, 
month={Feb}, 
volume={22}, 
number={2}, 
pages={518-530}, 
}

@inproceedings{RoebelA2010shapeinvint,
	author = "Roebel, Axel",
	booktitle = "{Proc. Interspeech}",
	lockkey = "Y",
	pages = "2146--2149",
	title = "{Shape-Invariant Speech Transformation with the Phase Vocoder}",
	year = "2010"
}

@inproceedings{ImaiS1983,
	author = "Imai, S.",
	booktitle = "{IEEE International Conference on Acoustics, Speech and Signal Processing }",
	issn = "",
	keywords = "",
	month = "apr",
	number = "",
	pages = "93--96",
	title = "{Cepstral analysis synthesis on the mel frequency scale}",
	volume = "8",
	year = "1983"
}

@inproceedings{Degottex2010e,
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	booktitle = "{Journ{\'e}es Jeunes Chercheurs en Audition, Acoustique musicale et Signal audio (JJCAAS)}",
	file = "http://recherche.ircam.fr/equipes/analyse-synthese/degottex/uploads/Main/Degottex2009e.pdf",
	lockkey = "Y",
	pdf = "Degottex2009e.pdf",
	title = "{Transformation de la voix {\`a} l'aide d'un mod{\`e}le de source glottique}",
	year = 2010
}

@article{Degottex2010dshort,
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	doi = "10.1109/TASL.2010.2076806",
	issn = "1558-7916",
	journal = "IEEE ASLP",
	lockkey = "Y",
	number = "5",
	pages = "1080--1090",
	title = "{Phase minimization for glottal model estimation}",
	volume = "19",
	year = "2011"
}

@inproceedings{LanchantinP2010svlnhmm,
	address = "Dallas, USA",
	author = "Lanchantin, P. and Degottex, G. and Rodet, X.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	keywords = "HMM-based speech synthesis; Liljencrants-Fant model",
	lockkey = "Y",
	pages = "4630--4633",
	title = "{A {HMM}-based speech synthesis system using a new glottal source and vocal-tract separation method}",
	year = 2010
}

@inproceedings{Degottex2009c,
	author = "Degottex, G. and Rodet, X.",
	booktitle = "{Summer school: Sciences et voix approche pluri-disciplinaire de la voix chant{\'e}e, EESVC}",
	lockkey = "Y",
	title = "{Evolution de param{\`e}tres de mod{\`e}le glottique et comparaisons avec signaux physiologiques}",
	year = 2009
}

@inproceedings{ZharkikhA2009b,
	author = "Zharkikh, A. A.",
	booktitle = "{in Russian}",
	comment = "13th International Conference on Speech and Computer,",
	conf = "13th International Conference on Speech and Computer",
	file = "http://recherche.ircam.fr/equipes/analyse-synthese/degottex/uploads/Main/Degottex2009a.pdf",
	lockkey = "Y",
	pdf = "Degottex2009a.pdf",
	title = "{Comparison of Representation Accuracy of Different Orders Gaussian Wavelets}",
	year = 2009
}

@inproceedings{Degottex2009b,
	
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	booktitle = "{Proc. Conference on Speech and Computer (SPECOM)}",
	fieldname = "13th International Conference on Speech and Computer",
	file = "http://recherche.ircam.fr/equipes/analyse-synthese/degottex/uploads/Main/Degottex2009b.pdf",
	lockkey = "Y",
	pages = "226--231",
	pdf = "Degottex2009b.pdf",
	title = "{Glottal Closure Instant detection from a glottal shape estimate}",
	year = 2009
}

@inproceedings{Degottex2010a,
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	keywords = "glottal source; joint estimate; phase Ã¯Â¬Âatness; phase minimization",
	lockkey = "Y",
	pages = "5058--5061",
	pdf = "Degottex2010a.pdf",
	title = "{Joint estimate of shape and time-synchronization of a glottal source model by phase flatness}",
	year = 2010
}

@misc{Degottex2008b,
	author = "Degottex, G. and Bianco, E. and Rodet, X.",
	howpublished = "SÃ¯Â¿Åminaire Recherche-Technologie, IRCAM",
	lockkey = "Y",
	month = "April",
	title = "{Mesure de la source glottique par VidÃ¯Â¿Åoendoscopie {\`a} haute vitesse}",
	year = 2008
}

@inproceedings{Bianco2008,
	address = "Paris, France",
	author = "Bianco, E. and Degottex, G. and Rodet, X.",
	booktitle = "{Congr{\`e}s de la soci{\'e}t{\'e} fran\c{c}aise de phoniatrie}",
	lockkey = "Y",
	month = "Oct.",
	title = "{M{\'e}canismes vibratoires ou registres ?}",
	year = 2008
}

@inproceedings{Degottex2008a,
	
	author = "Degottex, G. and Bianco, E. and Rodet, X.",
	booktitle = "{Proc. International Conference on Voice Physiology and Biomechanics (ICVPB)}",
	file = "http://recherche.ircam.fr/equipes/analyse-synthese/degottex/uploads/Main/Degottex2008a.pdf",
	lockkey = "Y",
	owner = "degottex",
	pages = "19--26",
	pdf = "Degottex2008a.pdf",
	timestamp = "2008.05.18",
	title = "{Usual to particular phonatory situations studied with high-speed videoendoscopy}",
	year = 2008
}

@inproceedings{Degottex2008,
	
	address = "Laboratoire de Phon{\'e}tique et Phonologie (LPP), Paris, France",
	author = "Degottex, G. and Bianco, E. and Rodet, X.",
	booktitle = "{Proc. Speech Production Workshop: Instrumentation-based approach}",
	lockkey = "Y",
	organization = "ParisIII/ILPGA",
	owner = "degottex",
	timestamp = "2008.01.07",
	title = "{Estimation of glottal area with high-speed videoendoscopy}",
	year = 2008
}

@inproceedings{Deliyski2006,
	author = "Deliyski, D.",
	booktitle = "{Proc. Advances in Quantitative Laryngology (AQL)}",
	journal = "AQL",
	lockkey = "Y",
	owner = "degottex",
	pages = "1--16 vol. 7",
	title = "{High-Speed Videoendoscopy: Recent Progress and Clinical Prospects}",
	year = "2006"
}

@article{Veldhuis1998,
	
	author = "Veldhuis, R.",
	doi = "10.1121/1.421103",
	journal = "Journal of the Acoustical Society of America",
	keywords = "speech; physiological models",
	lockkey = "Y",
	number = "1",
	pages = "566--571",
	publisher = "ASA",
	title = "{A computationally efficient alternative for the Liljencrants--Fant model and its perceptual evaluation}",
	url = "http://link.aip.org/link/?JAS/103/566/1",
	volume = "103",
	year = "1998"
}

@article{MaedaS1982,
	author = "Maeda, S.",
	journal = "Speech Communication",
	keywords = "simulation vocal tract glottal excitation speech synthesis",
	lockkey = "Y",
	number = "3-4",
	owner = "degottex",
	pages = "199--229",
	timestamp = "2008.05.14",
	title = "{A digital simulation method of the vocal-tract system}",
	volume = "1",
	year = 1982
}

@article{Alessandro_Doval_ESCA_1997,
	author = "d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Doval, B.",
	journal = "ESCA",
	keywords = "Spectral representation modelling of glottal flow signals",
	lockkey = "N",
	owner = "degottex",
	pdf = "Alessandro\_Doval\_ESCA\_1997\_glottal flow.pdf",
	timestamp = "2007.07.05",
	title = "{Spectral representation and modelling of glottal flow signals}",
	year = "1997"
}

@article{Thomas_Yegnanarayana_Karinthi_Venkateswar_ICASSP_1985,
	author = "A.Thomas, Joy and B.Yegnanarayana and Karinthi, Raghuram and V.Venkateswar",
	journal = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	keywords = "group delay; noise; speech",
	lockkey = "N",
	owner = "degottex",
	pages = "720--723",
	timestamp = "2007.03.06",
	title = "{Processing of noisy speech using group delay functions}",
	volume = "2",
	year = "1985"
}

@article{Abe_Smith_AES_2004,
	
	author = "Abe, Mototsugu and Smith, Julius O.",
	journal = "AES",
	keywords = "Sinusoidal Parameter Quadratic Interpolation FFT Magnitude Peaks Refinement relocation",
	lockkey = "N",
	owner = "norwin",
	pdf = "Abe\_Smith\_AES\_2004\_abe-aes04.pdf",
	timestamp = "2007.07.06",
	title = "{Design Criteria for Simple Sinusoidal Parameter Estimation based on Quadratic Interpolation of FFT Magnitude Peaks}",
	year = "2004"
}

@techreport{Abe_Smith_Inter1_2004,
	
	author = "Abe, Mototsugu and Smith, Julius O.",
	institution = "CCRMA",
	keywords = "Quadratically Interpolated FFT Bias refinement relocation",
	lockkey = "N",
	owner = "norwin",
	pdf = "Abe\_Smith\_Inter1\_2004\_abe-m114.pdf",
	timestamp = "2007.07.06",
	title = "{Design Criteria for the Quadratically Interpolated FFT Method (I): Bias due to Interpolation}",
	year = "2004"
}

@techreport{Abe_Smith_Inter2_2004,
	
	author = "Abe, Mototsugu and Smith, Julius O.",
	institution = "CCRMA",
	keywords = "Quadratically Interpolated FFT Bias Interfering Components refinement relocation",
	lockkey = "N",
	owner = "norwin",
	pdf = "Abe\_Smith\_Inter2\_2004\_abe-m115.pdf",
	timestamp = "2007.07.06",
	title = "{Design Criteria for the Quadratically Interpolated FFT Method (II): Bias due to Interfering Components}",
	year = "2004"
}

@techreport{Abe_Smith_Inter3_2004,
	
	author = "Abe, Mototsugu and Smith, Julius O.",
	institution = "CCRMA",
	keywords = "Quadratically Interpolated FFT Bias Amplitude Frequency Modulation refinement relocation",
	lockkey = "N",
	owner = "norwin",
	pdf = "Abe\_Smith\_Inter3\_2004\_abe-m116.pdf",
	timestamp = "2007.07.06",
	title = "{Design Criteria for the Quadratically Interpolated FFT Method (III): Bias due to Amplitude and Frequency Modulation}",
	year = "2004"
}

@techreport{Abe_Smith_InterCQIFFT_2004,
	
	author = "Abe, Mototsugu and Smith, Julius O.",
	institution = "CCRMA",
	keywords = "CQIFFT Correcting Bias Sinusoidal Parameter Estimator Quadratic Interpolation FFT Magnitude Peaks",
	lockkey = "N",
	owner = "norwin",
	pdf = "Abe\_Smith\_InterCQIFFT\_2004\_abe-m117.pdf",
	timestamp = "2007.07.06",
	title = "{CQIFFT: Correcting Bias in a Sinusoidal Parameter Estimator based on Quadratic Interpolation of FFT Magnitude Peaks}",
	year = "2004"
}

@article{Almeida_AA_2007,
	author = "Almeida and Vergez and Causse",
	journal = "Acta acustica",
	lockkey = "N",
	owner = "degottex",
	pages = "645--658",
	timestamp = "2007.11.27",
	title = "{Experimental Investigation of Reed Instrument Functioning Through Image Analysis of Reed Opening}",
	volume = "93",
	year = "2007"
}

@misc{Ariza_CMJ_2005,
	
	author = "Ariza, Christopher",
	keywords = "Xenakis Sieve Object Model Implementation",
	lockkey = "N",
	note = "New York University Graduate School of Arts and Science, Music Department 24 Waverly Place, Room 268 New York, New York 10003 USA ariza@Ã¯Â¬Âexatone.net",
	owner = "degottex",
	pdf = "Ariza\_CMJ\_2005\_5138.0.COMJ\_29\_2\_40\_0.pdf",
	timestamp = "2007.07.05",
	title = "{The Xenakis Sieve as Object: A New Model and a Complete Implementation}",
	year = "2005"
}

@article{Arroabarren_Carlosena_EURASIP_2004,
	
	author = "Arroabarren, Ixone and Carlosena, Alfonso",
	journal = "EURASIP",
	keywords = "voice quality; source-Ã¯Â¬Âlter model; inverse Ã¯Â¬Âltering; singing voice; vibrato; sinusoidal model.",
	lockkey = "N",
	owner = "norwin",
	pdf = "Arroabarren\_Carlosena\_EURASIP\_2004\_Vibrato in Singing voice - S1110865704401127-1.pdf",
	timestamp = "2007.07.06",
	title = "{Vibrato in Singing Voice: The Link between Source-Filter and Sinusoidal Models}",
	year = "2004"
}

@article{Arroabarren_Carlosena_JASP_2004,
	
	author = "Arroabarren, Ixone and Carlosena, Alfonso",
	journal = "JASP",
	keywords = "voice quality; source-Ã¯Â¬Âlter model; inverse Ã¯Â¬Âltering; singing voice; vibrato; sinusoidal model.",
	lockkey = "N",
	note = "Departamento de IngenierÃÅœa ElÃÅœctrica y ElectrÃÅœnica, Universidad PÃÅœ blica de Navarra, Campus de Arrosadia, 31006 Pamplona, Spain ÃÂ±e o u Email: ixone.arroabarren@unavarra.es Departamento de IngenierÃÅœa ElÃÅœctrica y ElectrÃÅœnica, Universidad PÃÅœ blica de Navarra, Campus de Arrosadia, 31006 Pamplona, Spain ÃÂ±e o u Email: carlosen@unavarra.es",
	owner = "degottex",
	pdf = "Arroabarren\_Carlosena\_JASP\_2004\_S1110865704401127-1.pdf",
	timestamp = "2007.07.05",
	title = "{Vibrato in Singing Voice: The Link between Source-Filter and Sinusoidal Models}",
	year = "2004"
}

@article{Avanzini_Drioli_Alku_ISMA_2001,
	abstract = "A physically-informed glottal model is proposed; some physical information is retained in a linear block that accounts for fold mechanics, while non-linear coupling with the airÃ¯Â¬Âow is modeled using a regressor- based mapping. The model is used in an identiÃ¯Â¬Âcation/resynthesis scheme. Given a real signal, system parameters are estimated via non-linear identiÃ¯Â¬Âcation techniques; then the model is used for resynthesizing the signal. With a proper choice of the regressor set the system accurately Ã¯Â¬Âts the target waveform and is stable during resynthesis. Physical parameters can be used to change voice quality and speaker identity.",
	author = "Avanzini, Federico and Drioli, Carlo and Alku, Paavo",
	journal = "ISMA",
	keywords = "SYNTHESIS VOICE SOURCE PHYSICALLY INFORMED MODEL GLOTTIS",
	lockkey = "N",
	owner = "norwin",
	pdf = "Avanzini\_Drioli\_Alku\_ISMA\_2001\_isma01voice.pdf",
	timestamp = "2007.07.06",
	title = "{SYNTHESIS OF THE VOICE SOURCE USING A PHYSICALLY-INFORMED MODEL OF THE GLOTTIS}",
	year = "2001"
}

@misc{Badeau2_ATIAM_2005,
	author = "Badeau, Roland",
	comment = "slides",
	lockkey = "N",
	month = "february",
	note = "slides",
	owner = "degottex",
	pdf = "Badeau2\_ATIAM\_2005\_Atiam-Transp-slides.pdf",
	timestamp = "2007.07.05",
	title = "{M{\'e}thodes {\`a} haute r{\'e}solution}",
	year = "2005"
}

@mastersthesis{Badeau_ATIAM_2004,
	author = "Badeau, R.",
	lockkey = "N",
	owner = "degottex",
	pdf = "Badeau\_ATIAM\_2004\_Atiam-Chap.pdf",
	school = "ATIAM",
	timestamp = "2007.07.05",
	title = "{M{\'e}thodes {\`a} haute r{\'e}solution}",
	year = "2004"
}

@article{Bailly_WASKOPF_1995,
	author = "Bailly, G{\'e}rard",
	journal = "WASKOPF",
	keywords = "Characterising formant trajectories tracking vocal tract resonances",
	lockkey = "N",
	owner = "degottex",
	pdf = "Bailly\_WASKOPF\_1995\_BaillyWASKOPF95.pdf",
	timestamp = "2007.07.05",
	title = "{Characterising formant trajectories by tracking vocal tract resonances}",
	year = "1995"
}

@article{BASTIEN_TCHelicon_2001,
	abstract = "Instrumental shifting allows to change the pitch of a sound in real time. It is used in processors such as guitar multi-effects.",
	author = "BASTIEN, Patrick",
	journal = "TC-Helicon",
	keywords = "Pitch shifting voice transformation techniques",
	lockkey = "N",
	note = "TC-Helicon Vocal Technologies, 6710 Bertram Place, Victoria, BC, CANADA V8M 1Z6 Tel. (250) 544-4091 Fax (250) 544-4100 - www.tc-helicon.com",
	owner = "degottex",
	pdf = "BASTIEN\_TCHelicon\_2001\_Pitch\_shifting.pdf",
	timestamp = "2007.07.05",
	title = "{Pitch shifting and voice transformation techniques}",
	year = "2001"
}

@misc{Baudoin_HDR_2000,
	author = "Baudoin, G.",
	lockkey = "N",
	pdf = "Baudoin\_HDR\_2000\_hdr\_baudoin.pdf",
	timestamp = "2007.07.11",
	title = "{CODAGE DE LA PAROLE {\`A} BAS ET TR{\`E}S BAS D{\'E}BIT TRANSFORMATION DE LA VOIX}",
	year = "2000"
}

@book{Flanagan1972,
	author = "Flanagan, J. L.",
	lockkey = "Y",
	publisher = "Springer Verlag",
	timestamp = "2008.05.14",
	title = "{Speech Analysis Synthesis and Perception}",
	year = "1972"
}

@inbook{Evans2000,
  author      = "Evans, M. and Hastings, N. and Peacock, B.",
  title       = "von Mises Distribution",
  chapter = {45},
  publisher = "Wiley \& Sons",  
  address     = "New York",
  year        = 2000,
}

." Ch. 41 in Statistical Distributions, 3rd ed. : Wiley, pp. 189-191, 2000.

@book{Boyd_Vandenberghe_CUP_2006,
	author = "Boyd, Stephen and Vandenberghe, Lieven",
	editor = "Press, Cambridge University",
	keywords = "Convex Optimization",
	lockkey = "N",
	owner = "norwin",
	pdf = "Boyd\_Vandenberghe\_CUP\_2006\_bv\_cvxbook.pdf",
	publisher = "Cambridge University Press",
	timestamp = "2007.07.05",
	title = "{Convex Optimization}",
	year = "2006"
}

@misc{WO2005031702A1,
	author = "Bozkurt and Dutoit",
	keywords = "patent",
	lockkey = "N",
	owner = "norwin",
	pdf = "WO2005031702A1\_patent.pdf",
	timestamp = "2007.07.11",
	title = "{Method for estimating resonance frequencies}",
	year = "2005"
}

@phdthesis{BozkurtB2005a,
	abstract = "This study proposes a new spectral representation called the Zeros of Z-Transform (ZZT), which is an all-zero representation of the z-transform of the signal. In addition, new chirp group delay processing techniques are developed for analysis of resonances of a signal. The combination of the ZZT representation with the chirp group delay processing algorithms provides a useful domain to study resonance characteristics of source and filter components of speech. Using the two representations, effective algorithms are developed for: source-tract decomposition of speech, glottal flow parameter estimation, formant tracking and feature extraction for speech recognition. The ZZT representation is mainly important for theoretical studies. Studying the ZZT of a signal is essential to be able to develop effective chirp group delay processing methods. Therefore, first the ZZT representation of the source-filter model of speech is studied for providing a theoretical background. We confirm through ZZT 
representation that anti-causality of the glottal flow signal introduces mixed-phase characteristics in speech signals. The ZZT of windowed speech signals is also studied since windowing cannot be avoided in practical signal processing algorithms and the effect of windowing on ZZT representation is drastic. We show that separate patterns exist in ZZT representations of windowed speech signals for the glottal flow and the vocal tract contributions. A decomposition method for source-tract separation is developed based on these patterns in ZZT. We define chirp group delay as group delay calculated on a circle other than the unit circle in z-plane. The need to compute group delay on a circle other than the unit circle comes from the fact that group delay spectra are often very noisy and cannot be easily processed for formant tracking purposes (the reasons are explained through ZZT representation). In this thesis, we propose methods to avoid such problems by modifying the ZZT of a signal and further computing the 
chirp group delay spectrum. New algorithms based on processing of the chirp group delay spectrum are developed for formant tracking and feature estimation for speech recognition. The proposed algorithms are compared to state-of-the-art techniques. Equivalent or higher efficiency is obtained for all proposed algorithms. The theoretical parts of the thesis further discuss a mixed-phase model for speech and phase processing problems in detail. Index Terms---spectral representation, source-filter separation, glottal flow estimation, formant tracking, zeros of z-transform, group delay processing, phase processing 7",
	address = "Belgium",
	author = "Bozkurt, Baris",
	keywords = "ZZT chirp group delay speech separation",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Bozkurt\_Mons\_2005\_ZZT and chirp grp delay proc for the analysis of src and filter charact of ss.pdf",
	school = "Facult{\'e} Polytechnique de Mons",
	timestamp = "2007.03.05",
	title = "{Zeros of the z-transform ({ZZT}) representation and chirp group delay processing for the analysis of source and filter characteristics of speech signals}",
	year = 2005
}

@article{DeLiang2014,
   author = "Williamson, D. S. and Wang, Y. and Wang, D.",
   title = "Reconstruction techniques for improving the perceptual quality of binary masked speech",
   journal = "The Journal of the Acoustical Society of America",
   year = "2014",
   volume = "136",
   number = "2", 
   pages = "892-902",
}


@article{Bozkurt_Couvreur_EUSPICO_2005,
	abstract = "This study addresses the use of short-time phase spectra in automatic speech recognition (ASR). Two recent studies [1,2] have proposed two group delay based spectral repres- entations. Here we propose three new group delay based rep- resentations and compare usefulness of all these representa- tions in an ASR experiment. We show that two of the repres- entations we propose perform better, contain equivalent or complementary information to that of the power spectrum and are potentially useful for improving ASR performance.",
	author = "Bozkurt, Baris and Couvreur, Laurent",
	journal = "EUSPICO",
	keywords = "PHASE SPEECH RECOGNITION",
	lockkey = "N",
	owner = "norwin",
	pdf = "Bozkurt\_Couvreur\_EUSPICO\_2005\_eusipco05\_bblc.pdf",
	timestamp = "2007.07.06",
	title = "{ON THE USE OF PHASE INFORMATION FOR SPEECH RECOGNITION}",
	year = "2005"
}

@article{Bozkurt_Doval_Alessandro_Dutoit_EUSPICO_2004,
	abstract = "This study discusses the difficulties of phase spectrum analysis of speech signals and shows that appropriate windowing is very crucial for obtaining reliable phase spectra. The main difficulties of phase based analysis stem from the domination of spiky effects of roots (zeros) of the signal z-transform close to the unit circle. We show how this problem is linked to windowing by discussing zero-patterns for speech signals. Once windowing is performed properly, group delay functions are much less noisy and reveal clearly formant information.",
	author = "Bozkurt, Baris and Doval, Boris and D{\rq}Alessandro, Christophe and Dutoit, Thierry",
	journal = "EUSPICO",
	keywords = "WINDOWING GROUP DELAY ANALYSIS ROOTS Z TRANSFORM OF SPEECH",
	lockkey = "N",
	owner = "degottex",
	pdf = "Bozkurt\_Doval\_Alessandro\_Dutoit\_EUSPICO\_2004\_approptiate win for grp delay analysis and roots of ZT of speech signals.pdf",
	timestamp = "2007.07.11",
	title = "{APPROPRIATE WINDOWING FOR GROUP DELAY ANALYSIS AND ROOTS OF Z TRANSFORM OF SPEECH SIGNALS}",
	year = "2004"
}

@article{Bozkurt2004,
	abstract = "This study proposes a new spectral decomposition method for source-tract separation. It is based on a new spectral representation called the Zeros of Z-Transform (ZZT), which is an all-zero representation of the z-transform of the signal. We show that separate patterns exist in ZZT representations of speech signals for the glottal flow and the vocal tract contributions. The ZZT-decomposition is simply composed of grouping the zeros into two sets, according to their location in the z-plane. This type of decomposition leads to separating glottal flow contribution (without a return phase) from vocal tract contributions in z domain.",
	author = "Bozkurt, B. and Doval, B. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Dutoit, T.",
	journal = "ICSLP",
	lockkey = "N",
	owner = "norwin",
	pdf = "Bozkurt\_Doval\_Alessandro\_Dutoit\_ICSLP\_2004\_a method for Fg freq estim.pdf",
	timestamp = "2007.07.11",
	title = "{Zeros of Z-Transform (ZZT) Decomposition of Speech For Source-Tract Separation}",
	year = "2004"
}

@article{Bozkurt_Doval_Alessandro_Dutoit_ICSLP_2004,
	abstract = "This study presents a method for estimation of glottal formant frequency (Fg) from speech signals. Our method is based on zeros of z-transform decomposition of speech spectra into two spectra : glottal flow dominated spectrum and vocal tract dominated spectrum. Peak picking is performed on the amplitude spectrum of the glottal flow dominated part. The algorithm is tested on synthetic speech. It is shown to be effective especially when glottal formant and first formant of vocal tract are not too close. In addition, tests on a real speech example are also presented where open quotient estimates from EGG signals are used as reference and correlated with the glottal formant frequency estimates.",
	author = "Bozkurt, Baris and Doval, Boris and D{\rq}Alessandro, Christophe and Dutoit, Thierry",
	journal = "ICSLP",
	keywords = "Glottal Formant Frequency Estimation",
	lockkey = "N",
	owner = "degottex",
	pdf = "Bozkurt\_Doval\_Alessandro\_Dutoit\_ICSLP\_2004\_a method for Fg freq estim.pdf",
	timestamp = "2007.07.11",
	title = "{A Method For Glottal Formant Frequency Estimation}",
	year = "2004"
}

@article{Bozkurt2004a,
	abstract = "This study presents an improved version of our previously introduced formant tracking algorithm. The algorithm is based on processing the negative derivative of the argument of the chirp-z transform (termed as the differential phase spectrum) of a given speech signal. No modeling is included in the procedure but only peak picking on differential phase spectrum. We discuss the effects of roots of z-transform to differential phase spectrum and the need to ensure that all zeros are at some distance from the circle where chirp-z transform is computed. For that, we include an additional zero-decomposition step in our previously presented algorithm to improve its robustness. The final version of the algorithm is tested for analysis of synthetic speech and real speech signals and compared to two other formant tracking systems.",
	author = "Bozkurt, Baris and Doval, Boris and D{\rq}Alessandro, Christophe and Dutoit, Thierry",
	journal = "ICSLP",
	lockkey = "Y",
	owner = "norwin",
	pdf = "Bozkurt\_Doval\_ICSLP\_2004\_Improved diff phase spect proc for formant tracking.pdf",
	timestamp = "2007.07.11",
	title = "{Improved Differential Phase Spectrum Processing For Formant Tracking}",
	year = 2004
}

@inproceedings{Bozkurt_Dutoit_VOQUAL_2003,
	abstract = "This paper introduces a new speech model, termed as the mixed-phase model, based on the assumption that the speech signal is produced by convolution of a maximum phase glottal excitation signal with a minimum phase vocal tract filter impulse response. The glottal excitation signal is assumed to be an anti-causal stable signal and the vocal tract filter is assumed to be causal and stable. For estimating resonances of the maximum phase signal (source) and the minimum phase filter (vocal tract filter), use of differential phase spectrums of z-transforms is proposed.",
	author = "Bozkurt, Baris and Dutoit, Thierry",
	booktitle = "{Proc. ISCA Voice Quality: Functions, Analysis and Synthesis (VOQUAL)}",
	lockkey = "N",
	owner = "norwin",
	pdf = "Bozkurt\_Dutoit\_VOQUAL\_2003\_mix-phase speech modeling and formant estim using diff phase spect.pdf",
	timestamp = "2007.07.11",
	title = "{MIXED-PHASE SPEECH MODELING AND FORMANT ESTIMATION, USING DIFFERENTIAL PHASE SPECTRUMS}",
	year = "2003"
}

@article{Bozkurt_Ozturk_Dutoit_EUROSPEECH_2003,
	abstract = "Speech corpora design is one of the key issues in building high quality text to speech synthesis systems. Often read speech is used since it seems to be the easiest way to obtain a recorded speech corpus with highest control of the content. The main topic of this study is designing text for recording read speech corpora for concatenative text to speech systems. We will discuss application of the greedy algorithm for text selection by proposing a new way of implementing it and comparing with the standard implementation. Additionally, a text corpus design for Turkish TTS is presented.",
	author = "Bozkurt, Baris and Ozturk, Ozlem and Dutoit, Thierry",
	journal = "EUROSPEECH",
	lockkey = "N",
	owner = "norwin",
	pdf = "Bozkurt\_Ozturk\_Dutoit\_EUROSPEECH\_2003\_text design.pdf",
	timestamp = "2007.07.11",
	title = "{TEXT DESIGN FOR TTS SPEECH CORPUS BUILDING USING A MODIFIED GREEDY SELECTION}",
	year = "2003"
}

@article{Bozkurt_Severin_Dutoit_Anticausal_2005,
	abstract = "In this paper, we define an algorithm with low complexity which performs a new use of the linear prediction analysis (covariance method) to retrieve the maximum-phase component of speech signals. First, we study the mixed-phase model of speech through a new representation named the Zeros of Z-Transform (ZZT) in the z-plane, which is an all-zero representation of the z- transform of a discrete time signal. Then, based on the properties of the mixed-phase model, we in- troduce an algorithm to estimate the anticausal glottal flow component from speech signals. LP-co- variance analysis is used to estimate a pole pair outside the unit circle corresponding to the anti- causal poles of the source signal component in the mixed-phase speech model. Given the pair of an- ticausal poles, a procedure to resynthesize the anticausal part of the glottal flow, and then an open quotient estimation method, are proposed. Evaluations show that the method is high quality for ana- lyzing synthetic speech but lacks 
robustness in analysis of natural speech.",
	author = "Bozkurt, Baris and Severin, Fran\c{c}ois and Dutoit, Thierry",
	keywords = "Anticausal Glottal Speech",
	lockkey = "N",
	owner = "degottex",
	pdf = "Bozkurt\_Severin\_Dutoit\_Anticausal\_2005\_an algo to estim anticausal glot flow comp from ss - book\_baris.pdf",
	timestamp = "2007.07.11",
	title = "{An Algorithm to Estimate Anticausal Glottal Flow Component from Speech Signals}",
	year = "2005"
}

@article{Bulut_Busso_Yildirim_Kazemzadeh_Lee_Lee_Narayanan_Emotional_2005,
	abstract = "Recent studies in our lab show that emotions in speech are man- ifested as, besides supra-segmental trends, distinct variations in phoneme-level prosodic and spectral parameters. In this pa- per, we further investigate the signiÃ¯Â¬Âcance of this Ã¯Â¬Ânding in the context of emotional speech synthesis. SpeciÃ¯Â¬Âcally, we study phoneme-level signal property manipulation in transforming the emotional information conveyed in a speech utterance. We ana- lyze the effect of individual and combined modiÃ¯Â¬Âcations of F0, duration, energy and spectrum using data recorded by a pro- fessional actress with happy, angry, sad and neutral expressive- ness. We use content matched source-target pairs and apply TD- PSOLA for prosody and LPC for spectrum modiÃ¯Â¬Âcations by di- rectly extracting the required parameters from the target speech. Listening tests conducted with 10 naive raters show that modi- Ã¯Â¬Âcation of prosody and spectral envelope parameters by them- selves is not sufÃ¯Â¬Âcient. However,
 when applied together, modi- fying spectrum and prosody at the phone level gives successful results for most emotion pairs, except conversion to happy tar- gets. We also observe that at the phoneme level, spectral enve- lope modiÃ¯Â¬Âcations are more effective than local prosodic mod- iÃ¯Â¬Âcations; and that, duration modiÃ¯Â¬Âcations are more effective than pitch modiÃ¯Â¬Âcations. The results conÃ¯Â¬Ârm our hypothesis that phoneme level modiÃ¯Â¬Âcations can be used to Ã¯Â¬Âne tune the ensuing suprasegmental-parameter-based modiÃ¯Â¬Âcations to im- prove the overall quality of synthesized emotions.",
	author = "Bulut, Murtaza and Busso, Carlos and Yildirim, Serdar and Kazemzadeh, Abe and Lee, Chul Min and Lee, Sungbok and Narayanan, Shrikanth",
	keywords = "role phoneme level modiÃ¯Â¬Âcation emotional speech resynthesis",
	lockkey = "N",
	note = "Department of Electrical Engineering Viterbi School of Engineering, University of Southern California, Los Angeles, CA, USA Speech Analysis and Interpretation Laboratory, http://sail.usc.edu mbulut@usc.edu",
	owner = "norwin",
	pdf = "Bulut\_Busso\_Yildirim\_Kazemzadeh\_Lee\_Lee\_Narayanan\_Emotional\_2005\_BulutBussoYildirim05.pdf",
	timestamp = "2007.07.06",
	title = "{Investigating the role of phoneme-level modiÃ¯Â¬Âcations in emotional speech resynthesis}",
	year = "2005"
}

@article{Burki_Gendrot_RJC_2007,
	abstract = "The present study examines the performance of an alignment system in the detection of schwas and the estimation of their duration. A comparison is made between the output of the system and a manual segmentation. Detection errors concern 8\% of the data and estimation errors 22\%. Regularities can be observed: the kind of errors and error rate are influenced by the nature of the consonant surrounding the schwa, as well as its acoustic properties. Usefulness of such information for enhancing system performances and pertinence of designing systems for particular linguistic needs are discussed in the light of these results. Implications of error rates for the use of such technologies for linguistic analysis are also mentioned.",
	author = "B{\"u}rki, Audrey and Gendrot, C{\'e}dric",
	journal = "RJC",
	keywords = "Reconnaissance linguistique schwa",
	lockkey = "N",
	month = "july",
	owner = "degottex",
	pdf = "Burki\_Gendrot\_RJC\_2007.pdf",
	timestamp = "2007.07.05",
	title = "{Reconnaissance automatique et analyse linguistique : l{\rq}exemple du schwa}",
	year = "2007"
}

@inproceedings{ChengYM1989,
	abstract = "The authors present an automatic and reliable algorithm for determining glottal closure instant (GCI). As a byproduct, nonstationary fundamental period estimation is achieved. The computation includes twelve-pole speech linear-prediction analysis, cross correlation, and both direct and inverse fast Fourier transforms (or a convolution). Maximum-likelihood epoch determination is used as the basis for locating GCIs, and the Hilbert transformation is applied to improve performance and reliability. A description of the system and the voiced/unvoiced/mixed (V/UV/M) decision procedure is given. The results show that the algorithm works in noise-free, noisy, and very noisy signals for vowels as well as for voiced constants. The proposed pitch estimation only needs a very short frame length and gives accurate results at voice onset",
	author = "Cheng, Y. M. and O'Shaughnessy, D.",
	booktitle = IEEE International Conference on Acoustics, Speech and Signal Processing ,
	doi = "10.1109/29.45529",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	keywords = "automatic and reliable algorithm; cross correlation; fast Fourier transforms; glottal closure instant; Hilbert transformation; maximum likelihood; noisy signals; period; pitch estimation; speech; speech analysis and processing; twelve-pole speech linear-prediction analysis; voiced constants; vowels",
	lockkey = "Y",
	pages = "1805--1815",
	title = "{Automatic and reliable estimation of glottal closure instant and period}",
	year = "1989"
}

@article{Campedel_Cappe_Moulines_IEEETSAP_2001,
	author = "Campedel-Oudot, Marine and Capp{\'e}, Olivier and Moulines, Eric",
	journal = "IEEETSAP",
	keywords = "Estimation Spectral Envelope Voiced Sounds Penalized Likelihood",
	lockkey = "N",
	owner = "norwin",
	pdf = "Campedel\_Cappe\_Moulines\_IEEETSAP\_2001\_CampedelIEEE01.pdf",
	timestamp = "2007.07.06",
	title = "{Estimation of the Spectral Envelope of Voiced Sounds Using a Penalized Likelihood Approach}",
	year = "2001"
}

@phdthesis{Carvalho_COIMBRA_2006,
	abstract = "In this research work, we address the problem of melody detection in polyphonic audio. Our system comprises three main modules, where a number of rule-based procedures are proposed to attain the specific goals of each unit: i) pitch detection; ii) determination of mu- sical notes (with precise temporal boundaries and pitches); and iii) identification of melodic notes. We follow a multi-stage approach, inspired on principles from perceptual theory and musical practice. Physiological models and perceptual cues of sound organization are incorporated into our method, mimicking the behavior of the human auditory system to some extent. Moreover, musicological principles are applied, in order to support the identification of the musical notes that convey the main melodic line. [...]",
	address = "Universidade de Coimbra Faculdade de Ci{\{\{\{\{\^e}}}}}ncias e Tecnologia Departamento de Engenharia Inform{\'a}tica",
	author = "{e Paiva}, Rui Pedro Pinto de Carvalho",
	keywords = "melody detection in polyphonic audio; music information retrieval; melody perception; musicology; pitch detection; conversion of pitch sequences into musical notes; pitch tracking and temporal segmentation; onset detection; identification of me- lodic notes; melody smoothing; note clustering.",
	lockkey = "N",
	month = "September",
	owner = "degottex",
	pdf = "Carvalho\_COIMBRA\_2006\_1349\_pub\_Thesis.pdf",
	school = "Universidade de Coimbra",
	timestamp = "2007.07.05",
	title = "{Melody Detection in Polyphonic Audio}",
	type = "Thesis submitted to the University of Coimbra in partial fulfillment of the requirements for the degree of Doctor of Philosophy in Informatics Engineering",
	year = "2006"
}

@article{Cemgil_Kappen_Barber_Transcription_2005,
	abstract = "In this paper we present a graphical model for polyphonic music transcription. Our model, formulated as a Dynamical Bayesian Network, embodies a transparent and computationally tractable approach to this acoustic analysis problem. An advantage of our approach is that it places emphasis on explicitly modelling the sound generation procedure. It provides a clear framework in which both high level (cognitive) prior information on music structure can be coupled with low level (acoustic physical) information in a principled manner to perform the analysis. The model is a special case of the, generally intractable, switching Kalman Ã¯Â¬Âlter model. Where possible, we derive, exact polynomial time inference procedures, and otherwise efÃ¯Â¬Âcient approximations. We argue that our generative model based approach is computationally feasible for many music applications and is readily extensible to more general auditory scene analysis scenarios.",
	author = "Cemgil, Ali Taylan and Kappen, Bert and Barber, David",
	keywords = "music transcription; polyphonic pitch tracking; Bayesian signal processing; switching Kalman Ã¯Â¬Âlters",
	lockkey = "N",
	owner = "norwin",
	pdf = "Cemgil\_Kappen\_Barber\_Transcription\_2005\_Generative model for music transcription.pdf",
	timestamp = "2007.07.06",
	title = "{A Generative Model for Music Transcription}",
	year = "2005"
}

@article{Cemgil_Kappen_Barber_IEEEWASPAA_2003,
	abstract = "In this paper we present a model for simultaneous tempo and poly- phonic pitch tracking. Our model, a form of Dynamical Bayesian Network [1], embodies a transparent and computationally tractable approach to this acoustic analysis problem. An advantage of our approach is that it places emphasis on modeling the sound gener- ation procedure. It provides a clear framework in which both high level (cognitive) prior information on music structure can be cou- pled with low level (acoustic physical) information in a principled manner to perform the analysis. The model is readily extensible to more complex sound generation processes.",
	author = "Cemgil, Ali Taylan and Kappen, Bert and Barber, David",
	journal = "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)",
	keywords = "GENERATIVE MODEL POLYPHONIC MUSIC TRANSCRIPTION",
	lockkey = "N",
	owner = "norwin",
	pdf = "Cemgil\_Kappen\_Barber\_IEEEWASPAA\_2003\_cemgil-waspaa03.pdf",
	timestamp = "2007.07.06",
	title = "{GENERATIVE MODEL BASED POLYPHONIC MUSIC TRANSCRIPTION}",
	year = "2003"
}

@phdthesis{Camacho2007,
	address = "USA",
	author = "Camacho, A.",
	lockkey = "Y",
	school = "University of Florida",
	title = "{{SWIPE}: {A} sawtooth waveform inspired pitch estimator for speech and music}",
	year = "2007"
}

@article{Cheveigne2002,
	abstract = "An algorithm is presented for the estimation of the fundamental frequency (F0) of speech or musical sounds. It is based on the well-known autocorrelation method with a number of modiÃ¯Â¬Âcations that combine to prevent errors. The algorithm has several desirable features. Error rates are about three times lower than the best competing methods, as evaluated over a database of speech recorded together with a laryngograph signal. There is no upper limit on the frequency search range, so the algorithm is suited for high-pitched voices and music. The algorithm is relatively simple and may be implemented efÃ¯Â¬Âciently and with low latency, and it involves few parameters that must be tuned. It is based on a signal model periodic signal that may be extended in several ways to handle various forms of aperiodicity that occur in particular applications. Finally, interesting parallels may be drawn with models of auditory processing.",
	author = "{de Cheveigne}, A. and Kawahara, H.",
	journal = "Journal of the Acoustical Society of America",
	keywords = "YIN f0 fundamental frequency",
	lockkey = "Y",
	number = "4",
	owner = "degottex",
	pages = "1917--1930",
	pdf = "Cheveigne\_Kawahara\_JASA\_2002\_YIN\_proof.pdf",
	timestamp = "2007.07.05",
	title = "{{YIN}, A fundamental frequency estimator for speech and music}",
	volume = "111",
	year = "2002"
}

@misc{Chew_Francois_ACM_2003,
	abstract = "We present MuSA.RT, Opus 1, a multimodal interactive sys- tem for music analysis and visualization using the Spiral Ar- ray model. Real-time MIDI input from a live performance is processed, analyzed and mapped to the 3D model, revealing tonal structures such as pitches, chords and keys. A user can concurrently navigate through the Spiral Array space using a gamepad or set the camera control to automatic pi- lot. The interaction among and concurrent processing of the diÃ¯Â¬Âerent data streams is made possible through the Modular Flow Scheduling Middleware.",
	author = "Chew, Elaine and Francois, Alexandre R.J.",
	keywords = "Spiral Array; SAI; MFSM; music analysis; system implementation; music visualization",
	lockkey = "N",
	month = "november",
	note = "Integrated Media Systems Center University of Southern California, Los Angeles, California",
	owner = "degottex",
	pdf = "Chew\_Francois\_ACM\_2003\_5169.0.de183-chewfrancois.pdf",
	timestamp = "2007.07.05",
	title = "{MuSA.RT: Music on the Spiral Array . Real-Time}",
	year = "2003"
}

@article{Chuan_Chew_ICME_2005,
	author = "Chuan and Chew",
	journal = "ICME",
	keywords = "Polyphonic Audio Key Finding Spiral Array CEG Algorithm",
	lockkey = "N",
	owner = "degottex",
	pdf = "Chuan\_Chew\_ICME\_2005\_5166.0.pdf",
	timestamp = "2007.07.05",
	title = "{Polyphonic Audio Key Finding using the Spiral Array CEG Algorithm}",
	year = "2005"
}

@misc{Conway_ONSALA_1999,
	abstract = "There are advantages in making the intermediate arrays of the MMA LSA which ll the 3km plain so-called 'zoom' arrays. In such arrays the antenna pads are arranged according to a scale-free self-similar distribution. By moving antennas from inner pads to outer ones the array gradually expands keeping a self-similar uv coverage. So far two types of zoom array have been proposed, one based on a de nite shape, a three-armed logarithmic spiral Conway 1998, and another assuming a circularly symmetric inverse-square law density of pads Webster 1998. In this memo we make a rst comparison of these two geometries. In the arrays tested we nd small but signi cant advantages of the spiral geometry over the circularly symmetric ones; both in terms of uv coverage and how well the geometry stays self-similar as the array zooms. Although better untested circularly symmetric con gurations may exist the advantages we see for the spiral appear to be intrinsic; coming fundamentally from its three-fold symmetry 
and the 'open' nature of this pattern. Despite these small di erences we argue that both circular and spiral zoom arrays have better capabilities than the series of set array con gurations that have dominated array con guration planning up to now.",
	author = "Conway, John",
	comment = "jconway@oso.chalmers.se",
	keywords = "Zoom Arrays Circular Spiral Symmetry",
	lockkey = "N",
	month = "April",
	note = "MMA Memo 260",
	owner = "degottex",
	pdf = "Conway\_ONSALA\_1999\_5164.0.memo260.pdf",
	timestamp = "2007.07.05",
	title = "{A Comparison of Zoom Arrays with Circular and Spiral Symmetry}",
	year = "1999"
}

@article{DAVY_GODSILL_Harmonic_2003,
	abstract = "This paper is concerned with the Bayesian analysis of musical signals. The ultimate aim is to use Bayesian hierarchical structures in order to infer quantities at the highest level, including such things as musical pitch, dynamics, timbre, instrument identity, etc. Analysis of real musical signals is complicated by many things, including the presence of transient sounds, noises and the complex structure of musical pitches in the frequency domain. The problem is truly Bayesian in that there is a wealth of (often subjective) prior knowledge about how musical signals are constructed, which can be exploited in order to achieve more accurate inference about the musical structure. Here we propose developments to an earlier Bayesian model which describes each component {\lq}note{\rq} at a given time in terms of a fundamental frequency, partials ({\lq}harmonics{\rq}), and amplitude. This basic model is modiÃ¯Â¬Âed for greater realism to include non-white residuals, time-varying amplitudes and partials {
\lq}detuned{\rq} from the natural linear relationship. The unknown parameters of the new model are simulated using a variable dimension MCMC algorithm, leading to a highly sophisticated analysis tool. We discuss how the models and algorithms can be applied for feature extraction, polyphonic music transcription, source separation and restoration of musical sources.",
	author = "DAVY, MANUEL and GODSILL, SIMON J.",
	keywords = "MUSICAL ANALYSIS; AUTOMATIC PITCH TRANSCRIPTION; PITCH ESTIMATION; INSTRUMENT CLASSIFICATION; AUDITORY SCENE ANALYSIS.",
	lockkey = "N",
	owner = "norwin",
	pdf = "DAVY\_GODSILL\_Harmonic\_2003\_harmonicfinal2.pdf",
	timestamp = "2007.07.06",
	title = "{Bayesian Harmonic Models for Musical Signal Analysis}",
	year = "2003"
}

@inproceedings{Deliyski2003,
	abstract = "The presented material is part of a bigger ongoing project at University of South Carolina studying the Clinical Utility of High-Speed Videoendoscopy (HSV) for Evaluation of Laryngeal Pathology. The overall goal of the project is to assess the potential of HSV to transition from a powerful research tool into a comprehensive clinical method. For several decades HSV has been regarded as the ultimate voice evaluation technique but the technology was not available. Nowadays the HSV technology is accessible, however no established clinical evaluation protocols, proven effective measurement techniques, or validity and reliability data are available. The main focus of this paper is on the methods for objective voice assessment of high- speed video examinations of subjects with normal and pathological laryngeal function. These methods are designed to deliver to the clinician the essential quantitative information of HSV in an effective way without compromising its subjective and intuitive components. 
Methods range from new visual representations to quantitative assessment parameters that uniquely describe voice characteristics contained in HSV. A reference to the currently ongoing clinical and instrumental validity and reliability assessment of HSV through the developed methods is also made.",
	author = "Deliyski, D. and Petrushev, P.",
	booktitle = "{Proc. Advances in Quantitative Laryngology (AQL)}",
	journal = "AQL",
	keywords = "high-speed video; kymography; voice analysis; voice disorders",
	lockkey = "Y",
	owner = "degottex",
	pages = "1--16",
	timestamp = "2007.11.27",
	title = "{Methods for Objective Assessment of High-Speed Videoendoscopy}",
	year = "2003"
}

@mastersthesis{DENIS_Transformation_2003,
	abstract = "La transformation de voix est une op{\'e}ration qui consiste {\`a} modiÃ¯Â¬Âer les enregistrements audio d{\rq}une voix aÃ¯Â¬Ân d{\rq}en changer l{\rq}identit{\'e} per\c{c}ue. On peut par exemple vouloir cr{\'e}er un enregistrement de voix d{\rq}homme {\`a} partir d{\rq}une voix de femme, en changer le timbre, l{\rq}intonation, l{\rq}accent ou la prononciation sur certaines r{\'e}gions, etc. [...]",
	author = "DENIS, Guillaume",
	keywords = "transformation voix conversion morphing synth{\`e}se apprentissage; DTW; PSOLA",
	lockkey = "N",
	owner = "norwin",
	pdf = "DENIS\_Transformation\_2003\_gd\_vt.pdf",
	school = "ATIAM",
	timestamp = "2007.07.06",
	title = "{Transformation de l{\rq}identit{\'e} d{\rq}une voix}",
	year = "2003"
}

@misc{Dolson2000,
	author = "Dolson, Mark",
	keywords = "Phase Vocoder Tutorial",
	lockkey = "Y",
	owner = "norwin",
	pdf = "Dolson\_Vocoder\_2006\_pvoc-dolson.par.pdf",
	timestamp = "2007.07.06",
	title = "{The Phase Vocoder: A Tutorial}",
	year = "2006"
}

@inproceedings{Doval2000,
	author = "Doval, Boris and d'Alessandro, C.",
	booktitle = IEEE International Conference on Acoustics, Speech and Signal Processing ,
	lockkey = "Y",
	owner = "norwin",
	pdf = "Doval\_Alessandro\_Correlates\_2000\_spectral-correlates-of-glottal.pdf",
	timestamp = "2007.07.11",
	title = "{Spectral Correlates of Glottal Waveform models: An analytic study}",
	year = "2000"
}

@techreport{Doval1999,
	abstract = "A uniÃ¯Â¬Âed framework for studying the time and frequency domains properties of glottal Ã¯Â¬Âow models is proposed. It is shown that all the models can be represented by a common set of Ã¯Â¬Âve time-domain parameters: three scale parameters (fundamental period, amplitude of voicing , open quotient), a shape parameter (asymmetry coefÃ¯Â¬Âcient), and a closure continuity parameter (return phase time constant). The spectrum of glottal Ã¯Â¬Âow models is low-pass, and its derivative can be characterized by a spectral peak. The closure continuity parameter corresponds to a spectral tilt component. The scale parameters are interpreted using scaling properties of the Fourier transform. Then, the glottal Ã¯Â¬Âow spectra can be stylized by 3 straight lines in a log-magnitude/log-frequency representation characterized by Ã¯Â¬Âve parameters: fundamental frequency, spectral peak amplitude and frequency, quality factor of the spectral peak, spectral tilt cut-off frequency. Explicit relationships 
between time domain and frequency domain parameters are given for four widely used glottal Ã¯Â¬Âow models.",
	author = "Doval, B. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro",
	institution = "LIMSI",
	keywords = "glottal Ã¯Â¬Âow; spectral analysis; vocal quality",
	lockkey = "Y",
	number = "NDL N 99-07",
	owner = "degottex",
	pdf = "DOVAL\_ALESSANDRO\_LIMSI\_1999\_DovalLIMSI99.pdf",
	timestamp = "2007.07.05",
	title = "{The spectrum of glottal flow models}",
	year = "1999"
}

@inproceedings{Doval2003,
	abstract = "A new type of glottal Ã¯Â¬Âow model, namely a causal- anticausal linear Ã¯Â¬Âlter model, is proposed. It is shown that the glottal Ã¯Â¬Âow signal can be considered as the impulse re- sponse of a linear Ã¯Â¬Âlter. Then the source/Ã¯Â¬Âlter speech model can be interpreted as an excitation/Ã¯Â¬Âlter speech model, the ``Ã¯Â¬Âl- ter'' comprising the glottal Ã¯Â¬Âow, vocal tract and radiation com- ponents. The spectral features of the voice source models are reviewed, both in the amplitude and phase domains. In the spec- tral amplitude domain the main features are a spectral maximum (the ``glottal formant'') and spectral tilt. Evidence for a mixed causal/anticausal phase behavior of the source is given. Then, a causal-anticausal linear Ã¯Â¬Âlter voice source model is designed. In conclusion, applications of this new approach are discussed for voice quality modiÃ¯Â¬Âcation, voice source estimation, voice quality perception.",
	author = "B. Doval and C. d'Alessandro and N. Henrich",
	booktitle = "{Proc. ISCA Voice Quality: Functions, Analysis and Synthesis (VOQUAL)}",
	journal = "VOQUAL",
	lockkey = "Y",
	owner = "norwin",
	pages = "16--20",
	pdf = "Doval\_Alessandro\_Henrich\_VOQUAL\_2003\_CALM.pdf",
	timestamp = "2007.07.05",
	title = "{The voice source as a causal/anticausal linear filter}",
	year = "2003"
}

@article{DZIUBINSKI_KOSTEK_AA_2004,
	abstract = "The aim of this paper is to present a method improving pitch estimation accuracy, show- ing high performance for both synthetic harmonic signals and musical instrument sounds. This method employs an ArtiÃ¯Â¬Âcial Neural Network of a feed-forward type. In addition, octave error optimized pitch detection algorithm, based on spectral analysis is introduced. The pro- posed algorithm is very effective for signals with strong harmonic, as well as nearly sinusoidal contents. Experiments were performed on a variety of musical instrument sounds and sample results exemplifying main issues of both engineered algorithms are shown.",
	author = "DZIUBINSKI, M. and KOSTEK, B.",
	journal = "AA",
	keywords = "HIGH ACCURACY AND OCTAVE ERROR IMMUNE PITCH DETECTION ALGORITHMS",
	lockkey = "N",
	note = "Multimedia Systems Department Gdansk University of Technology Narutowicza 11/12, 80-952 Gdansk, Poland e-mail: kido@sound.eti.pg.gda.pl",
	owner = "degottex",
	pdf = "DZIUBINSKI\_KOSTEK\_AA\_2004\_pitch\_detection\_algorithms.pdf",
	timestamp = "2007.07.05",
	title = "{HIGH ACCURACY AND OCTAVE ERROR IMMUNE PITCH DETECTION ALGORITHMS}",
	year = "2004"
}

@article{ElJaroudiA1991,
	abstract = "A method for parametric modeling and spectral envelopes when only a discrete set of spectral points is given is introduced. This method, called discrete all-pole (DAP) modeling, uses a discrete version of the Itakura-Saito distortion measure as its error criterion. One result is an autocorrelation matching condition that overcomes the limitations of linear prediction and produces better fitting spectral envelopes for spectra that are representable by a relatively small discrete set of values, such as in voiced speech. An iterative algorithm for DAP modeling that is shown to converge to a unique global minimum is presented. Results of applying DAP modeling to real and synthetic speech are also presented. DAP modeling is extended to allow frequency-dependent weighting of the error measure, so that spectral accuracy can be enhanced in certain frequency regions.",
	author = "El-Jaroudi, A. and Makhoul, J.",
	journal = "IEEE Trans. on Signal Processing",
	keywords = "Discrete All-Pole Modeling DAP",
	lockkey = "Y",
	number = "2",
	owner = "norwin",
	pages = "411--423",
	pdf = "El-Jaroudi\_Makhoul\_IEEETSP\_1991\_Discrete All-pole Modeling - ElJaroudiIEEE91.pdf",
	timestamp = "2007.07.06",
	title = "{Discrete All-Pole Modeling}",
	volume = "39",
	year = "1991"
}

@misc{Ellis2004,
	author = "Ellis, Dan",
	keywords = "Speech modeling synthesis",
	lockkey = "Y",
	note = "slides",
	owner = "norwin",
	pdf = "Ellis\_Modeling\_2004\_Ellis\_speechmodels.pdf",
	timestamp = "2007.07.06",
	title = "{Speech modeling and synthesis}",
	year = "2004"
}

@article{En-Najjary_Rosec_Chonavel_ICSLP_2004,
	abstract = "Most of the research in Voice Conversion (VC) is devoted to spectral transformation while the conversion of prosodic features is essentially obtained through a simple linear transformation of pitch. These separate transformations lead to an unsatisfactory speech conversion quality, especially when the speaking styles of the source and target speakers are different. In this paper, we propose a method capable of jointly converting pitch and spectral envelope information. The parameters to be transformed are obtained by combining scaled pitch values with the spectral envelope parameters for the voiced frames and only spectral envelope parameters for the unvoiced ones. These parameters are clustered using a Gaussian Mixture Model (GMM). Then the transformation functions are determined using a conditional expectation estimator. Tests carried out show that, this process leads to a satisfactory pitch transformation. Moreover, it makes the spectral envelope transformation more robust.",
	author = "En-Najjary, Taoufik and Rosec, Olivier and Chonavel, Thierry",
	journal = "ICSLP",
	keywords = "voice conversion method joint pitch spectral envelope transformation",
	lockkey = "N",
	owner = "norwin",
	pdf = "En-Najjary\_Rosec\_Chonavel\_ICSLP\_2004\_A voice conversion method based on joint pitch and spectral envelope transformation.pdf",
	timestamp = "2007.07.06",
	title = "{A voice conversion method based on joint pitch and spectral envelope transformation}",
	year = "2004"
}

@article{En-Najjary_Rosec_Chonavel_LCSLP_2004,
	abstract = "Voice conversion (VC) can be seen as a powerful technology for customizing Text-to-Speech (TTS) systems. This paper deals with the integration of a VC method based on Gaussian Mixture Model (GMM) in a TTS system. In this framework, an algorithm that enables complexity reduction of the VC processing is proposed. The main idea is to restrict the conversion function to the most representative components of the GMM for each frame and, if necessary, to store the component indices and their associated weights in the acoustic dictionary. This method is evaluated by comparison to a classical GMM-based transformation function. Tests show that both methods yield comparable results. Furthermore, additional experiments indicate that this new technique leads to a significant decrease of the computational load involved in the conversion process.",
	author = "En-Najjary, Taoufik and Rosec, Olivier and Chonavel, Thierry",
	journal = "LCSLP",
	keywords = "GMM voice conversion Text-To-Speech synthesis",
	lockkey = "N",
	owner = "norwin",
	pdf = "En-Najjary\_Rosec\_Chonavel\_LCSLP\_2004\_NBEST\_Icslp04.pdf",
	timestamp = "2007.07.06",
	title = "{Fast GMM-based voice conversion for Text-To-Speech synthesis systems}",
	year = "2004"
}

@inproceedings{Every_Szymanski_DAFX_2004,
	author = "Every and Szymanski",
	booktitle = "{DAFx}",
	journal = "DAFx",
	keywords = "Spectral-Filtering approach Music Signal Separation",
	lockkey = "N",
	owner = "norwin",
	pdf = "Every\_Szymanski\_DAFX\_2004\_P\_197.pdf",
	timestamp = "2007.07.05",
	title = "{A Spectral-Filtering approach to Music Signal Separation}",
	year = 2004
}

@article{Fant1985,
	author = "Fant, G. and Liljencrants, J. and Lin, Q.-G.",
	comment = "Gunnar Fant and Johan Liljencrants and Qi-guang Lin",
	file = "file:///data/anasynth/degottex/articles/db/Fant1985\_fant85-stl-qpsr.pdf",
	journal = "STL-QPSR",
	lockkey = "Y",
	number = "4",
	owner = "degottex",
	pages = "1--13",
	timestamp = "2007.12.13",
	title = "{A four-parameter model of glottal flow}",
	volume = "26",
	year = "1985"
}

@phdthesis{Fernandez2004,
	address = "USA",
	author = "Fernandez, Raul",
	keywords = "SPAT Computational Model Recognition Affect Speech",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Fernandez\_MIT\_2004\_phdthesis.pdf",
	school = "Massachusetts Institute of Technology",
	timestamp = "2007.07.05",
	title = "{A Computational Model for the Automatic Recognition of Affect in Speech}",
	year = "2004"
}

@article{Flaschka_2006,
	abstract = "The glottal closure is an important parameter to describe the phonation process. The duration of the glottal closure influences the effectiveness of voice production and the timbre of the voice. Therefore the glottal closure is an important factor to judge the voice function. Based on stroboscopic video sequences one can assess the kind of the glottal closure. A stroboscope is used to create an illusory slow motion of the periodic vibration of the vocal folds. The stroboscopic analysis gives the well known nominal scaled classification of the glottal closure: complete closure, posterior or anterior triangle, irregular, spindle, hourglass or incomplete glottal closure. Such a classification doesn{\rq}t allow a quantitative analysis of the glottal closure and it is ambiguous for the diagnosis of functional voice disorders. It gives no numeric information about the duration of the glottal closure and their time depended change. The results of the well known electroglottography (EGG) are not 
sufficient too, because, the EGG -- signal gives a mean value of the glottal closure duration. Another way, to investigate the glottal closure behaviour is the use of videokymography [1]. This technique records images along a single selected line which is crossed the vocal folds. This method shows the time dependence of the glottal closure, see fig. 1, but it is not possible to show the glottal closure along the glottis.",
	author = "Flaschka, J. and Braunschweig, T. and P.-Schelhorn-Neise",
	lockkey = "N",
	note = "Thomas.Braunschweig@med.uni-jena.de",
	owner = "degottex",
	timestamp = "2007.11.27",
	title = "{To Use the Quantitative Analysis of Duration of Glottal Closure for Diagnosis of Functional Voice Disorders}",
	year = "2006"
}

@article{Fu_Murphy_NOLISP_2003,
	abstract = "An adaptive, pitch-synchronous analysis method is proposed for the simultaneous estimation of vocal tract and voice source parameters from speech waveforms. A time varying autoregressive model with exogenous input (ARX) is chosen for vocal tract modeling because of the capability of such a model for characterising both the formants and antiformants of the vocal tract. The Liljencrants-Fant model for the voice source is integrated into an iterative adaptive estimation procedure. Furthermore, an adaptive inverse filtering technique is put forward to obtain high accuracy estimation of the glottal source waveform, which is necessary for the intended application of the method to pathological voice analysis. The technique is evaluated and compared with a number of other approaches using synthetic speech containing additive noise at the source. The results illustrate the superior performance of the new method.",
	author = "Fu, Qiang and Murphy, Peter",
	journal = "NOLISP",
	keywords = "Adaptive Inverse Filtering Estimation Glottal Source",
	lockkey = "N",
	note = "Department of Electronic and Computer Engineering University of Limerick, Limerick, Ireland Email: Qiang.Fu@ul.ie Peter.Murphy@ul.ie",
	owner = "degottex",
	pdf = "Fu\_Murphy\_NOLISP\_2003\_QFuNOLISP03.pdf",
	timestamp = "2007.07.05",
	title = "{Adaptive Inverse Filtering for High Accuracy Estimation of the Glottal Source}",
	year = "2003"
}

@article{Fulop_Formant_2003,
	abstract = "This paper describes a new kind of power spectrum which, when properly em- ployed, can provide hitherto unseen accuracy in probing the resonance spectrum of the vocal tract. By drawing on new signal processing techniques developed by Nelson and his collaborators [2, 3], a method for computing a power spectrum has been implemented in Matlab, and applied to the problem of the accurate mea- surement of formant frequencies and other resonances. Some direct information about formant bandwidths is also available in the spectrum, though this may or may not be suÃ¯Â¬Âciently readable to provide accurate measurements. The result- ing computed spectrum, which we call the ``Nelson power spectrum'' in honor of the person principally responsible for the theory behind it, has been proven by Nelson to be a good estimate of a theoretical spectrum which has frequency reso- lution far beyond that of the familiar Fourier transform power spectrum, and far fewer errors and artifacts as well. While Nelson{\rq}s 
papers present the mathemati- cal theory behind this new technique, there are only loose guidelines as to speciÃ¯Â¬Âc digital-domain methods and algorithms. The principal contributions of this paper are the development of a method using the Nelson spectrum for the measure- ment of formants and other vocal tract resonances with examples generated by a Matlab implementation, and the presentation and discussion of a complete pseu- docode algorithm for computing the Nelson spectrum. Since a picture is worth a thousand words in this case, we will leave it to the example images to convince the reader that there is simply no other way of measuring formant frequencies that can even come close to the accuracy and conÃ¯Â¬Âdence that are provided by the Nelson power spectrum, and we consequently advocate this technique as a new benchmark for the accurate measurement of vocal tract resonances.",
	author = "Fulop, Sean A.",
	keywords = "means measuring formants",
	lockkey = "N",
	note = "Dept. of Linguistics Dept. of Computer Science The University of Chicago",
	owner = "norwin",
	pdf = "Fulop\_Formant\_2003\_FulopRep03.pdf",
	timestamp = "2007.07.06",
	title = "{An accurate means for measuring formants}",
	year = "2003"
}

@article{Garnier_Henrich_SCOLIA_2005,
	abstract = "This paper presents the main steps of a research project. It aims at understanding the notion of voice quality in western operatic singing, in studying what the singing teachers perceive while listening to a given voice, and how they orally express their perception. Trained singers and singing teachers were asked to speak about voice quality, while producing different voice qualities on a given musical sentence or while listening to singing examples. A linguistic analysis was conducted on their speech. It provided with part of the vocabulary related to the notion of voice quality, and helped to understand the underlying concepts. The possible correlates between acoustical parameters and verbal criterions were also explored.",
	author = "Garnier, Ma{\"e}va and Henrich, Nathalie",
	journal = "SCOLIA",
	lockkey = "N",
	note = "Laboratoire d{\rq}Acoustique Musicale CNRS, UPMC, Minist{\`e}re de la Culture, Paris",
	owner = "norwin",
	pdf = "Garnier\_Henrich\_SCOLIA\_2005\_sco20Garnier.pdf",
	timestamp = "2007.07.05",
	title = "{ETUDE DE LA QUALIT{\'E} VOCALE DANS LE CHANT LYRIQUE}",
	year = "2005"
}

@article{Garnier2004,
	abstract = "This paper presents a method for finding outstanding physical parameters which should contribute to the perception of western operatic vocal quality. Based on the results of a previous cognitive study, presented in a companion paper [4], this methodology emphasises the listening point of vue and endeavours thinking about the relevance of the evaluation criters and of the realised analyses. It is shown how the enhancement of the first two formants or of the singing formant may contribute to the perception of brightness (``brillance''), of the character ``voix timbr{\'e}e'' or of the presence of air (``air sur la voix'').",
	author = "Garnier, Maeva and Henrich, Nathalie and Castellengo, Michelle and Dubois, Danielle and Poitevineau, Jacques",
	lockkey = "N",
	owner = "norwin",
	pdf = "Garnier\_Henrich\_Qualite\_2004\_JEP\_Garnier\_2.pdf",
	timestamp = "2007.07.11",
	title = "{Perception et description acoustique de la qualite vocale dans le chant lyrique}",
	year = "2004"
}

@article{Gerhard_Pitch_2003,
	abstract = "Pitch extraction (also called fundamental frequency estimation) has been a popular topic in many Ã¯Â¬Âelds of research since the age of computers. Yet in the course of some 50 years of study, current techniques are still not to a desired level of accuracy and robustness. When presented with a single clean pitched signal, most techniques do well, but when the signal is noisy, or when there are multiple pitch streams, many current pitch algorithms still fail to perform well. This report presents a discussion of the history of pitch detection techniques, as well as a survey of the current state of the art in pitch detection technology.",
	author = "Gerhard, David",
	keywords = "Pitch Extraction Fundamental Frequency",
	lockkey = "N",
	owner = "norwin",
	pdf = "Gerhard\_Pitch\_2003\_TRdbg-Pitch.pdf",
	timestamp = "2007.07.06",
	title = "{Pitch Extraction and Fundamental Frequency: History and Current Techniques}",
	year = "2003"
}

@article{Goto_ICASSP_2000,
	abstract = "This paper describes a robust method for estimating the funda- mental frequency (F0) of melody and bass lines in monaural real- world musical audio signals containing sounds of various instru- ments. Most previous F0-estimation methods had great difÃ¯Â¬Âculty dealing with such complex audio signals because they were de- signed to deal with mixtures of only a few sounds. To make it possible to estimate the F0 of the melody and bass lines, we pro- pose a predominant-F0 estimation method called PreFEst that does not rely on the F0{\rq}s unreliable frequency component and obtains the most predominant F0 supported by harmonics within an inten- tionally limited frequency range. It evaluates the relative domi- nance of every possible F0 by using the Expectation-Maximization algorithm and considers the temporal continuity of F0s by using a multiple-agent architecture. Experimental results show that our real-time system can detect the melody and bass lines in audio sig- nals sampled from commercially 
distributed compact discs.",
	author = "Goto, Masataka",
	journal = IEEE International Conference on Acoustics, Speech and Signal Processing ,
	keywords = "PREDOMINANT F0 METHOD REAL-TIME MELODY BASS LINES",
	lockkey = "N",
	owner = "norwin",
	timestamp = "2007.07.06",
	title = "{A ROBUST PREDOMINANT-F0 ESTIMATION METHOD FOR REAL-TIME DETECTION OF MELODY AND BASS LINES IN CD RECORDINGS}",
	year = "2000"
}

@article{Granqvist_Hammarberg_2003,
	abstract = "Fundamental frequency (F0) extraction is often used in voice quality analysis. In pathological voices with a high degree of instability in F0, it is common for F0 extraction algorithms to fail. In such cases, the faulty F0 values might spoil the possibilities for further data analysis. This paper presents the correlogram, a new method of displaying periodicity. The correlogram is based on the waveform matching techniques often used in F0 extraction programs, but with no mechanism to select an actual F0 value. Instead, several candidates for F0 are shown as dark bands. The result is presented as a 3D-plot with time on the x-axis, correlation delay inverted to frequency on the y-axis and correlation on the z-axis. The z-axis is represented in a gray scale as in a spectrogram. Delays corresponding to integer multiples of the period time will receive high correlation, thus resulting in candidates at F0, F0/2, F0/3 etc. While the corrlogram adds little to F0 analysis of normal voices, it is useful 
for analysis of pathological voices since it illustrates the full complexity of the periodicity in the voice signal. Also, in combination with manual tracing, the correlogram can be used for semi-manual F0 extraction. If so, F0 extraction can be performed on many voices that cause problems for conventional F0 extractors. To demonstrate the properties of the method it is applied to synthetic and natural voices, among them six pathological voices, which are characterized by roughness, vocal fry, gratings/scrape, hypofunctional breathiness and voice breaks, or combinations of these.",
	author = "Granqvist, Svante and Hammarberg, Britta",
	keywords = "Correlogram visual display periodicity",
	lockkey = "N",
	note = "* Dept of Speech, Music and Hearing, KTH, Stockholm; Electronic mail: svante.granqvist@speech.kth.se ** Dept of Logopedics and Phoniatrics, Karolinska Institute, Huddinge University Hospital; Electronic mail: britta.hammarberg@klinvet.ki.se",
	owner = "degottex",
	pdf = "Granqvist\_Hammarberg\_2003\_paperII.pdf",
	timestamp = "2007.07.05",
	title = "{The Correlogram: a visual display of periodicity}",
	year = "2003"
}

@article{Granqvista_JASA_2001,
	author = "Granqvista, Svante and Lindestadb, Per-Ake",
	journal = "JASA",
	lockkey = "N",
	owner = "degottex",
	timestamp = "2007.11.27",
	title = "{A method of applying Fourier analysis to high-speed laryngoscopy}",
	year = "2001"
}

@misc{Hainsworth_Rep1_2001,
	abstract = "This report centres around some of this issues involved in automatic transcription of polyphonic musical audio signals. That is, representing the information contained in the audio in such a way as to be recog- nisable and usable by a musician. First, a review of the various Ã¯Â¬Âelds which have a bearing on the subject is put forward, including music, music psychology, auditory psychology and signal processing. Then a thorough appraisal of previous work on automated polyphonic transcription is presented. Next, original work on the use of time-frequency reassignment as a front end is imparted and Ã¯Â¬Ânally, future ideas are expounded and a timetable for forthcoming research is given.",
	author = "Hainsworth, Stephen W.",
	keywords = "Analysis Musical Audio Polyphonic Transcription",
	lockkey = "N",
	owner = "norwin",
	pdf = "Hainsworth\_Rep1\_2001\_Analysis of Musical audio for polyphonic transcription - rep1st.pdf",
	timestamp = "2007.07.06",
	title = "{Analysis of Musical Audio for Polyphonic Transcription}",
	year = "2001"
}

@article{Hainsworth_Macleod_ICMC_2001,
	abstract = "This paper examines the transcription of just a single instru- ment from a rich, polyphonic audio stream. The {\lq}bass line{\rq} in jazz and rock recordings was chosen for this as a reasonably separable instrument, given several assumptions. An algo- rithm is presented which performs the following, sequential steps: note onset location; note hypothesis generation; a hy- pothesis tracker; and Ã¯Â¬Ânally a hypothesis resolver. Results are presented for examples taken from commercially avail- able CDs which achieve a note recognition rate of 78.7\%, using the metric of Kashino and Murase (1998).",
	author = "Hainsworth, Stephen W. and Macleod, Malcolm D.",
	journal = "ICMC",
	keywords = "Automatic Bass Line Transcription Polyphonic Music",
	lockkey = "N",
	note = "Signal Processing Laboratory, Department of Engineering University of Cambridge. Ã¯Â¿Å swh21, mdm!` @eng.cam.ac.uk",
	owner = "norwin",
	pdf = "Hainsworth\_Macleod\_ICMC\_2001\_bass.pdf",
	timestamp = "2007.07.05",
	title = "{Automatic Bass Line Transcription from Polyphonic Music}",
	year = "2001"
}

@article{Hegde2007,
	author = "Hegde, R. M. and Murthy, H. A. and Gadde, V. R. R.",
	doi = "10.1109/TASL.2006.876858",
	journal = "Audio, Speech and Language Processing, IEEE Trans. on [see also Speech and Audio Processing, IEEE Trans. on]",
	lockkey = "N",
	month = "Jan.",
	number = "1",
	owner = "degottex",
	pages = "190--202",
	timestamp = "2007.03.05",
	title = "{Significance of the Modified Group Delay Feature in Speech Recognition}",
	volume = "15",
	year = "2007"
}

@article{Hedge_Murthy_ICASSP_2004,
	abstract = "This paper discusses the significance of joint cepstral features derived from the modified group delay function and MFCC in speech processing. We start with a definition of cepstral features derived from the modified group delay function called the modified group delay feature (MODGDF) which is derived from the Fourier transform phase. Robustness issues like similarities of the MODGDF to RASTA and cepstral mean subtraction are discussed. The efficiency with which formants can be reconstructed for noisy cellular speech using joint features derived from early fusion is illustrated. The joint features are used for four speech processing tasks phoneme, syllable, speaker, and language recognition. Based on the results of analysis and performance evaluation the significance of joint features derived from the MODGDF and MFCC are discussed.",
	author = "Hegde, Rajesh M. and Murthy, Hema A. and Rao, Gadde V. Ramana",
	journal = IEEE International Conference on Acoustics, Speech and Signal Processing ,
	lockkey = "N",
	owner = "degottex",
	pdf = "Hedge\_Murthy\_ICASSP\_2004\_Speech\_processing\_Modified\_Group\_Delay\_Function.pdf",
	timestamp = "2007.03.01",
	title = "{SPEECH PROCESSING USING JOINT FEATURES DERIVED FROM THE MODIFIED GROUP DELAY FUNCTION}",
	year = "2004"
}

@phdthesis{Henrich2001,
	address = "France",
	author = "Henrich, Nathalie",
	keywords = "glottis EGG separation",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Henrich\_UPMC\_2001\_PhDthesis-301101.pdf",
	school = "UPMC, in french",
	timestamp = "2007.03.05",
	title = "{Etude de la source glottique en voix parl{\'e}e et chant{\'e}e}",
	year = "2001"
}

@article{Hindi_PARC_2007,
	abstract = "Abstract--- In recent years, convex optimization has become a computational tool of central importance in engineering, thanks to its ability to solve very large, practical engineering problems reliably and efÃ¯Â¬Âciently. The goal of this tutorial is to continue the overview of modern convex optimization from where our ACC2004 Tutorial on Convex Optimization left off, to cover important topics that were omitted there due to lack of space and time, and highlight the intimate connections between them. The topics of duality and interior point algorithms will be our focus, along with simple examples. The material in this tutorial is excerpted from the recent book on convex optimization, by Boyd and Vandenberghe, who have made available a large amount of free course material and freely available software. These can be downloaded and used immediately by the reader both for self-study and to solve real problems.",
	author = "Hindi, Haitham",
	journal = "PARC",
	keywords = "Tutorial Convex Optimization II Duality Interior Point Methods",
	lockkey = "N",
	note = "Palo Alto Research Center (PARC), Palo Alto, California 94304 email: hhindi@parc.com",
	owner = "norwin",
	pdf = "Hindi\_PARC\_2007\_hindiTutorial2.pdf",
	timestamp = "2007.07.05",
	title = "{A Tutorial on Convex Optimization II: Duality and Interior Point Methods}",
	year = "2007"
}

@article{Hindi_2006_Convex,
	abstract = "In recent years, convex optimization has be- come a computational tool of central importance in engi- neering, thanks to it{\rq}s ability to solve very large, practical engineering problems reliably and efÃ¯Â¬Âciently. The goal of this tutorial is to give an overview of the basic concepts of convex sets, functions and convex optimization problems, so that the reader can more readily recognize and formulate engineering problems using modern convex optimization. This tutorial coincides with the publication of the new book on convex optimization, by Boyd and Vandenberghe [7], who have made available a large amount of free course material and links to freely available code. These can be downloaded and used immediately by the audience both for self-study and to solve real problems.",
	author = "Hindi, Haitham",
	journal = "PARC",
	keywords = "Tutorial Convex Optimization",
	lockkey = "N",
	note = "Palo Alto Research Center (PARC), Palo Alto, California",
	owner = "degottex",
	pdf = "Hindi\_2006\_Convex\_CvxOptTutPaper.pdf",
	timestamp = "2007.07.05",
	title = "{A Tutorial on Convex Optimization}",
	year = "2006"
}

@article{Hiroya_Honda_IEEETSAP_2004,
	abstract = "We present a method that determines articulatory movements from speech acoustics using a Hidden Markov Model (HMM)-based speech production model. The model statistically generates speech spectrum and articulatory parameters from a given phonemic string. It consists of HMMs of articulatory param- eters for each phoneme and an articulatory-to-acoustic mapping for each HMM state. For a given speech spectrum, maximum a posteriori estimation of the articulatory parameters of the statis- tical model is presented. The performance on sentences was evalu- ated by comparing the estimated articulatory parameters with the observed parameters. The average RMS errors of the estimated ar- ticulatory parameters were 1.50 mm from the speech acoustics and the phonemic information in an utterance and 1.73 mm from the speech acoustics only.",
	author = "Hiroya, Sadao and Honda, Masaaki",
	journal = "IEEETSAP",
	keywords = "Articulatory HMM; articulatory-to-acoustic mapping; HMM-based speech production model; speech inversion.",
	lockkey = "N",
	month = "march",
	owner = "degottex",
	pages = "175",
	pdf = "Hiroya\_Honda\_IEEETSAP\_2004\_HiroyaIEEE04.pdf",
	timestamp = "2007.07.05",
	title = "{Estimation of Articulatory Movements From Speech Acoustics Using an HMM-Based Speech Production Model}",
	volume = "12",
	year = "2004"
}

@article{Hiroya_Honda_IEICETIS_2004,
	abstract = "We present a speaker adaptation method that makes it possible to determine articulatory parameters from an unknown speaker's speech spectrum using an HMM (Hidden Markov Model)-based speech production model. The model consists of HMMs of articulatory parameters for each phoneme and an articulatory-to-acoustic mapping that transforms the articulatory parameters into a speech spectrum for each HMM state. The model is statistically constructed by using actual articulatory-acoustic data. In the adaptation method, geometrical differences in the vocal tract as well as the articulatory behavior in the reference model are statistically adjusted to an unknown speaker. First, the articulatory parameters are estimated from an unknown speaker's speech spectrum using the reference model. Secondly, the articulatory-to-acoustic mapping is adjusted by maximizing the output probability of the acoustic parameters for the estimated articulatory parameters of the unknown speaker. With the adaptation method, the RMS 
error between the estimated articulatory parameters and the observed ones is 1.65 mm. The improvement rate over the speaker independent model is 56.1 \%.",
	author = "Hiroya, Sadao and Honda, Masaaki",
	journal = "IEICETIS",
	keywords = "Speaker Adaptation Method for Acoustic-to-Articulatory Inversion using an HMM-Based Speech Production Model",
	lockkey = "N",
	month = "may",
	owner = "degottex",
	pages = "1071",
	pdf = "Hiroya\_Honda\_IEICETIS\_2004\_HiroyaIEEE04b.pdf",
	timestamp = "2007.07.05",
	title = "{Speaker Adaptation Method for Acoustic-to-Articulatory Inversion using an HMM-Based Speech Production Model}",
	volume = "E87-D",
	year = "2004"
}

@article{IseliM2007,
	abstract = "The effects of age, sex, and vocal tract conÃ¯Â¬Âguration on the glottal excitation signal in speech are only partially understood, yet understanding these effects is important for both recognition and synthesis of speech as well as for medical purposes. In this paper, three acoustic measures related to the voice source are analyzed for Ã¯Â¬Âve vowels from 3145 CVC utterances spoken by 335 talkers 8 -- 39 years old from the CID database Miller et al., Proceedings of ICASSP, 1996, Vol. 2, pp. 849--852 . The measures are: the fundamental frequency F0 , the difference between the ``corrected'' denoted by an asterisk Ã¯Â¬Ârst two spectral harmonic magnitudes, H* Ã¢ÂÂ H* related to the 1 2 open quotient , and the difference between the ``corrected'' magnitudes of the Ã¯Â¬Ârst spectral harmonic and that of the third formant peak, H* Ã¢ÂÂ A* related to source spectral tilt . The correction refers to 1 3 compensating for the inÃ¯Â¬Âuence of formant frequencies on spectral magnitude estimation. 
Experimental results show that the three acoustic measures are dependent to varying degrees on age and vowel. Age dependencies are more prominent for male talkers, while vowel dependencies are more prominent for female talkers suggesting a greater vocal tract-source interaction. All talkers show a dependency of F0 on sex and on F3, and of H* Ã¢ÂÂ A* on vowel type. For low-pitched talkers 1 3 F0 175 Hz , H* Ã¢ÂÂ H* is positively correlated with F0 while for high-pitched talkers, H* Ã¢ÂÂ H* is 1 2 1 2 dependent on F1 or vowel height. For high-pitched talkers there were no signiÃ¯Â¬Âcant sex dependencies of H* Ã¢ÂÂ H* and H* Ã¢ÂÂ A*. The statistical signiÃ¯Â¬Âcance of these results is shown. 1 2 1 3",
	author = "Iseli, Markus and Shue, Yen-Liang and Alwan, Abeer",
	journal = "JASA",
	keywords = "Age; sex; vowel dependencies acoustic measures related voice source",
	lockkey = "N",
	month = "april",
	note = "Department of Electrical Engineering, University of California Los Angeles, 405 Hilgard Avenue, Los Angeles, California 90095",
	owner = "degottex",
	pdf = "Iseli\_Shue\_Alwan\_JASA\_2007\_iseli07-jasa.pdf",
	timestamp = "2007.07.05",
	title = "{Age, sex, and vowel dependencies of acoustic measures related to the voice source}",
	year = "2007"
}

@article{Jarifi_Pastor_Rosec_EUSIPCO_2005,
	abstract = "In comparison with standard HMM (Hidden Markov Model) with forced alignment, this paper discusses two automatic segmentation algorithms from different points of view: the probabilities of insertion and omission, and the accuracy. The first algorithm, hereafter named the refined HMM algorithm, aims at refining the segmentation performed by standard HMM via a GMM (Gaussian Mixture Model) of each boundary. The second is the Brandt{\rq}s GLR (Generalized Likelihood Ratio) method. Its goal is to detect signal discontinuities. Provided that the sequence of speech units is known, the experimental results presented in this paper suggest in combining the refined HMM algorithm with Brandt{\rq}s GLR method and other algorithms adapted to the detection of boundaries between known acoustic classes.",
	author = "Jarifi, Safaa and Pastor, Dominique and Rosec, Olivier",
	journal = "EUSIPCO",
	keywords = "BRANDT GLR METHOD REFINED HMM SEGMENTATION TTS SYNTHESIS",
	lockkey = "N",
	note = "Ecole Nationale SupÃÅœerieure des TÃÅœelÃÅœecommunications de Bretagne, TechnopÃÂole Brest Iroise, 29238 Brest Cedex, France safaa.jarifi, dominique.pastor@enst-bretagne.fr France Telecom, R\&D Division TECH/SSTP/VMI 2, avenue Pierre Marzin, 22307 Lannion Cedex olivier.rosec@rd.francetelecom.com",
	owner = "degottex",
	pdf = "Jarifi\_Pastor\_Rosec\_EUSIPCO\_2005\_Brandt GLR method and Refined hmm segmentation for TTS synthesis application - cr1491.pdf",
	timestamp = "2007.07.05",
	title = "{BRANDT{\rq}S GLR METHOD \& REFINED HMM SEGMENTATION FOR TTS SYNTHESIS APPLICATION}",
	year = "2005"
}

@article{JARIFI_PASTOR_ROSEC_GRETSI_2005,
	abstract = "We compare the performance of two automatic segmentation algorithms. The Ã¯Â¬Ârst one is the so-called ``reÃ¯Â¬Âned HMM'' and aims at reÃ¯Â¬Âning the segmentation performed by Hidden Markov Models (HMM). The second is the Brandt{\rq}s GLR (Generalized Likelihood Ratio) algorithm. It detects speech signal discontinuities. The Ã¯Â¬Ârst method assumes the knowledge of the phonetic sequence whereas in the Brandt{\rq}GLR method, this constraint is not used. The reÃ¯Â¬Âned HMM yields no insertion and no omission in contrast with the Brandt{\rq}s GLR method. Hence, we generalize the notion of correct segmentation rate (CSR) so as to compare these algorithms. The experimental results given in this paper exhibit an upper limit for Brandt{\rq}s GLR method CSRs and suggest in combining the two methods with other algorithms adapted to the detection of boundaries between known acoustic classes.",
	author = "JARIFI, Safaa and PASTOR, Dominique and ROSEC, Olivier",
	journal = "GRETSI",
	keywords = "Mod{\`e}les GMM algorithme Brandt correction segmentation parole HMM",
	lockkey = "N",
	note = "1 DÃÅœ partement Signal et Communication e ENST Bretagne, TechnopÃÂ le Brest-Iroise, 29238 Brest, France o 2 France TÃÅœ lÃÅœ com, Division R\&D TECH/SSTP/VMI ee 2, avenue Pierre Marzin, 22307 Lannion Cedex, France safaa.jarifi@enst-bretagne.fr, dominique.pastor@enst-bretagne.fr olivier.rosec@francetelecom.fr",
	owner = "degottex",
	pdf = "JARIFI\_PASTOR\_ROSEC\_GRETSI\_2005\_articleGretsi2005\_final.pdf",
	timestamp = "2007.07.05",
	title = "{Mod{\`e}les GMM et algorithme de Brandt pour la correction de la segmentation de la parole par HMM}",
	year = "2005"
}

@inproceedings{Jiang_Murphy_DAFX_2001,
	abstract = "Much research has shown that the voice source has strong influence on the quality of speech processing [4][5][6]. But in most of the existing speech modification algorithms, the effect of the voice source variation is neglected. This work explains why the existing modification scheme can{\rq}t truly reflect the voice source variation during pitch modification. We use synthesized voiced speech sound to compare an existing pitch modification scheme with our proposed voice source scaling based modification scheme. Results show that voice source scaling based pitch modification can be used for wider range pitch modification.",
	author = "Jiang, Yinglong and Murphy, Peter",
	booktitle = "{DAFx}",
	journal = "DAFX",
	keywords = "speech pitch modification; voice source; formant synthesis",
	lockkey = "N",
	note = "Department of Electronic and Computer Engineering, University of Limerick, Limerick, Ireland *yinglong.jiang@ul.ie **peter.murphy@ul.ie",
	owner = "degottex",
	pdf = "Jiang\_Murphy\_DAFX\_2001\_YJiangDAFX01.pdf",
	timestamp = "2007.07.05",
	title = "{Voice source analysis for pitch-scale modification of speech signals}",
	year = 2001
}

@phdthesis{Kameoka_2007,
	abstract = "We deal through this paper with the problem of estimating ``information'' of each sound source separately from an acoustic signal of compound sound. Here ``information'' is used in a wide sense to include not only the waveform itself of the separate source signal but also the power spectrum, fundamental frequency (F0 ), spectral envelope and other features. Such a technique could be potentially useful for a wide range of applications such as robot auditory sensor, robust speech recognition, automatic transcription of music, waveform encoding for the audio CODEC (compression-decompression) system, a new equalizer system enabling bass and treble controls for separate source, and indexing of music for music retrieval system. [...]",
	author = "Kameoka, Hirokazu",
	keywords = "Statistical Approach Multipitch Analysis",
	lockkey = "N",
	owner = "degottex",
	pdf = "Kameoka\_2007\_DoctorThesis.pdf",
	timestamp = "2007.07.05",
	title = "{Statistical Approach to Multipitch Analysis}",
	year = "2007"
}

@other{Kawahara2000,
	author = "Kawahara, H.",
	booktitle = "{Acoustical Society of Japan}",
	lockkey = "N",
	owner = "degottex",
	timestamp = "2008.03.03",
	title = "{Vocal Fold and speech event detection using group delay}",
	year = "2000"
}

@article{Klapuri_ASPAA_1999,
	abstract = "A system for the detection of the pitch of musical sounds at a wide pitch range and in diverse conditions is presented. The sys- tem is built upon a pitch model that calculates independent pitch estimates in separate time-frequency windows and then combines them to yield a single estimate of the pitch. Both psychoacoustic and computational experiments were carried out to determine the optimal sizes of the elementary windows. The robustness of the system in wide-band additive noise and in the interference of another harmonic sound are demonstrated. An extension of the algorithm to the multi-pitch case is described, and simulation results for two-voice polyphonies are presented.1",
	author = "Klapuri, Anssi",
	journal = "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)",
	keywords = "PITCH MULTIPLE INDEPENDENT TIME-FREQUENCY WINDOWS",
	lockkey = "N",
	owner = "norwin",
	pdf = "Klapuri\_ASPAA\_1999\_pitch estimation - waspaa99.pdf",
	timestamp = "2007.07.06",
	title = "{PITCH ESTIMATION USING MULTIPLE INDEPENDENT TIME-FREQUENCY WINDOWS}",
	year = "1999"
}

@inproceedings{Klapuri_Virtanen_Holm_DAFX_2000,
	abstract = "A method for the estimation of the multiple pitches of concurrent musical sounds is described. Experimental data comprised sung vowels and the whole pitch range of 26 musical instruments. Mul- tipitch estimation was performed at the level of a single time frame for random pitch and sound source combinations. Note error rates for mixtures ranging from one to six simultaneous sounds were 2.1 \%, 2.4 \%, 3.8 \%, 8.1 \%, 12 \%, and 18 \%, respec- tively. In musical interval and chord identiÃ¯Â¬Âcation tasks, the algo- rithm outperformed the average of ten trained musicians. Particular emphasis was laid on robustness in the presence of other sounds and noise. The algorithm is based on an iterative estimation and separation procedure and is able to resolve at least a couple of most prominent pitches even in ten sound polypho- nies. Sounds that exhibit inharmonicities can be handled without problems, and the inharmonicity factor and spectral envelope of each sound is estimated along with the pitch. 
Examples are given of musical signal manipulations that become possible with the proposed method.",
	author = "Klapuri, Anssi and Virtanen, Tuomas and Holm, Jan-Markus",
	booktitle = "{DAFx}",
	journal = "DAFX",
	keywords = "ROBUST MULTIPITCH ESTIMATION ANALYSIS MANIPULATION POLYPHONIC MUSICAL SIGNALS",
	lockkey = "N",
	owner = "norwin",
	pdf = "Klapuri\_Virtanen\_Holm\_DAFX\_2000\_dafx2000.pdf",
	timestamp = "2007.07.06",
	title = "{ROBUST MULTIPITCH ESTIMATION FOR THE ANALYSIS AND MANIPULATION OF POLYPHONIC MUSICAL SIGNALS}",
	year = 2000
}

@article{Klapuri_SAP_2003,
	abstract = "A new method for estimating the fundamental frequencies of concurrent musical sounds is described. The method is based on an iterative approach, where the fundamental frequency of the most prominent sound is estimated, the sound is subtracted from the mixture, and the process is repeated for the residual signal. For the estimation stage, an algorithm is pro- posed which utilizes the frequency relationships of simultaneous spectral components, without assuming ideal harmonicity. For the subtraction stage, the spectral smoothness principle is proposed as an efficient new mechanism in estimating the spectral envelopes of detected sounds. With these techniques, multiple fundamental frequency estimation can be performed quite accurately in a single time frame, without the use of long-term temporal features. The experimental data comprised recorded samples of 30 musical instruments from four different sources. Multiple fundamental frequency estimation was performed for random sound source and pitch 
combinations. Error rates for mixtures ranging from one to six simultaneous sounds were 1.8\%, 3.9\%, 6.3\%, 9.9\%, 14\%, and 18\%, respectively. In musical interval and chord identification tasks, the algorithm outperformed the average of ten trained musicians. The method works robustly in noise, and is able to handle sounds that exhibit inharmonicities. The inharmonicity factor and spectral envelope of each sound is estimated along with the fundamental frequency.",
	author = "Klapuri, Anssi P.",
	journal = "SAP",
	keywords = "Acoustic signal analysis; fundamental frequency estimation; music; music transcription; pitch perception.",
	lockkey = "N",
	owner = "norwin",
	pdf = "Klapuri\_SAP\_2003\_multiplef0.pdf",
	timestamp = "2007.07.06",
	title = "{Multiple Fundamental Frequency Estimation Based on Harmonicity and Spectral Smoothness}",
	year = "2003"
}

@article{Klinker_IJCV_1990,
	author = "Klinker, G.J. and Shafer, S.A. and Kanade, T.",
	journal = "IJCV",
	lockkey = "N",
	owner = "degottex",
	pages = "7--38",
	timestamp = "2007.12.04",
	title = "{A Physical Approach to Color Image Understanding}",
	url = "http://citeseer.ist.psu.edu/klinker90physical.html",
	volume = "4",
	year = "1990"
}

@inproceedings{Kominek2003,
	abstract = "This report introduces the CMU Arctic databases designed for the purpose of speech synthesis research. These single speaker speech databases have been carefully recorded under studio conditions and consist of nearly 1150 phonetically balanced English utterances. They are distributed as free software, without restriction on commercial or non-commercial use. The Arctic corpus consists of four primary sets of recordings (3 male, 1 female), plus several ancillary databases. Each database is distributed with automatically segmented phonetic labels. These extra files were derived using the standard voice building scripts of the Festvox system. In addition to phonetic labels, the databases provide complete support for the Festival Speech Synthesis System, including pre-built voices that may be used as is. Festival and Festvox are available at http://www.festvox.org. The Arctic speech corpus is available at http://www.festvox.org/cmu\_arctic.",
	author = "Kominek, J. and Black, A. W.",
	booktitle = "{Proc. ISCA Speech Synthesis Workshop}",
	keywords = "CMU ARCTIC databases speech synthesis",
	lockkey = "Y",
	note = "http://www.festvox.org/cmu\_arctic",
	owner = "norwin",
	pages = "223--224",
	pdf = "Kominek\_Black\_ARCTIC\_2003\_cmu\_arctic\_report.pdf",
	timestamp = "2007.07.11",
	title = "{The {CMU} {ARCTIC} speech databases}",
	year = "2003"
}

@inproceedings{Kounoudes2002,
	abstract = "We present the DYPSA algorithm for automatic and reliable estimation of glottal closure instants (GCIs) in voiced speech. Reliable GCI estimation is essential for closed-phase speech analysis, from which can be derived features of the vocal tract and, separately, the voice source. It has been shown that such features can be used with significant advantages in applications such as speaker recognition. DYPSA is automatic and operates using the speech signal alone without the need for an EGG or Laryngograph signal. It incorporates a new technique for estimating GCI candidates and employs dynamic programming to select the most likely candidates according to a defined cost function. We review and evaluate three existing methods and compare our new algorithm to them. Results for DYPSA show GCI detection accuracy to within ÃÂ±0.25ms on 87\% of the test database and fewer than 1\% false alarms and misses.",
	author = "Kounoudes, A. and Naylor, P. A. and Brookes, M.",
	booktitle = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	comment = "Anastasis Kounoudes and Patrick A. Naylor and Mike Brookes",
	keywords = "DYPSA ALGORITHM GLOTTAL CLOSURE INSTANTS VOICED SPEECH",
	lockkey = "Y",
	timestamp = "2007.07.05",
	title = "{The {DYPSA} algorithm for estimation of glottal closure instants in voiced speech}",
	year = "2002"
}

@article{Krishnamurthy1981,
	author = "Krishnamurthy, A. and Childers, D.C.",
	journal = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	lockkey = "Y",
	owner = "norwin",
	timestamp = "2007.12.01",
	title = "{VOCAL FOLD VIBRATORY PATTERNS: COMPARISON OF FILM AND INVERSE FILTERING}",
	year = "1981"
}

@inproceedings{Laroche1999a,
	abstract = "The phase-vocoder is usually presented as a high-quality so- lution for time-scale modiÃ¯Â¬Âcation of signals, pitch-scale mod- iÃ¯Â¬Âcations usually being implemented as a combination of time- scaling and sampling rate conversion [1]. In this paper, we present two new phase-vocoder-based techniques which al- low direct manipulation of the signal in the frequency-domain, enabling such applications as pitch-shifting, chorusing, har- monizing, partial stretching and other exotic modiÃ¯Â¬Âcations which cannot be achieved by the standard time-scale sampling- rate conversion scheme. The new techniques are based on a very simple peak-detection stage, followed by a peak-shifting stage. The very simplest one allows for 50\% overlap but restricts the precision of the modiÃ¯Â¬Âcations, while the most Ã¯Â¬Âexible techniques requires a more expensive 75\% overlap.",
	author = "Laroche, J. and Dolson, M.",
	booktitle = "{IEEE Proc. Workshop on Applications of Signal Processing to Audio and Acoustics ({WASPAA})}",
	keywords = "PHASE VOCODER TECHNICS PITCH-SHIFTING HARMONIZING EXOTIC EFFECTS",
	lockkey = "Y",
	owner = "norwin",
	pages = "91--94",
	pdf = "Laroche\_Dolson\_ASPAA\_1999\_LaroD99-pvoc.pdf",
	timestamp = "2007.07.06",
	title = "{New phase-vocoder techniques for pitch-shifting, harmonizing and other exotic effects}",
	year = "1999"
}

@manual{Lefebvre2007,
	author = "LEFEBVRE, Doroth{\'e}e and L{\OE}VENBRUCK, H{\'e}l{\`e}ne and SAVARIAUX, Christophe",
	keywords = "TRAP",
	lockkey = "Y",
	note = "LOGICIEL DE TRAITEMENT DES SIGNAUX DE PAROLE",
	owner = "degottex",
	pdf = "LEFEBVRE\_L{\OE}VENBRUCK\_SAVARIAUX\_ICP\_2007\_guide\_util\_v5\_5.pdf",
	timestamp = "2007.07.05",
	title = "{TRAP LOGICIEL DE TRAITEMENT DES SIGNAUX DE PAROLE}",
	year = "2007"
}

@phdthesis{Lu2002,
	address = "USA",
	author = "Lu, Hui-Ling",
	keywords = "Toward High-quality Singing Synthesizer Vocal Texture Control LF voice",
	lockkey = "Y",
	owner = "norwin",
	pdf = "Lu\_PhD\_2002\_Toward a high-quality singing synthetizer with vocal texture control.pdf",
	school = "Stanford University",
	timestamp = "2007.07.06",
	title = "{Toward a High-quality Singing Synthesizer with Vocal Texture Control}",
	year = 2002
}

@article{Lu1999,
	abstract = "For singing synthesis applications, it is essential to generate natural voiced sound, since singing is nearly 95\% voiced [1]. In this paper, the linearly separable source-filter model is assumed for voiced sound. A convex optimization method is then applied to estimate the vocal tract filter and glottal source waveform jointly. The merits of using convex optimization methods are computational efficiency and global optimality. The final results show that the joint estimation is effective in conjunction with a smoothing constraint.",
	author = "Lu, H.-L. and III, J. O. Smith",
	journal = "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)",
	keywords = "Joint Estimation Vocal Tract Filter Glottal Source Waveform Convex Optimization",
	lockkey = "Y",
	note = "Center for Computer Research in Music and Acoustics (CCRMA) Stanford University, Stanford, CA94305, USA vickylu@ccrma.stanford.edu jos@ccrma.stanford.edu",
	owner = "degottex",
	pdf = "Lu\_Smith\_IEEEWASPAA\_1999\_HLLuWASPAA99.pdf",
	timestamp = "2007.07.05",
	title = "{Joint Estimation of Vocal Tract Filter and Glottal Source Waveform via Convex Optimization}",
	year = "1999"
}

@article{Martin_Kim_MASA_1998,
	abstract = "A statistical pattern-recognition technique was applied to the classification of musical instrument tones within a taxonomic hierarchy. Perceptually salient acoustic features--- related to the physical properties of source excitation and resonance structure---were measured from the output of an auditory model (the log-lag correlogram) for 1023 isolated tones over the full pitch ranges of 15 orchestral instruments. The data set included examples from the string (bowed and plucked), woodwind (single, double, and air reed), and brass families. Using 70\%/30\% splits between training and test data, maximum a posteriori classifiers were constructed based on Gaussian models arrived at through Fisher multiple- discriminant analysis. The classifiers distinguished transient from continuant tones with approximately 99\% correct performance. Instrument families were identified with approximately 90\% performance, and individual instruments were identified with an overall success rate of approximately 70\%. 
These preliminary analyses compare favorably with human performance on the same task and demonstrate the utility of the hierarchical approach to classification.",
	author = "Martin, Keith D. and Kim, Youngmoo E.",
	journal = "MASA",
	keywords = "Musical instrument identification pattern-recognition approach",
	lockkey = "N",
	note = "MIT Media Lab Machine Listening Group Rm. E15-401, 20 Ames St., Cambridge, MA 02139",
	owner = "degottex",
	pdf = "Martin\_Kim\_MASA\_1998\_kdm-asa98.pdf",
	timestamp = "2007.07.05",
	title = "{Musical instrument identification: A pattern-recognition approach}",
	year = "1998"
}

@article{Mattheyses_Verhelst_Verhoeve_SPS-DARTS_2006,
	abstract = "TD-PSOLA is a well-known technique for prosodic modiÃ¯Â¬Âca- tion of speech signals, especially for pitch shifting and time scal- ing. The quality of the modiÃ¯Â¬Âcation results can be very high, but critically depends on the determination of the individual pitch periods (epochs) in the speech signal. As speech is a naturally produced signal, the robust estimation of pitch epochs thus be- comes extremely important for TD-PSOLA applications, espe- cially where real-time operation is required. This paper pro- poses an efÃ¯Â¬Âcient algorithm for robust pitch epoch detection that is amenable for real-time implementations.",
	author = "Mattheyses, Wesley and Verhelst, Werner and Verhoeve, Piet",
	journal = "SPS-DARTS",
	keywords = "ROBUST PITCH MARKING PROSODIC MODIFICATION SPEECH TD-PSOLA",
	lockkey = "N",
	owner = "norwin",
	pdf = "Mattheyses\_Verhelst\_Verhoeve\_SPS-DARTS\_2006.pdf",
	timestamp = "2007.07.06",
	title = "{ROBUST PITCH MARKING FOR PROSODIC MODIFICATION OF SPEECH USING TD-PSOLA}",
	year = "2006"
}

@article{McKenna_Isard_EURO_1999,
	abstract = "This paper describes a method for obtaining smoothed vocal tract parameters from analysis during the closed phase of the glottis. The method is based upon Expectation Maximisa- tion (EM) and uses Kalman-Rauch forward-backward iterations through a voiced segment, in which the speech data during exci- tation and open phases are excluded by treating them as {\lq}missing data{\rq}. This approach exploits the non-independence of neighbour- ing spectra and compensates for small numbers of available points, while preserving speaker-characteristic information and tracking variations in it. The vocal tract Ã¯Â¬Âlter parameters are then used for inverse Ã¯Â¬Âltering the speech, thus obtaining estimates of the source exci- tation. The extracted excitation signal can be used to excite other sets of parameters to produce natural sounding speech.",
	author = "McKenna, John and Isard, Stephen",
	journal = "EURO",
	keywords = "TAILORING KALMAN FILTERING SPEAKER CHARACTERISATION",
	lockkey = "N",
	owner = "norwin",
	pdf = "McKenna\_Isard\_EURO\_1999\_McKennaEURO99.pdf",
	timestamp = "2007.07.06",
	title = "{TAILORING KALMAN FILTERING TOWARDS SPEAKER CHARACTERISATION}",
	year = "1999"
}

@article{MergellP2000,
	abstract = "Direct observations of nonstationary asymmetric vocal-fold oscillations are reported. Complex time series of the left and the right vocal-fold vibrations are extracted from digital high-speed image sequences separately. The dynamics of the corresponding high-speed glottograms reveals transitions between low-dimensional attractors such as subharmonic and quasiperiodic oscillations. The spectral components of either oscillation are given by positive linear combinations of two fundamental frequencies. Their ratio is determined from the high-speed sequences and is used as a parameter of laryngeal asymmetry in model calculations. The parameters of a simpliÃ¯Â¬Âed asymmetric two-mass model of the larynx are preset by using experimental data. Its bifurcation structure is explored in order to Ã¯Â¬Ât simulations to the observed time series. Appropriate parameter settings allow the reproduction of time series and differentiated amplitude contours with quantitative agreement. In particular, several phase-
locked episodes ranging from 4:5 to 2:3 rhythms are generated realistically with the model.",
	author = "Mergell, Patrick and Herzel, Hanspeter and Titze, Ingo R.",
	doi = "10.1121/1.1314398",
	journal = "Journal of the Acoustical Society of America",
	keywords = "speech; time series; oscillations; vibrations; bifurcation; biomechanics",
	lockkey = "Y",
	number = "6",
	pages = "2996--3002",
	publisher = "ASA",
	title = "{Irregular vocal-fold vibration---High-speed observation and modeling}",
	url = "http://link.aip.org/link/?JAS/108/2996/1",
	volume = "108",
	year = "2000"
}

@article{MergellP1998,
	abstract = "Phonation onset is discussed in the framework of dynamical systems as a Hopf bifurcation, i.e., as a transition from damped to sustained vocal fold oscillations due to changes of parameters deÃ¯Â¬Âning the underlying laryngeal conÃ¯Â¬Âguration e.g., adduction, subglottal pressure, muscular activity . An analytic envelope curve of the oscillation onset is deduced by analyzing the Hopf bifurcation in mathematical models of the vocal folds. It is governed by a single time constant which can be identiÃ¯Â¬Âed with the physiological parameter phonation onset time. This parameter reÃ¯Â¬Âects the laryngeal state prior to phonation and can be used as a quantitative classiÃ¯Â¬Âcation criterion in order to assess the phonation onset in clinical diagnosis. The extraction of the phonation onset time from simulated time series using a simpliÃ¯Â¬Âed two-mass model and from digital high-speed videos is described in detail. It shows a good agreement between theory and measurement. ÃÂ© 1998 Acoustical 
Society of America. S0001-4966 98 06106-2",
	author = "Mergell, P. and Herzelb, H. and Wittenberg, T. and Tigges, M. and Eysholdte, U.",
	journal = "JASA",
	lockkey = "Y",
	owner = "degottex",
	timestamp = "2007.11.27",
	title = "{Phonation onset: Vocal fold modeling and high-speed glottography}",
	year = "1998"
}

@misc{MiddletonG2003,
	abstract = "An algorithm for modifying the pitch of a solo human voice in the frequency domain.",
	author = "Middleton, Gareth",
	keywords = "Frequency Domain Pitch Correction",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Middleton2\_ConModule\_2003\_m11715.pdf",
	timestamp = "2007.07.05",
	title = "{Frequency Domain Pitch Correction}",
	year = "2003"
}

@misc{Middleton_ConModule_2003,
	abstract = "Two algorithms operating in the time domain to change the pitch of solo human voice.",
	author = "Middleton, Gareth",
	comment = "Connexions module",
	keywords = "Time Domain Pitch Correction",
	lockkey = "N",
	note = "Connexions module",
	owner = "norwin",
	pdf = "Middleton\_ConModule\_2003\_m117112.pdf",
	timestamp = "2007.07.05",
	title = "{Time Domain Pitch Correction}",
	year = "2003"
}

@techreport{ITURBS15342003,
	author = "Assembly, The ITU Radiocommunication",
	institution = "ITU",
	title = "{ITU-R BS.1534: Method for the subjective assessment of intermediate quality levels of coding systems}",
	year = "2003"
}

@article{Miranda_Vocoder_2000,
	abstract = "In this paper we explain how we are improving the source component of a source-filter vocal synthesis system. Our strategy for this improvement involves the replacement of the pulse generator by a phase vocoder module whose coefficients are derived from the analysis of speech signals. Firstly, we introduce the context of our research and then indicate the problem; finally, we present our solution followed by our conclusions and suggestions for further work.",
	author = "Miranda, Eduardo Reck",
	keywords = "Phase Vocoder Model Glottis Expressive Voice Synthesis",
	lockkey = "N",
	owner = "norwin",
	pdf = "Miranda\_Vocoder\_2000\_miranda-glottis1999.pdf",
	timestamp = "2007.07.06",
	title = "{A Phase Vocoder Model of the Glottis for Expressive Voice Synthesis}",
	year = "2000"
}

@article{Murthy_IEEE_1989a,
	author = "Murthy",
	journal = "IEEE",
	lockkey = "N",
	note = "voir notes du 9.3.07",
	owner = "degottex",
	pdf = "Murthy\_IEEE\_1989a\_Formant\_Extraction\_from\_Phase\_Weigthed\_Group\_Delay\_Function.pdf",
	timestamp = "2007.03.01",
	title = "{Formant\_Extraction\_from\_Phase\_Weigthed\_Group\_Delay\_Function}",
	year = "1989"
}

@article{Murthy_IEEE_1989b,
	author = "Murthy",
	journal = "IEEE",
	lockkey = "N",
	owner = "degottex",
	pdf = "Murthy\_IEEE\_1989b\_non\_parametric\_method\_using\_group\_delay\_function.pdf",
	timestamp = "2007.03.01",
	title = "{non\_parametric\_method\_using\_group\_delay\_function}",
	year = "1989"
}

@article{Murthy_ICASSP_2003,
	abstract = "We explore a new spectral representation of speech signals through group delay functions. The group delay functions by themselves are noisy and difficult to interpret owing to zeroes that are close to the unit circle in the z-domain and these clutter the spectra. A new modified group delay function [1] that reduces the effects of zeroes close to the unit circle is used. Assuming that this new function is minimum phase, the modified group delay spectrum is converted to a sequence of cepstral coefficients. A preliminary phoneme recogniser is built using features derived from these cepstra. Results are compared with those obtained from features derived from the traditional mel frequency cepstral coefficients (MFCC). The baseline MFCC performance is 34.7\%, while that of the best modified group delay cepstrum is 39.2\%. The performance of the composite MFCC feature, which includes the derivatives and double derivatives, is 60.7\%, while that of the composite modified group delay feature is 57.3\%. 
When these two composite features are combined,  2\% improvement in performance is achieved (62.8\%). When this new system is combined with linear frequency cepstra (LFC) [2], the system performance results in another  0.8\% improvement (63.6\%).",
	author = "Murthy, Hema A and Gadde, Venkata Ramana Rao",
	journal = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	lockkey = "N",
	owner = "degottex",
	pdf = "Murthy\_ICASSP\_2003\_modified\_Group\_Delay\_Function\_ASR.pdf",
	timestamp = "2007.03.01",
	title = "{THE MODIFIED GROUP DELAY FUNCTION AND ITS APPLICATION TO PHONEME RECOGNITION}",
	year = "2003"
}

@article{Murthy_Yegnanarayana_Formant_1991,
	abstract = "This paper presents an approach based on the properties of group delay functions for extracting formants from speech signals. The algorithm is similar to the cepstral smoothing approach for formant extraction using homomorphic deconvolution. The significant differences are (i) the logarithmic operation is replaced by ()' operation and (ii) the additive and high resolution properties of group delay functions are exploited to emphasize formant peaks. The group delay function (or the negative derivative of the Fourier transform phase) is derived for a signal which in turn is derived from the Fourier transform magnitude of the speech signal. If a suitable value of r is used, this method gives highly consistent estimates of formants compared to both the cepstral approach and the model-based linear prediction (LP) approach for smoothing the magnitude spectrum. The effects of the parameters, exponent r and window width p, on the proposed technique for formant extraction are studied.",
	author = "Murthy, Hema A. and Yegnanarayana, B.",
	journal = "Elsevier",
	keywords = "Fourier transform phase; spectral root cepstrum; group delay functions; formant extraction",
	lockkey = "N",
	note = "Department o f Computer Science and Engineering, Indian Institute o f Technology, Madras - 600 036, India",
	owner = "degottex",
	pages = "209--221",
	pdf = "Murthy\_Yegnanarayana\_Elsevier\_1991\_ormant extraction from group delay function.pdf",
	timestamp = "2007.07.05",
	title = "{Formant extraction from group delay function}",
	year = "1991"
}

@article{MurthyHA1991,
	abstract = "In this paper we demonstrate the feasibility of processing the Fourier transform (FT) phase of a speeech signal to derive the smooth log magnitude spectrum corresponding to the vocal tract system. We exploit the additive property of the group delay function (negative derivative of the FT phase) to process the FT phase. We show that the rapid fluctuations in the log magnitude spectrum and the group delay function are caused by the zeroes of the z-transform of the excitation components of the speech signal. Zeroes close to the unit circle in the z-plane produce large amplitude spikes in the group delay function and mask the group delay information corresponding to the vocal tract system. We propose a technique to extract the vocal tract system component of the group delay function by using the spectral properties of the excitation signal.",
	author = "Murthy, Hema A. and Yegnanarayana, B.",
	journal = "Elsevier Signal Processing",
	keywords = "Fourier transform phase; group delay functions; speech processing; formants.",
	lockkey = "Y",
	note = "Department of Computer Science and Engineering, Indian Institute of Technology, Madras-600 036, India.",
	owner = "degottex",
	pages = "259--267",
	pdf = "Murthy\_Yegnanarayana\_GroupDelay\_1991\_Speech processing using group delay functions.pdf",
	timestamp = "2007.03.06",
	title = "{Speech processing using group delay functions}",
	volume = "22",
	year = "1991"
}

@article{Nakatani_Irino_ICSLP_2002,
	abstract = "This paper presents a new method for robust fundamental fre- quency ( ÃÅ ) estimation in the presence of background noise and spectral distortion. We deÃ¯Â¬Âne degree of dominance and a domi- nance spectrum based on instantaneous frequencies. The degree of dominance allows us to evaluate the magnitude of individual har- monic components of speech signals relative to background noise while eliminating the inÃ¯Â¬Âuence of spectral distortion. The fun- damental frequency is robustly estimated from reliable harmonic components easily selected from the dominance spectra. Experi- ments are performed using white and multi-talker background noise with and without spectral distortion produced by a SRAEN Ã¯Â¬Âlter. Results show that the present method is better than the commonly- used methods in terms of correct ÃÅ rates.",
	author = "Nakatani, Tomohiro and Irino, Toshio",
	journal = "ICSLP",
	keywords = "ROBUST FUNDAMENTAL FREQUENCY ESTIMATION AGAINST BACKGROUND NOISE SPECTRAL DISTORTION",
	lockkey = "N",
	owner = "norwin",
	pdf = "Nakatani\_Irino\_ICSLP\_2002\_icslp2002f0.pdf",
	timestamp = "2007.07.06",
	title = "{ROBUST FUNDAMENTAL FREQUENCY ESTIMATION AGAINST BACKGROUND NOISE AND SPECTRAL DISTORTION}",
	year = "2002"
}

@article{NeubauerJ2001,
	abstract = "This report is on direct observation and modal analysis of irregular spatio-temporal vibration patterns of vocal fold pathologies in vivo. The observed oscillation patterns are described quantitatively with multiline kymograms, spectral analysis, and spatio-temporal plots. The complex spatio-temporal vibration patterns are decomposed by empirical orthogonal functions into independent vibratory modes. It is shown quantitatively that biphonation can be induced either by left--right asymmetry or by desynchronized anterior--posterior vibratory modes, and the term {\lq}{\lq}AP anterior--posterior biphonation{\rq}{\rq} is introduced. The presented phonation examples show that for normal phonation the Ã¯Â¬Ârst two modes sufÃ¯Â¬Âciently explain the glottal dynamics. The spatio-temporal oscillation pattern associated with biphonation due to left--right asymmetry can be explained by the Ã¯Â¬Ârst three modes. Higher-order modes are required to describe the pattern for biphonation induced by anterior--
posterior vibrations. Spatial irregularity is quantiÃ¯Â¬Âed by an entropy measure, which is signiÃ¯Â¬Âcantly higher for irregular phonation than for normal phonation. Two asymmetry measures are introduced: the left--right asymmetry and the anterior--posterior asymmetry, as the ratios of the fundamental frequencies of left and right vocal fold and of anterior--posterior modes, respectively. These quantities clearly differentiate between left--right biphonation and anterior--posterior biphonation. This paper proposes methods to analyze quantitatively irregular vocal fold contour patterns in vivo and complements previous Ã¯Â¬Ândings of desynchronization of vibration modes in computer modes and in in vitro experiments.",
	author = "Neubauer, J. and Mergell, P. and Eysholdt, U. and Herzel, H.",
	doi = "10.1121/1.1406498",
	journal = "Journal of the Acoustical Society of America",
	keywords = "modal analysis; spectral analysis; oscillations; vibrations; speech",
	lockkey = "Y",
	number = "6",
	pages = "3179--3192",
	publisher = "ASA",
	title = "{Spatio-temporal analysis of irregular vocal fold oscillations: Biphonation due to desynchronization of spatial modes}",
	url = "http://link.aip.org/link/?JAS/110/3179/1",
	volume = "110",
	year = "2001"
}

@mastersthesis{Obin_UPMC_2005,
	abstract = "Notre rapport traite du sujet de l{\rq}estimation de la fr{\'e}quence fondamentale dans le cas de signaux musicaux monophoniques. Nous y proposons une nouvelle m{\'e}thode d{\rq}estimation pour des signaux pseudo harmoniques bas{\'e}e sur le mod{\`e}le sous harmonique de Terhardt ainsi que sur une m{\'e}thode d{\rq}optimisation des moindres carr{\'e}s avec convergence de Newton. Nous avons test{\'e} notre algorithme sur une large base de donn{\'e}es de piano, et avons obtenu des r{\'e}sultats prometteurs. Par ailleurs nous sommes {\`a} l{\rq}origine de l{\rq}{\'e}valuation de plusieurs algorithmes d{\rq}estimation de la fr{\'e}quence fondamentale sur une large base de donn{\'e}es monophonique, {\'e}valuation qui a mis en valeur les performances de l{\rq}algorithme YIN.",
	author = "Obin, Nicolas",
	keywords = "f0 fundamental frequency music",
	lockkey = "N",
	month = "july",
	owner = "degottex",
	pdf = "Obin\_UPMC\_2005\_ReportPitchEstimationv1.3.pdf",
	school = "UPMC",
	timestamp = "2007.03.05",
	title = "{Evaluation des algorithmes d'estimation de la frequence fondamentale dans le cadre de signaux musicaux monophoniques}",
	type = "stage Repport",
	year = "2005"
}

@misc{ParkS2006,
	abstract = "In a variety of applications, it is desirable to compress a speech signal for efficient transmission or storage. For example, to accommodate many speech signals in a given bandwidth of a cellular phone system, each digitized speech signal is compressed before transmission. In the case of a digital answering machine, to save a memory space, a message is digitized and compressed. For medium or low bit-rate speech coders, linear predictive coding (LPC) is most widely used. Redundancy in a speech signal is removed by passing the signal through a speech analysis filter. The output of the filter, termed the residual error signal, has less redundancy than original speech signal and can be quantized by smaller number of bits than the original speech. The residual error signal along with the filter coefficients are transmitted to the receiver. At the receiver, the speech is reconstructed by passing the residual error signal through the synthesis filter. To model a human speech production system, all-pole 
model (also known as the linear prediction model) is used. In this chapter, human speech production system, spectrogram, speech analysis and speech synthesis using linear prediction are explained.",
	author = "Park, Sung",
	keywords = "Linear Predictive Speech Processing LPC",
	lockkey = "Y",
	owner = "norwin",
	pdf = "Park\_LPC\_2006\_LP for speech processing - chap7.pdf",
	timestamp = "2007.07.06",
	title = "{Linear Predictive Speech Processing}",
	year = "2006"
}

@phdthesis{Peeters2001,
	abstract = "The purpose of this research is to develop a method for the modification of the sound signal, using signal models adapted to the local characteristics of the signal. With this end in view, we study two models of signal representation, each one corresponding to a different interpretation of a sound signal : temporal decomposition of the signal into elementary waveforms - interpretation, in the case of a periodic signal, in terms of temporal repetition of quasi-identical waveforms -, and signal representation by a sum of time-variable sinusoidal components - interpretation in term of harmonic relations between its frequential components -. The originality of our method consists in taking benefit of each model for the signal class for which the model is best suited. This hybrid method requires estimating the parameters of each of the two models (waveforms localization, fundamental frequency, frequency, amplitude and phase of the spectral components) as well as a set of characteristics allowing the 
choice of the best-suited model represent a given time/frequency region (singularity of the waveforms, modelization error, specification error, harmonicity, voicing). New estimators are proposed and we show the relevance of phase information for the sake of estimation. In each case, the proposed estimators are compared with the commonly used ones. The signal modification methods associated with these two models are the PSOLA (Pitch Synchronous Overlap-Add) method and the sinusoidal additive synthesis. Signal modification possibilities of each of these methods are studied and improvements are proposed, especially concerning the consideration of phase relations during signal modifications. The two models are then used in a new hybrid method to modify the signal (SINOLA), which assigns to each time/frequency region the best-suited model for its representation and its modification.",
	address = "France",
	author = "Peeters, G.",
	keywords = "computer music; PSOLA; sinusoidal analysis/synthesis; phase; group delay; estimation; speech",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Peeters\_UPMC\_2001\_PhDThesisv1.1.pdf",
	school = "UPMC, in french",
	timestamp = "2007.03.05",
	title = "{Modeles et modification du signal sonore adaptees a ses caracteristiques locales}",
	year = "2001"
}

@other{Peeters1999,
	author = "Peeters, G. and Rodet, X.",
	booktitle = "{Proc. Int. Congr. Signal Proc. Applic. and Tech.}",
	lockkey = "Y",
	owner = "degottex",
	timestamp = "2008.03.03",
	title = "{Non-Stationary Analysis/Synthesis using Spectrum Peak Shape Distortion, Phase and Reassigned Spectrum}",
	year = "1999"
}

@misc{Peeters1999b,
	abstract = "In this paper we present a new Analysis/Synthesis method namedSINOLA, which benefits from both sinusoidal additive model and OLA/PSOLA method, and which allows adequate processing according to the inherent local characteristics of the signal. All the parameters of the models are derived at the same time from spectrum analysis. We propose an analytical formulation of a Complex Short-Time Spectrum Distortion measure, which allows the retrieval of precise sinusoidal parameters as well as their slopes. A new partial tracking method is proposed which benefits from these informations. Reassigned Spectrum is used in both time and frequency in order to characterize the signal and to position the PSOLA markers. Introduction Sinusoidal additive Analysis/Synthesis (A/S) is extremely accurate for signals which can be considered as a sum of sinusoids with stationary parameters in a window of 3 to 4 fundamental periods. On the other side, Time-Domain Overlap-Add (TD-OLA) and TDPitch -Synchro...",
	annote = "Geoffroy Peeters (Ircam - Centre Georges-Pompidou Analysis/Synthesis Team; 1 , pl. Igor Stravinsky , 75004 Paris , France); Xavier Rodet (Ircam - Centre Georges-Pompidou Analysis/Synthesis Team; 1 , pl. Igor Stravinsky , 75004 Paris , France);",
	author = "Peeters, Geoffroy and Rodet, Xavier",
	file = "FFFFFF",
	journal = "Proc. Int. Congr. Signal Proc. Applic. and Tech",
	lockkey = "Y",
	owner = "degottex",
	timestamp = "2008.03.03",
	title = "{SINOLA: A New Analysis/Synthesis Method using Spectrum Peak Shape Distortion, Phase and Reassigned Spectrum}",
	url = "http://citeseer.ist.psu.edu/296830.html; http://www.ircam.fr/equipes/analyse-synthese/listePublications/articlesRodet/ICMC99/SINOLA.ps",
	year = "1999"
}

@misc{Petersen_Pedersen_Matrix_2007,
	abstract = "These pages are a collection of facts (identities, approxima- tions, inequalities, relations, ...) about matrices and matters relating to them. It is collected in this form for the convenience of anyone who wants a quick desktop reference .",
	author = "Petersen, Kaare Brandt and Pedersen, Michael Syskind",
	keywords = "Matrix algebra; matrix relations; matrix identities; derivative of determinant; derivative of inverse matrix; diÃ¯Â¬Âerentiate a matrix.",
	lockkey = "N",
	owner = "norwin",
	pdf = "Petersen\_Pedersen\_Matrix\_2007\_Matrix Cookbook.imm3274.pdf",
	timestamp = "2007.07.06",
	title = "{The Matrix Cookbook}",
	year = "2007"
}

@inproceedings{LCAV-CONF-2006-029,
	affiliation = "OTHER",
	author = "Pinto, F and Rocha, A and Leite, A and Ferreira, A",
	booktitle = "{120{t}h {AES} {C}onvention}",
	details = "http://infoscience.epfl.ch/search.py?recid=97148",
	documenturl = "http://infoscience.epfl.ch/getfile.py?recid=97148\&mode=best",
	location = "Paris - France",
	lockkey = "N",
	oai-id = "oai:infoscience.epfl.ch:97148",
	oai-set = "conf",
	owner = "norwin",
	pdf = "LCAV-CONF-2006-029\_AES120-000304.pdf",
	review = "NON-REVIEWED",
	status = "PUBLISHED",
	timestamp = "2007.07.06",
	title = "{Adaptive {A}udio {E}qualization of {R}ooms based on a {T}echnique of {T}ransparent {I}nsertion of {A}coustic {P}robe {S}ignals}",
	unit = "LCAV",
	year = "2006"
}

@article{Puckette_Brown_SAP_1998,
	abstract = "The phase vocoder is a well-known technique for dividing an audio signal into time-varying sinusoidal components and estimating their frequencies and amplitudes. The accuracy of the frequency estimates is studied here by predicting, and then measuring experimentally, the magnitude of errors due to two factors: 1) interference between different components, and 2) interference due to the presence of noise in the signal. The magnitude of the error depends on the relative amplitudes of the component in question and the disturbing signal, on the size and spacing of the analysis windows, on the window function used, and, in the case where the disturbance is due to another sinusoidal component, on the phase difference between the two. The implications of these results for choosing analysis parameters are discussed. The case of a one-sample spacing between analysis windows is treated in detail. Finally, we compare the phase vocoder with the maximum likelihood frequency estimator.",
	author = "Puckette, Miller S. and Brown, Judith C.",
	journal = "SAP",
	keywords = "Accuracy Frequency Estimates Phase Vocoder",
	lockkey = "N",
	owner = "norwin",
	pdf = "Puckette\_Brown\_SAP\_1998\_pvocWmiller00661475.pdf",
	timestamp = "2007.07.06",
	title = "{Accuracy of Frequency Estimates Using the Phase Vocoder}",
	year = "1998"
}

@mastersthesis{PulakkaH2005,
	abstract = "Human voice production was studied using three methods: inverse Ã¯Â¬Âltering, digital high-speed imaging of the vocal folds, and electroglottography. The primary goal was to evaluate an inverse Ã¯Â¬Âltering method by comparing inverse Ã¯Â¬Âltered glottal Ã¯Â¬Âow estimates with information obtained by the other methods. More detailed examination of the human voice source behavior was also included in the work. Material from two experiments was analyzed in this study. The data of the Ã¯Â¬Ârst experiment consisted of simultaneous recordings of acoustic speech signal, electroglottogram, and high-speed imaging acquired during sustained vowel phonations. Inverse Ã¯Â¬Âltered glottal Ã¯Â¬Âow estimates were compared with glottal area waveforms derived from the image material by calculating pulse shape parameters from the signals. The material of the second experiment included recordings of acoustic speech signal and electroglottogram during phonations of sustained vowels. This mate- rial was 
utilized for the analysis of the opening phase and the closing phase of vocal fold vibration. The evaluated inverse Ã¯Â¬Âltering method was found to produce mostly reasonable estimates of glottal Ã¯Â¬Âow. However, the parameters of the system have to be set appropriately, which requires experience on inverse Ã¯Â¬Âltering and speech production. The Ã¯Â¬Âow estimates often showed a two-stage opening phase with two instants of rapid increase in the Ã¯Â¬Âow derivative. The instant of glottal opening detected in the electroglottogram was often found to coincide with an increase in the Ã¯Â¬Âow derivative. The instant of minimum Ã¯Â¬Âow derivative was found to occur mostly during the last quarter of the closing phase and it was shown to precede the closing peak of the differentiated electroglottogram.",
	address = "Finland",
	author = "Pulakka, H.",
	comment = "Department Of Computer Science And Engineering",
	keywords = "speech production; glottal Ã¯Â¬Âow; vocal fold vibration; digital high-speed imaging; inverse Ã¯Â¬Âltering; electroglottography",
	lockkey = "Y",
	owner = "norwin",
	pdf = "Pulakka\_VoiceProduction\_2005\_pulakka\_mst.pdf",
	school = "Helsinki University of Technology",
	timestamp = "2007.07.06",
	title = "{Analysis of Human Voice Production Using Inverse Filtering, High-Speed Imaging, and Electroglottography}",
	year = "2005"
}

@inproceedings{Perez2005,
	abstract = "We present here our work in automatic parameterization of nat- ural speech by means of a pitch synchronous source-Ã¯Â¬Âlter de- composition algorithm. The derivative glottal source is mod- elled using the Liljencrants-Fant (LF) model. The model pa- rameters are obtained simultaneously with the coefÃ¯Â¬Âcients of an all-pole Ã¯Â¬Âlter representing the vocal tract response by means of a quadratic programming algorithm. Synthetic data has been created and analyzed in order to show the appropriate function of the estimation method. The parameterization results in high quality synthesized speech for voiced frames. Voice quality ex- traction is performed on basis to the LF source representation. The inherent modelling of the voice source makes it suitable for voice modiÃ¯Â¬Âcation tasks. Work is in progress to add this speech representation to emotional speech synthesis and voice conver- sion algorithms.",
	author = "Perez, J. and Bonafonte, A.",
	booktitle = "{Proc. Interspeech}",
	comment = "je vois pas ce que \c{c}a apporte par rapport {\`a} Lu",
	keywords = "Automatic Voice-Source Parameterization Natural Speech",
	lockkey = "Y",
	note = "Department of Signal Theory and Communication TALP Research Center Technical University of Catalonia (UPC), Barcelona, Spain {javierp,antonio}@gps.tsc.upc.edu",
	owner = "degottex",
	pages = "1065--1068",
	pdf = "Perez\_Bonafonte\_INTERSPEECH\_2005\_perez\_\_interspeech\_2005.pdf",
	timestamp = "2007.07.05",
	title = "{Automatic Voice-Source Parameterization of Natural Speech}",
	year = 2005
}

@misc{Rabatel_2003,
	abstract = "La r{\'e}alisation d{\rq}un programme permettant la reconnaissance de notes musicales fond{\'e}e sur la transform{\'e}e de Fourier ne permet pas d{\rq}obtenir des r{\'e}sultats probants. Un autre outil math{\'e}matique, la transform{\'e}e en ondelette, semble mieux adapt{\'e}e {\`a} ce type de probl{\`e}me. La premi{\`e}re partie de notre projet se concentre sur l{\rq}analyse et la compr{\'e}hension globale (``< intuitive ''>) du fonctionnement de cette transform{\'e}e. La deuxi{\`e}me partie {\'e}tudie l{\rq}analyse d{\rq}un son et l{\rq}application de la transform{\'e}e en ondelette sur celui-ci.",
	author = "Rabatel, Laurent",
	keywords = "Reconnaissance note musique transformee ondelette wavelet",
	lockkey = "N",
	owner = "degottex",
	pdf = "Rabatel\_2003\_Reconnaissance de note de musique par transformee en ondelette.pdf",
	timestamp = "2007.07.05",
	title = "{Reconnaissance de note de musique par transformee en ondelette}",
	year = "2003"
}

@misc{Rendas_2006,
	abstract = "Tests d'hypoth{\`e}ses. Tests de Bayes. Rapport de Vraisemblance. Statistique suffisante. Tests de Neyman-Pearson. ROC. Tests simples et compos{\'e}s. Tests UMP. Rapport de Vraisemblance G{\'e}n{\'e}ralis{\'e}. D{\'e}tection d'un signal dans un bruit: le filtre adapt{\'e}.",
	author = "Rendas, Joao",
	keywords = "Tests d'hypoth{\`e}ses. Tests de Bayes. Rapport de Vraisemblance. Statistique suffisante. Tests de Neyman-Pearson. ROC. Tests simples et compos{\'e}s. Tests UMP. Rapport de Vraisemblance G{\'e}n{\'e}ralis{\'e}. D{\'e}tection d'un signal dans un bruit: le filtre adapt{\'e}.",
	lockkey = "N",
	owner = "degottex",
	pdf = "Rendas\_2006\_TSSTDEC.pdf",
	timestamp = "2007.07.05",
	title = "{Th{\'e}orie de la D{\'e}cision}",
	year = "2006"
}

@misc{Roebel2006,
	author = "Roebel, A.",
	keywords = "spectral envelop",
	lockkey = "Y",
	note = "lecture slides",
	owner = "degottex",
	pdf = "Robel\_IRCAM\_2006\_VL4.pdf",
	timestamp = "2007.03.01",
	title = "{Source filter modeling and spectral envelope estimation}",
	year = "2006"
}

@inproceedings{Roebel2005,
	abstract = "In this article the estimation of the spectral envelope of sound signals is addressed. The intended application for the developed algorithm is pitch shifting with preservation of the spectral envelope in the phase vocoder. As a first step the different existing envelope estimation algorithms are investigated and their specific properties discussed. As the most promising algorithm the cepstrum based iterative true envelope estimator is selected. By means of controlled sub-sampling of the log amplitude spectrum and by means of a simple step size control for the iterative algorithm the run time of the algorithm can be decreased by a factor of 2.5-11. As a remedy for the ringing effects in the the spectral envelope that are due to the rectangular filter used for spectral smoothing we propose the use of a Hamming window as smoothing filter. The resulting implementation of the algorithm has slightly increased computational complexity compared to the standard LPC algorithm but offers significantly 
improved control over the envelope characteristics. The application of the true envelope estimator in a pitch shifting application is investigated. The main problems for pitch shifting with envelope preservation in a phase vocoder are identified and a simple yet efficient remedy is proposed.",
	author = "Roebel, A. and Rodet, X.",
	booktitle = "{Proc. Digital Audio Effects (DAFx)}",
	journal = "DAFX",
	keywords = "true envelope",
	lockkey = "Y",
	owner = "degottex",
	pages = "30--35",
	pdf = "Robel\_Rodet\_DAFX\_2005\_trueenv\_dafx2005.pdf",
	timestamp = "2007.03.22",
	title = "{Efficient Spectral Envelope Estimation And Its Application To Pitch Shifting And Envelope Preservation}",
	year = 2005
}

@article{Roebel2005a,
	abstract = "The following article presents a new real time implementation of an iterative cepstrum based spectral envelope estimation technique that was originally published under the name true envelope. Because the original algorithm is hardly known outside Japan we will first describe the algorithm and compare it to the standard techniques, i.e. LPC and discrete cepstrum. The estimation properties are compared and it is shown that the true envelope estimator achieves convincing envelope estimations even for problematic, high pitch signals. The algorithm is analyzed with the objective to find an efficient implementation that sufficiently reduces the computational complexity such that the algorithm can be used in real time within the phase vocoder. The implementation that is presented reduces the run time required by the algorithm depending on the cepstral order on the estimation parameters by a factor of 2 to 9 such that real time processing becomes feasible.",
	author = "Roebel, A. and Rodet, X.",
	journal = "ICMC",
	keywords = "true envelope",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Robel\_Rodet\_ICMC\_2005\_trueenv\_icmc2005.pdf",
	timestamp = "2007.03.22",
	title = "{Real Time Signal Transposition With Envelope Preservation In The Phase Vocoder}",
	year = "2005"
}

@article{Roebel2003,
	abstract = "In this paper we propose a new method to reduce phase vocoder artifacts during attack transients. In contrast to all transient preser- vation algorithms that have been proposed up to now the new ap- proach does not impose any constraints on the time dilation pa- rameter for processing transient segments. By means of an in- vestigation into the spectral properties of attack transients of sim- ple sinusoids we provide new insights into the causes of phase vocoder artifacts and propose a new method for transient preser- vation as well as a new criterion and a new algorithm for transient detection. Both, the transient detection and the transient process- ing algorithms are designed to operate on the level of spectral bins which reduces possible artifacts in stationary signal components that are close to the spectral peaks classiÃ¯Â¬Âed as transient. The tran- sient detection criterion has a close relation to the transient posi- tion and allows us to Ã¯Â¬Ând an optimal position for reinitializing 
the phase spectrum. The evaluation of the transient detector by means of a hand labeled data base demonstrates its superior performance compared to a previously published algorithm. Attack transients in sound signals transformed with the new algorithm achieves high quality even if strong dilation is applied to polyphonic signals.",
	author = "Roebel, A.",
	journal = "DAFx",
	keywords = "TRANSIENT PROCESSING PHASE VOCODER",
	lockkey = "Y",
	owner = "norwin",
	pdf = "Robel\_DAFX\_2003\_dafx2003.pdf",
	timestamp = "2007.07.06",
	title = "{A NEW APPROACH TO TRANSIENT PROCESSING IN THE PHASE VOCODER}",
	year = 2003
}

@article{Saul_Lee_Isbell_LeCun_Audiovisual_2002,
	abstract = "We have implemented a real time front end for detecting voiced speech and estimating its fundamental frequency. The front end performs the signal processing for voice-driven agents that attend to the pitch contours of human speech and provide continuous audiovisual feedback. The al- gorithm we use for pitch tracking has several distinguishing features: it makes no use of FFTs or autocorrelation at the pitch period; it updates the pitch incrementally on a sample-by-sample basis; it avoids peak picking and does not require interpolation in time or frequency to obtain high res- olution estimates; and it works reliably over a four octave range, in real time, without the need for postprocessing to produce smooth contours. The algorithm is based on two simple ideas in neural computation: the introduction of a purposeful nonlinearity, and the error signal of a least squares Ã¯Â¬Ât. The pitch tracker is used in two real time multimedia applica- tions: a voice-to-MIDI player that synthesizes electronic 
music from vo- calized melodies, and an audiovisual Karaoke machine with multimodal feedback. Both applications run on a laptop and display the user{\rq}s pitch scrolling across the screen as he or she sings into the computer.",
	author = "Saul, Lawrence K. and Lee, Daniel D. and Isbell, Charles L. and LeCun, Yann",
	keywords = "Real time voice processing audiovisual feedback autonomous agents perfect pitch",
	lockkey = "N",
	owner = "norwin",
	pdf = "Saul\_Lee\_Isbell\_LeCun\_Audiovisual\_2002\_RT voice processing - voice-nips-2002.pdf",
	timestamp = "2007.07.06",
	title = "{Real time voice processing with audiovisual feedback: toward autonomous agents with perfect pitch}",
	year = "2002"
}

@misc{Schluns2000,
	annote = "UNPUBLISHED",
	author = "Schl{\"u}ns, Karsten and KOSCHAN, Andreas",
	lockkey = "Y",
	owner = "degottex",
	timestamp = "2007.12.04",
	title = "{Global And Local Highlight Analysis In Color Images}",
	url = "http://citeseer.ist.psu.edu/553423.html",
	year = "2000"
}

@inproceedings{Schnell2007,
	abstract = "Analysis of speech signals can be performed with the aid of linear or nonlinear statistics using appropriate prediction algorithms. In this contribution, speech features are treated using the results of a nonlinear prediction based on Volterra series. Features are investigated representing the prediction gain by nonlinear statistics and representing individual coefficients of the nonlinear components. The features are estimated quasi continuously resulting in a feature signal. Additionally, to obtain features which are highly sensitive to segmentation shifting, an asymmetric window function is integrated into the prediction algorithm. The analyses of speech signals show that the estimated features correlate with the glottal pulses. Furthermore, the investigations show that using the first individual nonlinear coefficient as a feature is advantageous over using the prediction gain.",
	author = "Schnell, K. and Lacroix, A.",
	booktitle = "{Proc. Non-Linear Speech Processing (NOLISP)}",
	keywords = "Estimation of Speech Features of Glottal Excitation by Nonlinear Prediction",
	lockkey = "Y",
	pages = "116--119",
	timestamp = "2007.07.05",
	title = "{Estimation of Speech Features of Glottal Excitation by Nonlinear Prediction}",
	year = "2007"
}

@article{Schnell_Lacroix_EU_2006,
	abstract = "The analysis of speech is usually based on linear models. In this contribution speech features are treated using nonlinear statistics of the speech signal. Therefore a nonlinear predic- tion based on Volterra series is applied segment-wise to the speech signal. The optimal nonlinear predictor can be de- termined by a vector expansion. Since the statistics of a segment is estimated a window function is integrated into the estimation procedure. Speech features are investigated representing the prediction gain between the linear and the nonlinear prediction. The analyses of speech signals show that the nonlinear features correlate with the glottal pulses. The integration of an appropriate window function into the prediction algorithm plays an important part for the results.",
	author = "Schnell, Karl and Lacroix, Arild",
	journal = "EU",
	keywords = "WEIGHTED NONLINEAR PREDICTION VOLTERRA SERIES SPEECH ANALYSIS",
	lockkey = "N",
	note = "Institute of Applied Physics, Goethe-University Frankfurt Max-von-Laue-Str. 1, D-60438 Frankfurt am Main, Germany email: {Schnell, Lacroix}@iap.uni-frankfurt.de",
	owner = "degottex",
	pdf = "Schnell\_Lacroix\_EU\_2006\_EU06a.pdf",
	timestamp = "2007.07.05",
	title = "{WEIGHTED NONLINEAR PREDICTION BASED ON VOLTERRA SERIES FOR SPEECH ANALYSIS}",
	year = "2006"
}

@misc{DepSci_Couplage_2005,
	abstract = "La mod{\'e}lisation de la production vocale s{\rq}appuie sur la th{\'e}orie source-filtre d{\'e}velopp{\'e}e par Fant en 1960. Cette th{\'e}orie a eu un impact majeur dans le domaine du traitement de la parole, du fait d{\rq}un tr{\`e}s bon accord avec les r{\'e}sultats exp{\'e}rimentaux. Elle fut appliqu{\'e}e avec succ{\`e}s Ã¯Â¿Å l{\rq}analyse, la synth{\`e}se et le codage de la parole. Une hypoth{\`e}se majeure de cette th{\'e}orie porte sur l{\rq}ind{\'e}pendance des parties ``< source ''> et ``< filtre ''>. Si ces hypoth{\`e}ses semblent valides dans le cas de la parole spontan{\'e}e, elles semblent plus discutables dans le cas du chant, de la parole projet{\'e}e (e.g. production vocale des acteurs) ou des productions vocales pathologiques. En effet, les techniques vocales mises en pratique dans ces types de phonation montrent la recherche d{\rq}une interaction entre le syst{\`e}me respiratoire et vibratoire d'un c{\{\{\{\{\^o}}}}}t{\'e} et l{\rq}ajustement des cavit{\'e}s supra-
glottiques de l'autre, ceci dans le but d{\rq}am{\'e}liorer l{\rq}efficacit{\'e} vocale et de ma{\{\{\{\{\^i}}}}}triser la qualit{\'e} vocale du son produit. [...]",
	author = "{et de la Soci{\'e}t{\'e}}, D{\'e}partement des Sciences de l{\rq}Homme",
	keywords = "Exploration des ph{\'e}nom{\`e}nes d{\rq}interaction source-filtre en phonation humaine couplage",
	lockkey = "N",
	note = "ATIP Jeunes Chercheurs Appel d{\rq}offres 2005",
	owner = "degottex",
	pdf = "DepSci\_Couplage\_2005\_phenomenes d'interaction source-filtre - ProjetATIP2005\_NH.pdf",
	timestamp = "2007.07.05",
	title = "{Exploration des ph{\'e}nom{\`e}nes d{\rq}interaction source-filtre en phonation humaine}",
	year = "2005"
}

@phdthesis{Shiga2005,
	abstract = "This thesis addresses the problem of quality degradation in speech produced by parameter-based speech synthesis, within the framework of an articulatory-acoustic forward mapping. I first investigate current problems in speech parameterisation, and point out the fact that conventional parameterisation inaccurately extracts the vocal tract response due to interference fromthe harmonic structure of voiced speech. To overcome this problem, I introduce amethod for estimating filter responsesmore precisely from periodic signals. The method achieves such estimation in the frequency domain by approximating all the harmonics observed in several frames based on a least squares criterion. It is shown that the proposed method is capable of estimating the response more accurately than widely-used frame-by-frame parameterisation, for simulations using synthetic speech and for an articulatory-acoustic mapping using actual speech. I also deal with the source-filter separation problem and independent control of 
the voice source characteristic during speech synthesis. I propose a statistical approach to separating out the vocal-tract filter response from the voice source characteristic using a large articulatory database. The approach realises such separation for voiced speech using an iterative approximation procedure under the assumption that the speech production process is a linear system composed of a voice source and a vocal-tract filter, and that each of the components is controlled independently by different sets of factors. Experimental results show that controlling the source characteristic greatly improves the accuracy of the articulatory-acoustic mapping, and that the spectral variation of the source characteristic is evidently influenced by the fundamental frequency or the power of speech. The thesis provides more accurate acoustical approximation of the vocal tract response, which will be beneficial in a wide range of speech technologies, and lays the groundwork in speech science for a new type of 
corpus-based statistical solution to the source-filter separation problem.",
	author = "Shiga, Yoshinori",
	keywords = "Vocal Tract Voice Source",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Shiga\_Edinburgh\_2005\_phd\_thesis\_shiga.pdf",
	school = "University of Edinburgh",
	timestamp = "2007.03.05",
	title = "{Precise Estimation of Vocal Tract and Voice Source Characteristics}",
	type = "PhD Thesis",
	year = 2005
}

@article{Shiga2004a,
	abstract = "In this paper we examine a method for separating out the vocal-tract Ã¯Â¬Âlter response from the voice source characteristic using a large ar- ticulatory database. The method realises such separation for voiced speech using an iterative approximation procedure under the as- sumption that the speech production process is a linear system com- posed of a voice source and a vocal-tract Ã¯Â¬Âlter, and that each of the components is controlled independently by different sets of factors. Experimental results show that the spectral variation is evidently in- Ã¯Â¬Âuenced by the fundamental frequency or the power of speech, and that the tendency of the variation may be related closely to speaker identity. The method enables independent control over the voice source characteristic in our articulation-to-speech synthesis.",
	author = "Shiga, Yoshinori and King, Simon",
	comment = "peut {\{\^e}}tre ignor{\'e} difficile de savoir le pourquoi de tout ce processus",
	journal = "ICSLP",
	lockkey = "Y",
	owner = "norwin",
	pdf = "Shiga\_King\_ICSLP\_2004.pdf",
	timestamp = "2007.07.11",
	title = "{Source-Filter Separation for Articulation-to-Speech Synthesis}",
	year = "2004"
}

@article{Shiga2004b,
	abstract = "This paper introduces a novel articulatory-acoustic mapping in which detailed spectral envelopes are estimated based on the cep- strum, inclusive of the high-quefrency elements which are dis- carded in conventional speech synthesis to eliminate the pitch component of speech. For this estimation, the method deals with the harmonics of multiple voiced-speech spectra so that several sets of harmonics can be obtained at various pitch frequencies to form a spectral envelope. The experimental result shows that the method estimates spectral envelopes with the highest accuracy when the cepstral order is 48-64, which suggests that the higher- order coefÃ¯Â¬Âcients are required to represent detailed envelopes re- Ã¯Â¬Âecting the real vocal-tract responses.",
	author = "Shiga, Yoshinori and King, Simon",
	journal = "ISCA",
	keywords = "SPECTRAL ENVELOPE ESTIMATION ARTICULATION-TO-SPEECH SYNTHESIS",
	lockkey = "Y",
	owner = "norwin",
	pdf = "Shiga\_King\_ISCA\_2004\_1041.pdf",
	timestamp = "2007.07.06",
	title = "{ACCURATE SPECTRAL ENVELOPE ESTIMATION FOR ARTICULATION-TO-SPEECH SYNTHESIS}",
	year = "2004"
}

@article{Shiga2003dcemfa,
	abstract = "This paper presents a new approach for estimating voice source and vocal tract filter characteristics of voiced speech. When it is required to know the transfer function of a system in signal processing, the input and output of the system are experimentally observed and used to calculate the function. However, in the case of source-filter separation we deal with in this paper, only the output (speech) is observed and the characteristics of the system (vocal tract) and the input (voice source) must simultaneously be estimated. Hence the estimate becomes extremely difficult, and it is usually solved approximately using oversimplified models. We demonstrate that these characteristics are separable under the assumption that they are independently controlled by different factors. The separation is realised using an iterative approximation along with the Multi-frame Analysis method, which we have proposed to find spectral envelopes of voiced speech with minimum interference of the harmonic structure.",
	author = "Shiga, Yoshinori and King, Simon",
	journal = "EUROSPEECH",
	keywords = "Estimation Voice Source Vocal Tract Characteristics Multi-frame Analysis",
	lockkey = "Y",
	note = "Centre for Speech Technology Research University of Edinburgh, Edinburgh, U.K. yoshi@cstr.ed.ac.uk",
	owner = "degottex",
	pdf = "Shiga\_King\_EUROSPEECH\_2003\_ShigaEURO03.pdf",
	timestamp = "2007.07.05",
	title = "{Estimation of Voice Source and Vocal Tract Characteristics Based on Multi-frame Analysis}",
	year = "2003"
}

@article{SmitsR1995,
	author = "Smits, R. and Yegnanarayana, B.",
	journal = "IEEE Trans. on Speech and Audio Processing",
	lockkey = "Y",
	number = "5",
	owner = "degottex",
	pages = "325--333",
	pdf = "Smits\_Yegnanarayana\_IEEE\_1995\_Determination of instants of significant excitation in speech using group delay function.pdf",
	timestamp = "2007.03.06",
	title = "{Determination of Instants of Significant Excitation in Speech Using Group Delay Function}",
	volume = "3",
	year = "1995"
}

@unpublished{Sobel1968,
	author = "Sobel, I. and Feldman, G.",
	comment = "unpublished but often cited, orig. in Pattern Classification and Scene Analysis, Duda,R. and Hart,P., John Wiley and Sons,'73, pp271-2",
	lockkey = "Y",
	note = "UNPUBLISHED",
	owner = "degottex",
	timestamp = "2007.12.03",
	title = "{A 3x3 Isotropic Gradient Operator for Image Processing}",
	year = "1968"
}

@article{Stern_Liu_Ohshima_Sullivan_Acero_1992,
	abstract = "This paper compares several different approaches to robust speech recognition. We review CMU's ongoing research in the use of acoustical pre-proeessing to achieve robust speech recog- nition, and we present the results of the first evaluation of pre- processing in the context of the DARPA standard ATIS domain for spoken language systems. We also describe and compare the effectiveness of three complementary methods of signal process- ing for robust speech recognition: acoustical pre-procossing, microphone array processing, and the use of physiologically- motivated models of peripheral signal processing. Recognition error rates are presented using these three approaches in isolation and in combination with each other for the speaker-independent continuous alphanumeric census speech recognition task.",
	author = "Stern, Richard M. and Liu, Fu-Hua and Ohshima, Yoshiaki and Sullivan, Thomas M. and Acero, Alejandro",
	keywords = "MULTIPLE APPROACHES ROBUST SPEECH RECOGNITION",
	lockkey = "N",
	note = "Department o f Electrical and Computer Engineering School of Computer Science Carnegie Mellon University Pittsburgh, PA 15213",
	owner = "degottex",
	pdf = "Stern\_Liu\_Ohshima\_Sullivan\_Acero\_1992\_H92-1055.pdf",
	timestamp = "2007.07.05",
	title = "{MULTIPLE APPROACHES TO ROBUST SPEECH RECOGNITION}",
	year = "1992"
}

@article{Strik_Cranen_Boves_FITTING_1993,
	abstract = "A method is presented for the automaticextraction of voice source parameters from speech. An automatic i n- versefiltering algorithm is used to obtain an esti mate of the glottal flow signal. Subsequently, an LF-model [1] is fitted to the glottal flow signal. In the current article we will focus on the improvement of the automatic fit pro- cedure. To keep track of the performance of the fit procedure, a quantitative evaluation criterion is preferred. It is dif- ficult to obtain such a criterion for naturalspeec h. There- fore, we proposean evaluation method in which synt hetic speech is used. We also conducted qualitative tests for disturbances that are often found in natural speech , i.e. source-filterinteraction.",
	author = "Strik, Helmer and Cranen, Bert and Boves, Louis",
	keywords = "inverse filtering; LF-model; fit; evaluation",
	lockkey = "N",
	owner = "norwin",
	pdf = "Strik\_Cranen\_Boves\_FITTING\_1993\_strik.1993.1.pdf",
	timestamp = "2007.07.11",
	title = "{FITTING A LF-MODEL TO INVERSE FILTER SIGNALS}",
	year = "1993"
}

@article{Strube1974,
	author = "Strube, H. W.",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "5",
	owner = "degottex",
	pages = "625--1629",
	timestamp = "2008.03.03",
	title = "{Determination of the instant of glottal closure from the speech wave}",
	volume = "56",
	year = "1974"
}

@mastersthesis{Sturmel2006,
	abstract = "Ce stage a pour sujet la d{\'e}tection des param{\`e}tres de la source glottique {\`a} l{\rq}aide de l{\rq}analyse par Z{\'e}ros de la Transform{\'e}e en Z (ZZT). En utilisant une description spectrale de la source glottique, des travaux pr{\'e}c{\'e}dent on montr{\'e} que la ZZT permet d{\rq}estimer les param{\`e}tres de source. Cette {\'e}tude est un approfondissement des travaux initiaux. Elle s{\rq}est articul{\'e}e autour de l{\rq}impl{\'e}mentation de l{\rq}algorithme de d{\'e}composition par ZZT, de l{\rq}{\'e}tude de sa robustesse. Nous avons notamment mesur{\'e} avec quelle finesse la position des points d{\rq}analyse, synchrones au fondamental (GCI, glottal closing instant), devaient {\{\{\{\{\^e}}}}}tre d{\'e}termin{\'e}s pour arriver {\`a} une d{\'e}composition optimale. Nous avons aussi {\'e}tudi{\'e} diff{\'e}rentes sources de probl{\`e}mes suppl{\'e}mentaires lors de la d{\'e}composition : erreurs sur le calcul des z{\'e}ros, rapport son/bruit, influence du fen{\{\{\{\{\^e}}}}}
trage du signal. Nous avons ensuite montr{\'e} qu{\rq}il {\'e}tait possible, via une mesure conjointe du quotient ouvert par {\'e}lectroglottographie (EGG) et du formant glottique par ZZT, d{\rq}arriver {\`a} estimer un nouveau param{\`e}tre de la source glottique : le coefficient d{\rq}asym{\'e}trie m. Nous avons alors cr{\'e}{\'e} une base de donn{\'e}es de signaux vocaux pour {\'e}prouver l{\rq}impl{\'e}mentation de la d{\'e}composition et la mesure de ce param{\`e}tre. Cette base s{\rq}articule autour de signaux {\'e}mis en m{\'e}canisme laryng{\'e} I et II par 3 locuteurs, sur 3 voyelles choisies pour leurs caract{\'e}ristiques spectrales typiques : A, I et OU. Il appara{\{\{\{\{\^i}}}}}t que l{\rq}analyse donne surtout de bons r{\'e}sultats pour les signaux {\`a} grande p{\'e}riode fondamentale et/ou {\`a} faible quotient ouvert. On mesure alors des valeurs de m typiquement comprises entre 0.6 et 0.8. Nous montrons donc, que sous certaines hypoth{\`e}ses vis {\`a} vis des signaux analys{\'e}s, nous 
pourrions faire une mesure dont la pr{\'e}cision serait inf{\'e}rieure au diff{\'e}rentiel percreptif. Par contre il semble que la m{\'e}thode de d{\'e}composition impl{\'e}ment{\'e}e n{\rq}est pas assez robustes pour des signaux {\'e}mis en m{\'e}canisme II lorsque les p{\'e}riodes sont courtes et les quotients ouverts forts.",
	author = "Sturmel, Nicolas",
	keywords = "ZZT",
	lockkey = "Y",
	month = "june",
	note = "encadr{\'e} par Christophe D{\rq}Alessandro",
	owner = "degottex",
	pdf = "Sturmel\_ATIAM\_2006\_Analyse de la source glottique par ZZT.pdf",
	school = "UPMC paris VI - IRCAM - LIMSI/CNRS - Master 2 MIS ATIAM",
	timestamp = "2007.03.05",
	title = "{Analyse de la source glottique par ZZT}",
	type = "Rapport de Stage ATIAM",
	year = 2006
}

@article{Sun_IEEE_2000,
	author = "Sun, Xuejing",
	journal = "IEEE",
	keywords = "VOICE QUALITY CONVERSION IN TD-PSOLA SPEECH SYNTHESIS",
	lockkey = "N",
	owner = "degottex",
	pages = "953",
	pdf = "Sun\_IEEE\_2000\_VOICE QUALITY CONVERSION IN TD-PSOLA SPEECH SYNTHESIS.pdf",
	timestamp = "2007.03.14",
	title = "{VOICE QUALITY CONVERSION IN TD-PSOLA SPEECH SYNTHESIS}",
	year = "2000"
}

@article{SZOKE_2003,
	abstract = "This article presents a method for speech prosodic modiÃ¯Â¬Âcation. Parametric har- monic and noise model (HNM) is used to describe a speech signal. The algorithm for prosodic modiÃ¯Â¬Âcations consists of two parts. The analysis part parameterizes the speech signal. We spread speech into a sequence of the pitch-marks, each of which is represented by a vector of parameters. The next part is synthesis. Prosodic modiÃ¯Â¬Âcations are done by remapping of the pitch-marks. ModiÃ¯Â¬Âed signal can be resynthesized from interpolated parameters.",
	author = "SZ{\"O}KE, Igor",
	keywords = "PROSODIC MODIFICATIONS SYNTHETIC SPEECH",
	lockkey = "N",
	owner = "norwin",
	pdf = "SZOKE\_2003\_02-xszoke00.pdf",
	timestamp = "2007.07.06",
	title = "{PROSODIC MODIFICATIONS OF SYNTHETIC SPEECH}",
	year = "2003"
}

@inproceedings{TahonM2012a,
	abstract = "We focus in this paper on the detection of emotions collected in real-life context. In order to improve our emotional valence detection system, we have tested new voice quality features that are mainly used for speech synthesis or voice transformation: the relaxation coefficient (Rd) and the functions of phase distortion (FPD); but also usual voice quality features. Distributions of voice quality features across speakers, gender, age and emotions are shown over the IDV-HR ecological corpus. Our results conclude that glottal and usual voice quality features are of interest for emotional valence detection even facing diverse kind of voices in ecological situations.",
	author = "Tahon, M. and Degottex, G. and Devillers, L.",
	booktitle = "{Proc. International Conference on Speech Prosody}",
	pages = "693--696",
	title = "{Usual voice quality features and glottal features for emotional valence detection}",
	year = "2012"
}

@inproceedings{TahonM2012aposter,
	abstract = "We focus in this paper on the detection of emotions collected in real-life context. In order to improve our emotional valence detection system, we have tested new voice quality features that are mainly used for speech synthesis or voice transformation: the relaxation coefficient (Rd) and the functions of phase distortion (FPD); but also usual voice quality features. Distributions of voice quality features across speakers, gender, age and emotions are shown over the IDV-HR ecological corpus. Our results conclude that glottal and usual voice quality features are of interest for emotional valence detection even facing diverse kind of voices in ecological situations.",
	author = "Tahon, M. and Degottex, G. and Devillers, L.",
	booktitle = "{ICSP}",
	pages = "693--696",
	title = "{Usual voice quality features and glottal features for emotional valence detection}",
	year = "2012"
}

@article{Nagarajan_Murthy_Hedge_ICASSP_2004,
	abstract = "In the development of a syllable-centric ASR system, segmentation of the acoustic signal into syllabic units is an important stage. This paper presents a minimum phase group delay based approach to segment spontaneous speech into syllable-like units. Here, three different minimum phase signals are derived from the short term energy functions of three sub-bands of speech signals, as if it were a magnitude spectrum. The experiments are carried out on Switchboard corpus and the error in segmentation is found to be utmost 40msec for 85\% of the syllable segments, in addition to 5.25\% insertions and 7.10\% deletions.",
	author = "T.Nagarajan, Hema A. Murthy and Hegde, Rajesh M.",
	journal = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	lockkey = "N",
	owner = "degottex",
	pdf = "Nagarajan\_Murthy\_Hedge\_ICASSP\_2004\_Grp\_delay\_segmentation\_syllabes.pdf",
	timestamp = "2007.03.01",
	title = "{GROUP DELAY BASED SEGMENTATION OF SPONTANEOUS SPEECH INTO SYLLABLE-LIKE UNITS}",
	year = "2004"
}

@article{Toda_Black_Tokuda_CMUNIT_2004,
	abstract = "This paper describes the acoustic-to-articulatory inversion map- ping using a Gaussian Mixture Model (GMM). Correspon- dence of an acoustic parameter and an articulatory parameter is modeled by the GMM trained using the parallel acoustic- articulatory data. We measure the performance of the GMM- based mapping and investigate the effectiveness of using multi- ple acoustic frames as an input feature and using multiple mix- tures. As a result, it is shown that although increasing the num- ber of mixtures is useful for reducing the estimation error, it causes many discontinuities in the estimated articulatory tra- jectories. In order to address this problem, we apply maxi- mum likelihood estimation (MLE) considering articulatory dy- namic features to the GMM-based mapping. Experimental re- sults demonstrate that the MLE using dynamic features can es- timate more appropriate articulatory movements compared with the GMM-based mapping applied smoothing by lowpass Ã¯Â¬Âlter.",
	author = "Toda, Tomoki and Black, Alan W and Tokuda, Keiichi",
	journal = "CMUNIT",
	keywords = "Acoustic-to-Articulatory Inversion Mapping with Gaussian Mixture Model",
	lockkey = "N",
	note = "Language Technologies Institute, Carnegie Mellon University, USA Graduate School of Engineering, Nagoya Institute of Technology, Japan tomoki,awb @cs.cmu.edu, tomoki,tokuda @ics.nitech.ac.jp",
	owner = "degottex",
	pdf = "Toda\_Black\_Tokuda\_CMUNIT\_2004\_TodaICSLP04.pdf",
	timestamp = "2007.07.05",
	title = "{Acoustic-to-Articulatory Inversion Mapping with Gaussian Mixture Model}",
	year = "2004"
}

@article{Veldhuis_EfficientLF_2006,
	abstract = "An alternative for the Liljencrants-Fant (LF) glottal-pulse model is presented. This alter- native is derived from the Rosenberg model. Therefore, we call it the Rosenberg++ mod- el. In the derivation use a general framework for glottal-pulse models. The Rosenberg++ model is described by the same set of T or R parameters as the LF model but has the ad- vantage over the LF model that it is computationally more efficient. It is compared with the LF model in a psycho-acoustic experiment, from which we conclude that in a practical situation it is capable of producing synthetic speech which is perceptually equivalent to speech generated with the LF model.",
	author = "Veldhuis, Raymond",
	keywords = "efficient alternative LF model perceptual",
	lockkey = "N",
	note = "IPO - Centre for Research on User-System Interaction PO Box 513, 5600 MB Eindhoven, The Netherlands e-mail: veldhuis@ipo.tue.nl",
	owner = "degottex",
	pdf = "Veldhuis\_EfficientLF\_2006\_a-computationally-efficient-alternative.pdf",
	timestamp = "2007.07.05",
	title = "{A computationally efficient alternative for the LF model and its perceptual evaluation}",
	year = "2006"
}

 @ARTICLE{ITU01,
     title = {Perceptual evaluation of speech quality ({PESQ})-a new method for speech quality assessment of telephone networks and codecs},
     author = {Rix, A. W. and Beerends, J. G. and Hollier, M. P. and Hekstra, A. P.},
     journal = {IEEE International Conference on Acoustics, Speech and Signal Processing},
     volume={2},
     pages = {749-752},
     month = {Aug. },
     year = {2001}
     }


	 
@inproceedings{Villavicencio2006,
	abstract = "n this work we address the problem of all pole spectral envelope estimation for speech signals. The currently widely used all pole spectral envelope model suffers from well-known systematic errors and more severely from model order mismatch. We will propose a procedure to first establish a band limited interpolation of the observed spectrum using a recently rediscovered true envelope estimator and then using the band limited envelope to derive an all pole envelope model named TE-LPC . The band-limited envelope that is used to derive the all pole envelope model reduces the problem of the unknown all pole model order. For the experimental investigation we propose a new perceptually motivated residual spectral peak flatness measure. The experimental results demonstrate that the proposed method significantly increases the spectral flatness for the perceptually especially important low order harmonics of voiced utterances",
	author = "Villavicencio, F. and Robel, A. and Rodet, X.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2006.1660159",
	issn = "1520-6149",
	keywords = "LPC spectral envelope extraction; band limited interpolation; spectral peak flatness; speech signals; true-envelope estimation; voiced speech; interpolation; speech processing",
	lockkey = "Y",
	pages = "869--872",
	title = "{Improving {LPC} Spectral Envelope Extraction of Voiced Speech By True-Envelope Estimation}",
	volume = "1",
	year = "2006"
}

@phdthesis{Vincent2007,
	address = "France",
	author = "Vincent, Damien",
	lockkey = "Y",
	owner = "degottex",
	school = "France Telecom, ENST, in french",
	timestamp = "2008.03.03",
	title = "{Analyse et controle du signal glottique en synthese de la parole}",
	year = 2007
}

@inproceedings{VincentD2007a,
	abstract = "In this paper a new method for speech synthesis is proposed. It relies on a source-filter decomposition of the speech signal by means of an ARX-LF model. This model allows the representation of the glottal signal as the sum of an LF waveform and a residual signal. The residual information is then analyzed by HNM. This signal representation enables high quality speech modification such as pitch, duration or even voice quality transformation. Experiments performed on a real speech database show the relevance of the proposed method as compared to other existing approaches",
	author = "Vincent, D. and Rosec, O. and Chonavel, T.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2007.366965",
	issn = "1520-6149",
	keywords = "ARX-LF source-filter decomposition; filtering theory; glottal signal representation; harmonic plus noise models; high quality speech modification; HNM modeling; LF waveform; speech database; speech processing; speech synthesis; voice quality transformation; waveform analysis",
	lockkey = "Y",
	pages = "525--528",
	title = "{A New Method for Speech Synthesis and Transformation Based on an {ARX-LF} Source-Filter Decomposition and {HNM} Modeling}",
	volume = "4",
	year = "2007"
}

@inproceedings{VincentD2006,
	abstract = "An algorithm for GCI (Glottal Closure Instants) estimation is presented in this paper. It relies on a source Ã¯Â¬Âlter model of speech production using a LF model for the source com- ponent. From this source Ã¯Â¬Âlter decomposition, a ratio which measures the goodness of Ã¯Â¬Ât of the LF source model is in- troduced in the GCI estimation procedure together with fun- damental frequency constraints. Then a Viterbi algorithm is applied to extract the most likely GCI sequence. Experiments performed on a real speech database show the relevance of the proposed method.",
	author = "Vincent, Damien and Rosec, Olivier and Chonavel, Thierry",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	keywords = "GLOTTAL CLOSURE INSTANT MEASURE SOURCE CONTINUITY CONSTRAINTS GCI",
	lockkey = "Y",
	owner = "degottex",
	pages = "381--384",
	pdf = "Vincent\_Rosec\_Chonavel\_GCI\_2006\_DV OR TC - 0100381.pdf",
	timestamp = "2007.07.05",
	title = "{Glottal closure instant estimation using an appropriateness measure of the source and continuity constraints}",
	volume = "1",
	year = "2006"
}

@inproceedings{VincentD2005,
	abstract = "The goal of this paper is to estimate the glottal source signal from the sole speech signal. By using the ARX model of speech production and a glottal source model, this deconvolution problem is turned into a complex nonlinear optimization problem. We present an efÃ¯Â¬Âcient method to solve this problem, and some experiments on synthetic speech as well as on natural speech signals.",
	author = "Vincent, D. and Rosec, O. and Chonavel, T.",
	booktitle = "{Proc. Groupe d'Etude sur le Traitement du Signal et des Images (GRETSI), in french}",
	keywords = "Estimation signal glottique mod{\`e}le ARX",
	lockkey = "Y",
	owner = "degottex",
	pdf = "VINCENT\_ROSEC\_CHONAVEL\_GRETSI\_2005\_GRETSI2005\_DamienVincent\_final.pdf",
	timestamp = "2007.07.05",
	title = "{Estimation du signal glottique bas{\'e}e sur un mod{\`e}le {ARX}}",
	year = "2005"
}

@article{VincentD2005a,
	abstract = "We propose a method to estimate the glottal Ã¯Â¬Âow based on the ARX model of speech production and on the LF model of glot- tal Ã¯Â¬Âow. This method splits the analysis in two stages: a low fre- quency analysis to estimate the glottal source parameters which have mainly a low pass effect and a second step to reÃ¯Â¬Âne the pa- rameters which have also a high pass effect. Along with this new analysis scheme, we introduce a new algorithm to efÃ¯Â¬Â- ciently minimize the nonlinear function resulting from the least square criterion applied to the ARX model. Results on syn- thetic and natural speech signals prove the effectiveness of the proposed method.",
	author = "Vincent, D. and Rosec, O. and Chonavel, T.",
	journal = "Proc. Interspeech",
	keywords = "Estimation LF glottal source parameters ARX model",
	lockkey = "Y",
	owner = "degottex",
	pages = "333--336",
	pdf = "Vincent\_Rosec\_Chonavel\_IS\_2005\_is2005\_DamienVincent\_final.pdf",
	timestamp = "2007.07.05",
	title = "{Estimation of {LF} glottal source parameters based on an {ARX} model}",
	year = "2005"
}

@phdthesis{VincentE2004,
	abstract = "For about Ã¯Â¬Âfteen years the study of chamber music recordings has focused on two distinct view- points : source separation and polyphonic transcription. Source separation tries to extract from a re- cording the signals corresponding to each musical instrument playing. Polyphonic transcription aims at describing a recording by a set of parameters : names of the instruments, pitch and loudness of the notes, etc. Existing methods, based on spatial and spectro-temporal analysis of the recordings, provide satis- fying results in simple cases. But their performance generally degrades fast with more instruments than a Ã¯Â¬Âxed limit, under reverberant conditions, with instruments of similar playing ranges or with notes at harmonic intervals. Our hypothesis is that these methods often suffer from too generic models of instrumental sources. We propose to address this by creating speciÃ¯Â¬Âc instrument models based on learning. In this dissertation, we justify this hypothesis by studying the 
relevant information present in musi- cal recordings and its use by existing methods. Then we describe new probabilistic instrument models inspired from Independent Subspace Analysis (ISA) and we give a few examples of learnt instruments. Finally we exploit these models to separate and transcribe realistic recordings, among which CD tracks and synthetic convolutive or underdetermined mixtures of these tracks.",
	author = "VINCENT, EMMANUEL",
	keywords = "source separation; polyphonic transcription; instrument identiÃ¯Â¬Âcation; auditory scene analysis; probabilistic source models; Independent Subspace Analysis",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Vincent\_UPMC\_2004\_vincent\_PhD.pdf",
	school = "UPMC-IRCAM",
	timestamp = "2007.07.05",
	title = "{Mod{\`e}les d{\rq}instruments pour la s{\'e}paration de sources et la transcription d{\rq}enregistrements musicaux}",
	year = "2004"
}

@mastersthesis{Vincent_ATIAM_2001,
	abstract = "J{\rq}ai travaillÃÅœ en collaboration avec Bertrand Delezoide sur le sujet de la e sÃÅœparation de sources sur des signaux monophoniques par analyse en sous- e espaces indÃÅœpendants sur le spectrogramme. e Apr`s avoir ÃÅœtudiÃÅœ a la fois un mod`le s{\rq}appliquant aux sons stationnaires e e e` e et la question de l{\rq}inversion des reprÃÅœsentations temps-frÃÅœquence, j{\rq}ai ÃÅœcrit les e e e programmes MATLAB correspondants. J{\rq}ai eÃ¯Â¬ÂectuÃÅœ alors plusieurs tests sur e des mÃÅœlanges monophoniques, qui m{\rq}ont permis de dÃÅœgager l{\rq}importance d{\rq}une e e interprÃÅœtation non statistique du mod`le. Je me suis Ã¯Â¬Ânalement intÃÅœressÃÅœ a e e e e` amÃÅœliorer les rÃÅœsultats du mod`le en essayant de le modiÃ¯Â¬Âer ou de lui ajou- e e e ter des connaissances a priori. De son cÃÂtÃÅœ, Bertrand a ÃÅœtudiÃÅœ les questions du regroupement des sources oe e e suite a l{\rq}application du mod`le et de l{\rq}utilisation du mod`le pour des signaux ` e e non 
stationnaires. Il a ÃÅœcrit les programmes MATLAB correspondants, et fait e plusieurs tests pour dÃÅœterminer les mÃÅœlanges les plus adaptÃÅœs a cette technique e e e` de sÃÅœparation. Il a aussi dÃÅœveloppÃÅœ une approche par Ã¯Â¬Âltrage de l{\rq}inversion des e e e reprÃÅœsentations temps-frÃÅœquence des sources. Dans la suite, je signale ses contri- e e butions par la rÃÅœfÃÅœrence [Del01]. ee",
	author = "Vincent, Emmanuel",
	keywords = "S{\'e}paration de signaux audio: principes statistiques de l{\rq}analyse en composantes ind{\'e}pendantes et applications au signal monophonique",
	lockkey = "N",
	month = "juin",
	note = "Rapport de stage de DEA ATIAM Equipe analyse-synth{\`e}se, IRCAM sous la direction de Xavier Rodet en collaboration avec Bertrand Delezoide",
	owner = "degottex",
	pdf = "Vincent\_ATIAM\_2001\_vincent\_MSc.pdf",
	school = "ATIAM",
	timestamp = "2007.07.05",
	title = "{S{\'e}paration de signaux audio: principes statistiques de l{\rq}analyse en composantes ind{\'e}pendantes et applications au signal monophonique}",
	year = "2001"
}

@inproceedings{Virtanen_DAFX_2003,
	abstract = "A signal model is described which forces temporal and spec- tral smoothness of harmonic sounds. Smoothness refers to har- monic partials, the amplitudes of which are slowly-varying as a function of time and frequency. An algorithm is proposed for the estimation of the model parameters. The algorithm is utilized in a sound separation system, the robustness of which is increased by the smoothness constraints.",
	author = "Virtanen, Tuomas",
	booktitle = "{DAFx}",
	journal = "DAFX",
	keywords = "algorithm separation harmonic sounds time-frequency smoothness constraint",
	lockkey = "N",
	month = "September",
	note = "Institute of Signal Processing, Tampere University of Technology P.O.Box 553, FIN-33101 Tampere, Finland tuomas.virtanen@tut.fi",
	owner = "degottex",
	pdf = "Virtanen\_DAFX\_2003\_dafx2003.pdf",
	timestamp = "2007.07.05",
	title = "{ALGORITHM FOR THE SEPARATION OF HARMONIC SOUNDS WITH TIME-FREQUENCY SMOOTHNESS CONSTRAINT}",
	year = 2003
}

@article{Virtanen_Klapuri_ICASSP_2002,
	abstract = "A signal processing method is described, which separates har- monic sounds by applying linear models for the overtone series of sounds. Time-varying sinusoidal parameters are estimated in an iterative algorithm which is initialized using a multipitch estimator that Ã¯Â¬Ânds the number of concurrent sounds and their frequency components. The iterative process then improves the estimates using the least-squares criterion. The harmonic stucture is retained by keeping the frequency ratio of overtones constant over time. Overlapping frequency components are resolved by using linear models for the overtone amplitudes. In practice, the models retain the spectral continuity of natural sounds. Simulation experiments were done using some basic structures for the linear models. These include polynomial, mel-cepstal and frequency-band model. Dem- onstration signals are available at http://www.cs.tut.Ã¯Â¬Â/~tuomasv/ demopage.html.",
	author = "Virtanen, Tuomas and Klapuri, Anssi",
	journal = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	keywords = "SEPARATION HARMONIC SOUNDS LINEAR MODELS OVERTONE SERIES",
	lockkey = "N",
	note = "Signal Processing Laboratory, Tampere University of Technology P.O.Box 553, FIN-33101 Tampere, Finland tuomasv@cs.tut.fi, klap@cs.tut.fi",
	owner = "degottex",
	pdf = "Virtanen\_Klapuri\_ICASSP\_2002\_icassp2002.pdf",
	timestamp = "2007.07.05",
	title = "{SEPARATION OF HARMONIC SOUNDS USING LINEAR MODELS FOR THE OVERTONE SERIES}",
	year = "2002"
}

@article{Virtanen_Klapuri_ICASSP_2000,
	abstract = "In this paper, an approach for the separation of harmonic sounds is described. The overall system consists of three components. Sinusoidal modeling is Ã¯Â¬Ârst used to analyze the mixed signal and to obtain the frequencies and amplitudes of sinusoidal spectral components. Then a new method is proposed for the calculation of the perceptual distance between pairs of sinusoidal trajectories, according to the implications of recent psychoacoustic knowl- edge. A procedure for classifying the sinusoids into separate sound sources is presented. The system is not designed to separate sounds that have same fundamental frequencies. However, a solu- tion to detect single colliding sinusoids is given. Demonstrations of synthesized signals are available at http://www.cs.tut.Ã¯Â¬Â/~tuo- masv/demopage.html.",
	author = "Virtanen, Tuomas and Klapuri, Anssi",
	journal = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	keywords = "SEPARATION HARMONIC SOUND SOURCES SINUSOIDAL MODELING",
	lockkey = "N",
	note = "tuomasv@cs.tut.fi, klap@cs.tut.fi Signal Processing Laboratory, Tampere University of Technology P.O.Box 553, FIN-33101 Tampere, FINLAND",
	owner = "degottex",
	pdf = "Virtanen\_Klapuri\_ICASSP\_2000\_2718\_159.pdf",
	timestamp = "2007.07.05",
	title = "{SEPARATION OF HARMONIC SOUND SOURCES USING SINUSOIDAL MODELING}",
	year = "2000"
}

@article{Viterbi1967,
	author = "Viterbi, A. J.",
	comment = "papier fondateur de Viterbi",
	journal = "IEEE TIT",
	lockkey = "Y",
	owner = "norwin",
	pages = "260--269",
	timestamp = "2007.12.01",
	title = "{Error bounds for convolutional codes and an asymptotically optimum decoding algorithm}",
	volume = "13(2)",
	year = 1967
}

@misc{Warwick_Transcription_2006,
	abstract = "Musical sounds may be produced in an inÃ¯Â¬Ânite variety of ways, both by traditional instruments (violins and so forth) or more modern devices, such as synthesizers. As a result there is an inÃ¯Â¬Ânite number of possible sounds which may be employed in a musical piece. However, for the purposes of this work it is assumed that all sounds employed in the sorts of music to be analysed may be adequately described by four physical parameters, which have corresponding psychological correlates [14]. [...]",
	author = "Warwick",
	keywords = "Signals Music Transcription",
	lockkey = "N",
	owner = "norwin",
	pdf = "Warwick\_Transcription\_2006\_cs-rr-252.pdf",
	timestamp = "2007.07.06",
	title = "{Musical Signals and Music Transcription}",
	year = "2006"
}

@article{Weber_Wet_Cranen_Boves_Bengio_Bourlard_ICSLP_2002,
	abstract = "This paper investigates possibilities to automatically Ã¯Â¬Ând a low- dimensional, formant-related physical representation of the speech signal, which is suitable for automatic speech recognition (ASR). This aim is motivated by the fact that formants have been shown to be discriminant features for ASR. Combinations of automatically extracted formant-like features and {\lq}conventional{\rq}, noise- robust, state-of-the-art features (such as MFCCs including spectral subtraction and cepstral mean subtraction) have previ- ously been shown to be more robust in adverse conditions than state-of-the-art features alone. However, it is not clear how these automatically extracted formant-like features behave in compari- son with true formants. The purpose of this paper is to investigate two methods to automatically extract formant-like features, and to compare these features to hand-labeled formant tracks as well as to standard MFCCs in terms of their performance on a vowel classiÃ¯Â¬Âcation task.",
	author = "Weber, Katrin and {de Wet}, Febe and Cranen, Bert and Boves, Loe and Bengio, Samy and Bourlard, Herv{\'e}",
	journal = "ICSLP",
	keywords = "EVALUATION FORMANT LIKE FEATURES ASR",
	lockkey = "N",
	note = "1 IDIAP - Dalle Molle Institute of Perceptual ArtiÃ¯Â¬Âcial Intelligence, Martigny, Switzerland 2 EPFL - Swiss Federal Institute of Technology, Lausanne, Switzerland 3Department of Language and Speech, University of Nijmegen, The Netherlands email: {weber, bengio, bourlard}@idiap.ch, {F.de.Wet, B.Cranen, L.Boves}@let.kun.nl",
	owner = "norwin",
	pdf = "Weber\_Wet\_Cranen\_Boves\_Bengio\_Bourlard\_ICSLP\_2002\_WeberICSLP02.pdf",
	timestamp = "2007.07.06",
	title = "{EVALUATION OF FORMANT-LIKE FEATURES FOR ASR}",
	year = "2002"
}

@article{Wittenberg_ICASSP_1997,
	abstract = "A semi-automatic motion analysis software is used to extract elongation-time diagrams (trajectories) of vocal fold vibrations from digital high-speed video sequences. By combining digital image processing with biomechanical modeling we extract characteristic parameters such as phonation onset time and pitch. A modified two-mass model of the vocal folds is employed in order to fit the main features of the simulated time series to those of the extracted trajectories. Due to the variation of the model parameters, general conclusions can be made about laryngeal dysfunctions such as functional dysphonia. We show the first results of semi-automatic motion analysis in combination with model simulations as a step towards a computer aided diagnosis of voice disorders",
	author = "Wittenberg, T. and Mergell, P. and Tigges, M. and Eysholdt, U.",
	journal = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	lockkey = "N",
	owner = "norwin",
	pages = "1663--1666",
	timestamp = "2007.12.01",
	title = "{Quantitative characterization of functional voice disorders usingmotion analysis of high-speed video and modeling}",
	volume = "3",
	year = "1997"
}

@inproceedings{Wittenberg_BFDM_1996,
	abstract = "A digital high-speed camera in combination with a light intensi er and a exible endoscope is used to record running human speech. Due to the light absorbtion of the exible endo- scope, the recorded image sequences are too dark for human examination and too poor for digital motion analysis. Therefore, two di erent image enhancement methods are com- pared to improve the image sequences. Resulting trajectories of motion analysis of vocal cord vibrations during running speech will be shown.",
	author = "Wittenberg, T. and Mergell, P. and Tigges, M. and Eysholdt, U.",
	booktitle = "{Bildverarbeitung f{\"u}r die Medizin}",
	ee = "http://sunsite.informatik.rwth-aachen.de/Publications/CEUR-WS/Vol-6/OP_019.ps",
	lockkey = "N",
	title = "{Highspeedglottography with a flexible endoscope for the examination of the human larynx during running speech.}",
	year = "1996"
}

@article{Wu_Wang_IEEETSAP_2003,
	abstract = "An effective multipitch tracking algorithm for noisy speech is critical for acoustic signal processing. However, the performance of existing algorithms is not satisfactory. In this paper, we present a robust algorithm for multipitch tracking of noisy speech. Our approach integrates an improved channel and peak selection method, a new method for extracting periodicity information across different channels, and a hidden Markov model (HMM) for forming continuous pitch tracks. The resulting algorithm can reliably track single and double pitch tracks in a noisy environment. We suggest a pitch error measure for the multipitch situation. The proposed algorithm is evaluated on a database of speech utterances mixed with various types of interference. Quantitative comparisons show that our algorithm significantly outperforms existing ones.",
	author = "Wu, Mingyang and Wang, DeLiang and Brown, Guy J.",
	journal = "IEEETSAP",
	keywords = "Channel selection correlogram hidden Markov model HMM multipitch tracking noisy speech pitch detection",
	lockkey = "N",
	month = "may",
	owner = "degottex",
	pages = "229",
	pdf = "Wu\_Wang\_IEEETSAP\_2003\_tsap2003-1.pdf",
	timestamp = "2007.07.05",
	title = "{A Multipitch Tracking Algorithm for Noisy Speech}",
	volume = "11",
	year = "2003"
}

@misc{Wohlk_DynProg_2004,
	author = "W{\o}hlk, Sanne",
	keywords = "DYPSA Dynamic Programming Simulated Annealing Routing Scheduling",
	lockkey = "N",
	owner = "norwin",
	pdf = "Wohlk\_DynProg\_2004\_DMF-2004-02-002-v1.pdf",
	timestamp = "2007.07.06",
	title = "{Combining Dynamic Programming and Simulated Annealing}",
	year = "2004"
}

@article{YegnanarayanaB1992,
	author = "Yegnanarayana and Murthy",
	journal = "IEEETSP",
	keywords = "Significance Group Delay Functions Spectrum",
	lockkey = "Y",
	month = "september",
	owner = "degottex",
	pdf = "Yegnanarayana\_Murthy\_IEEETSP\_1992\_Significance of group delay functions in spectrum estimation.pdf",
	timestamp = "2007.07.05",
	title = "{Significance of Group Delay Functions in Spectrum}",
	volume = "40",
	year = "1992"
}

@other{Yegnanarayana1991,
	author = "Yegnanarayana, B. and Murthy, H. and Ramachandran, V.",
	booktitle = "{Proc. Int. Conf. on Audio, Speech and Signal Proc.}",
	lockkey = "N",
	owner = "degottex",
	timestamp = "2008.03.03",
	title = "{Processing of Noisy Speech using Modified Group Delay Functions}",
	year = "1991"
}

@article{YegnanarayanaB1984,
	abstract = "In this paper we discuss the problem of signal reconstruction from spectral magnitude or phase using group delay functions. We define two separate group delay functions for a signal, one is derived from the magnitude and the other from the phase of the Fourier transform of the signal. The group delay functions offer insight into the problem of signal reconstruction and suggest methods for reconstructing signals from partial information sucha s spectral magnitude opr hase. We examine the problem of signal reconstruction from spectral magnitude or phase on the basis of these two group delay functions and derive the conditions for signal reconstruction. Based on existing iterative and nonilerative algorithms for signal reconstruction, we propose new algorithms for some special classes of signals. The algorithms are illustrated with several examples. Our study shows that the relative importance of spectral magnitude and phase depends on the natuorfe s ignals. Speech signals are used to illustrate 
the importance of spectral magnitude and picture signals are used to illustrate the importance of phase in signal reconstruction problems. Using the group delay functions, we explain the convergence behavior of the existing iterative algorithms for signal reconstruction.",
	author = "YEGNANARAYANA, B. and SAIKIA, D. K. and KRISHNAN, T. R.",
	journal = "IEEE Trans. ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING,",
	keywords = "group delay phase reconstruction",
	lockkey = "Y",
	month = "JUNE",
	owner = "degottex",
	pdf = "YEGNANARAYANA\_SAIKIA\_KRISHNAN\_IEEE\_1984\_Significance of Group Delay Functions in Signal Reconstruction from Spectral Magnitude or Phase.pdf",
	timestamp = "2007.03.06",
	title = "{Significance of Group Delay Functions in Signal Reconstruction from Spectral Magnitude or Phase}",
	volume = "ASSP-32, NO. 3",
	year = "1984"
}

@article{YegnanarayanaB1985,
	abstract = "A method of signal waveform estimation from an ensemble of jittered noisy measurements is presented. The method uses group delay functions to perform theensemble averaging and thus overcomes the difficulty of computing the unwrapped phase function beforeaver- aging. We propose a new technique, called group delay processing, to estimate thesignal waveform if only a single noisy measurement isavail- able. We demonstrate our group delay averaging and group delay pro- cessing techniques through illustrative examples.",
	author = "YEGNANARAYANA, B. and SREEKANTH, J. and RANGARAJAN, ANAND",
	journal = "IEEETASSP",
	keywords = "Waveform Estimation Group Delay",
	lockkey = "Y",
	month = "august",
	owner = "degottex",
	pages = "832",
	pdf = "YEGNANARAYANA\_SREEKANTH\_RANGARAJAN\_IEEETASSP\_1985\_Waveform estimation using group delay processing.pdf",
	timestamp = "2007.07.05",
	title = "{Waveform Estimation Using Group Delay Processing}",
	volume = "33",
	year = "1985"
}

@article{YegnanarayanaB1998,
	abstract = "We propose methods to track natural variations in the characteristics of the vocal-tract system from speech signals. We are especially interested in the cases where these characteristics vary over time, as happens in dynamic sounds such as consonant-vowel transitions. We show that the selection of appropriate analysis segments is crucial in these methods, and we propose a selection based on estimated instants of significant excitation. These instants are obtained by a method based on the average group-delay property of minimum-phase signals. In voiced speech, they correspond to the instants of glottal closure. The vocal-tract system is characterized by its formant parameters, which are extracted from the analysis segments. Because the segments are always at the same relative position in each pitch period, in voiced speech the extracted formants are consistent across successive pitch periods. We demonstrate the results of the analysis for several difficult cases of speech signals.",
	author = "Yegnanarayana, B. and Veldhuis, Raymond N. J.",
	journal = "IEEE Trans. ON SPEECH AND AUDIO PROCESSING",
	keywords = "Formant analysis speech analysis",
	lockkey = "Y",
	month = "JULY",
	owner = "degottex",
	pages = "313--327",
	pdf = "Yegnanarayana\_Veldhuis\_IEEE\_1998\_Extraction of vocal-tract system characteristics from speech signals.pdf",
	timestamp = "2007.03.07",
	title = "{Extraction of Vocal-Tract System Characteristics from Speech Signals}",
	volume = "6.4",
	year = "1998"
}

@article{ZhuD2004,
	abstract = "Mel-frequency cepstral coefficients (MFCCs) are the most widely used features for speech recognition. These are derived from the power spectrum of the speech signal. Recently, the cepstral features derived from the modified group delay function (MGDF) have been studied by Murthy and Gadde [6] for speech recognition. In this paper, we propose to use the product of the power spectrum and the group delay function (GDF), and derive the MFCCs from the product spectrum. This spectrum combines the information from the magnitude spectrum as well as the phase spectrum. The MFCCs of the MGDF are also investigated in this paper. Results show that the cepstral features derived from the power spectrum perform better than that from the MGDF, and the product spectrum based features provide the best performance.",
	author = "Zhu, Donglai and Paliwal, Kuldip K.",
	journal = "IEEE International Conference on Acoustics, Speech and Signal Processing ",
	lockkey = "Y",
	owner = "degottex",
	pdf = "Zhu\_Paliwal\_ICASSP\_2004\_Product\_power\_spectrum\_Grp\_delay\_ASR.pdf",
	timestamp = "2007.03.01",
	title = "{PRODUCT OF POWER SPECTRUM AND GROUP DELAY FUNCTION FOR SPEECH RECOGNITION}",
	year = "2004"
}

@misc{NONAME_SIMPLEX_2003,
	abstract = "In this chapter, we put the theory developed in the last to practice. We develop the simplex method algorithm for LP problems given in feasible canonical form and standard form. We also discuss two methods, the M -Method and the Two-Phase Method, that deal with the situation that we have an infeasible starting basic solution.",
	keywords = "SIMPLEX METHOD",
	lockkey = "N",
	owner = "norwin",
	pdf = "NONAME\_SIMPLEX\_2003\_Simplex Method - lpch3.pdf",
	timestamp = "2007.07.06",
	title = "{SIMPLEX METHOD}",
	year = "2003"
}

@misc{NONAME_articulatory_2002,
	abstract = "Early research in analysis, synthesis and coding of voice has traditionally focused on the vocal tract Ã¯Â¬Âlter, paying less attention to the source signal. Especially in the last decade, however, more emphasis has been given to the characteristics of the glottal source waveform: the development of a good model for the glottal excitation has been recognized to be a key feature for obtaining high quality speech synthesis, and for characterizing voice quality (e.g. modal voice, vocal fry, breathy voice [6, 32]). [...]",
	keywords = "Source models articulatory speech synthesis",
	lockkey = "N",
	owner = "degottex",
	pdf = "NONAME\_articulatory\_2002\_ch4.pdf",
	timestamp = "2007.07.05",
	title = "{Source models for articulatory speech synthesis}",
	year = "2002"
}

@book{Brent1973,
	author = "Brent, R. P.",
	lockkey = "Y",
	publisher = "Prentice-Hall",
	title = "{Algorithms for Minimization without derivatives}",
	year = "1973"
}

@article{Fant1995,
	author = "Fant, G.",
	file = "file:///data/anasynth/degottex/articles/db/Fant1995\_36\_2-3\_119-156.pdf",
	journal = "STL-QPSR",
	lockkey = "Y",
	number = "2-3",
	pages = "119--156",
	title = "{The {LF}-model revisited. Transformations and frequency domain analysis.}",
	volume = "36",
	year = "1995"
}

@book{Markel1976short,
	author = "Markel, J and Gray, A",
	lockkey = "Y",
	publisher = "Springer Verlag",
	title = "{Linear Prediction of Speech}",
	year = 1976
}

@misc{UNKNOWN2005,
	author = "UNKNOWN",
	file = "file:///data/anasynth/degottex/articles/db/LSP2005\_lsp.pdf",
	lockkey = "Y",
	title = "{Line spectral pairs}",
	year = "2005"
}

@misc{Moreau2007,
	author = "Moreau, N.",
	file = "file:///data/anasynth/degottex/articles/db/Moreau2007\_Outils\%20pour\%20la\%20compression.pdf",
	lockkey = "N",
	month = "novembre",
	title = "{Outils pour la compression Application {\`a} la compression des signaux audio}",
	year = "2007"
}

@inproceedings{Niessen2007,
	abstract = "The performance of automatic speech recognition (ASR) systems is seriously degraded in reverberant environments. We propose a method for assessing the reverberation level in speech that makes it possible to determine in real-time whether a speech signal is reverberant or not. Reverberation causes an increase in the variation of the energy and frequency of harmonics in speech. Speech with a variable pitch is especially affected by reverberation. To capture the effect of reverberation we measured six features on the harmonics of the speech signal, which represent energy and frequency variation in different ways. Speech from the Aurora database was artificially reverberated to demonstrate the validity of these features. Each feature predicted reverberation time for a different subset of the dataset. To test the overall separability of the speech samples using these features, speech from the dataset was automatically classified as being either inside or outside the reverberation radius. Most of the 
speech was correctly classified, which suggests that a reliable real-time classification algorithm can be developed to select good-quality speech. This algorithm can improve pre-processing methods, such as speech enhancement or voice activity detection, for more robust ASR.",
	author = "{Maria Niessen}, Dirkjan Krijnders Joep Boers Tjeerd Andringa",
	booktitle = "{19th INTERNATIONAL CONGRESS ON ACOUSTICS}",
	lockkey = "N",
	title = "{ASSESSING THE REVERBERATION LEVEL IN SPEECH}",
	year = "2007"
}

@article{Childers1977,
	abstract = "This paper is a pragmatic tutorial review of the cepstrum literature focusing on data processing. The power, complex, and phase cepstra are shown to be easily related to one another. Problems associated with phase unwrapping, linear phase components, spectrum notching, aliasing, oversampling, and extending the data sequence with zeros are discussed. The advantages and disadvantages of windowing the sampled data sequence, the log spectrum, and the complex cepstrum are presented. The influence of noise upon the data processing procedures is discussed throughout the paper, but is not thoroughly analyzed. The effects of various forms of liftering the cepstrum are described. The results obtained by applying whitening and trend removal techniques to the spectrum prior to the calculation of the cepstrum are discussed. We have attempted to synthesize the results, procedures, and information peculiar to the many fields that are finding cepstrum analysis useful. In particular we discuss the interpretation 
and processing of data in such areas as speech, seismology, and hydroacoustics. But we must caution the reader that the paper is heavily influenced by our own experiences; specific procedures that have been found useful in one field should not be considered as totally general to other fields. It is hoped that this review will be of value to those familiar with the field and reduce the time required for those wishing to become so.",
	author = "Childers, D. G. and Skinner, D. P. and Kemerait, R. C.",
	booktitle = "{Proceedings of the IEEE}",
	citeulike-article-id = "1595841",
	journal = "Proceedings of the IEEE",
	keywords = "cepstrum; dsp; speech; speech-recognition; tutorial",
	lockkey = "Y",
	number = "10",
	pages = "1428--1443",
	posted-at = "2007-08-27 09:59:54",
	priority = "2",
	title = "{The cepstrum: A guide to processing}",
	url = "http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1455016",
	volume = "65",
	year = "1977"
}

@article{Kim2006,
	address = "New York, NY, United States",
	author = "Kim, Chanwoo and Seo, Kwang-deok and Sung, Wonyong",
	doi = "10.1155/ASP",
	issn = "1110-8657",
	journal = "EURASIP J. Appl. Signal Process.",
	lockkey = "N",
	number = "1",
	pages = "33--33",
	publisher = "Hindawi Publishing Corp.",
	title = "{A robust formant extraction algorithm combining spectral peak picking and root polishing}",
	volume = "2006",
	year = "2006"
}

@article{Lulich2007,
	adsnote = "Provided by the SAO/NASA Astrophysics Data System",
	adsurl = "http://adsabs.harvard.edu/abs/2007ASAJ..122.2320L",
	author = "Lulich, S. and Bachrach, A. and Malyska, N.",
	doi = "10.1121/1.2772227",
	journal = "Acoustical Society of America Journal",
	lockkey = "N",
	pages = "2320--+",
	title = "{A role for the second subglottal resonance in lexical access}",
	volume = 122,
	year = 2007
}

@article{Lasota1985,
	adsurl = "http://adsabs.harvard.edu/abs/1985ASAJ...78.1086L",
	author = "Lasota, H.",
	doi = "10.1121/1.393027",
	journal = "Acoustical Society of America Journal",
	lockkey = "N",
	month = sep,
	pages = "1086--1092",
	title = "{Diffraction of acoustic plane waves: A time-domain analysis}",
	volume = 78,
	year = 1985
}

@article{ImaiS1979,
	author = "Imai, S. and Abe, Y.",
	journal = "Electronics and Communication",
	lockkey = "Y",
	note = "in japanese",
	number = "4",
	pages = "10--17",
	title = "{Spectral envelope extraction by improved cepstral method}",
	volume = "62-A",
	year = "1979"
}

@inproceedings{Yeh2004a,
	author = "Yeh, C. and Roebel, A.",
	booktitle = "{Proc. Digital Audio Effects (DAFx)}",
	lockkey = "Y",
	pages = "234--239",
	statut-editorial = "publi{\'e}",
	title = "{A new score function for joint evaluation of multiple F0 hypothesis}",
	url = "http://mediatheque.ircam.fr/articles/textes/Yeh04a",
	year = 2004
}

@article{NaylorPA2007,
	abstract = "We present the Dynamic Programming Projected Phase-Slope Algorithm (DYPSA) for automatic estimation of glottal closure instants (GCIs) in voiced speech. Accurate estimation of GCIs is an important tool that can be applied to a wide range of speech processing tasks including speech analysis, synthesis and coding. DYPSA is automatic and operates using the speech signal alone without the need for an EGG signal. The algorithm employs the phase-slope function and a novel phase-slope projection technique for estimating GCI candidates from the speech signal. The most likely candidates are then selected using a dynamic programming technique to minimize a cost function that we define. We review and evaluate three existing methods of GCI estimation and compare the new DYPSA algorithm to them. Results are presented for the APLAWD and SAM databases for which 95.7\% and 93.19\% of GCI's are correctly identified.",
	author = "Naylor, P. A. and Kounoudes, A. and Gudnason, J. and Brookes, M.",
	journal = "IEEE Trans. on Audio, Speech and Language Processing",
	lockkey = "Y",
	number = "1",
	pages = "34--43",
	title = "{Estimation of Glottal Closure Instants in Voiced Speech using the {DYPSA} algorithm}",
	volume = "15",
	year = "2007"
}

@article{Fu2006,
	abstract = "This paper describes a robust glottal source estimation method based on a joint source-filter separation technique. In this method, the Liljencrants-Fant (LF) model, which models the glottal flow derivative, is integrated into a time-varying ARX speech production model. These two models are estimated in a joint optimization procedure, in which a Kalman filtering process is embedded for adaptively identifying the vocal tract parameters. Since the formulated joint estimation problem is a multiparameter nonlinear optimization procedure, we separate the optimization procedure into two passes. The first pass initializes the glottal source and vocal tract models by solving a quasi-convex approximate optimization problem. Having robust initial values, the joint estimation procedure determines the accuracy of model estimation implemented with a trust-region descent optimization algorithm. Experiments with synthetic and real voice signals show that the proposed method is a robust glottal source parameter 
estimation method with a high degree of accuracy.",
	author = "Fu, Qiang and Murphy, P.",
	doi = "10.1109/TSA.2005.857807",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	keywords = "Kalman filtering process; Liljencrants-Fant model; joint source-filter model optimization; multiparameter nonlinear optimization procedure; robust glottal source estimation; speech production model; trust-region descent optimization algorithm; vocal tract models; Kalman filters; adaptive filters; filtering theory; parameter estimation; speech processing",
	lockkey = "Y",
	number = "2",
	pages = "492--501",
	title = "{Robust glottal source estimation based on joint source-filter model optimization}",
	volume = "14",
	year = "2006"
}

@book{Oppenheim1978com,
	author = "Oppenheim, A. V. and Schafer, R. W.",
	lockkey = "Y",
	note = "note that this edition contains a chapter about complex cepstrum which has been removed in the 3rd edition (and seems to come back in the 4th)",
	publisher = "Prentice-Hall, 2nd edition",
	title = "{Digital Signal Processing}",
	year = "1978"
}

@inproceedings{Peeters1999a,
	address = "Orlando, USA",
	author = "Peeters, Geoffroy and Rodet, Xavier",
	booktitle = "{ICSPAT (DSP-World)}",
	editor = "{Miller Freeman}, Inc.",
	lockkey = "Y",
	month = "Novembre",
	statut-editorial = "publi{\'e}",
	title = "{Non-Stationary Analysis/Synthesis using Spectrum Peak Shape Distortion, Phase and Reassignement}",
	year = "1999"
}

@phdthesis{Chauvet2004,
	author = "Chauvet",
	lockkey = "N",
	school = "www",
	title = "{LPTV}",
	year = "2004"
}

@article{Maeda1988,
	author = "Maeda, S.",
	journal = "Journal of Acoustic Society of America",
	lockkey = "Y",
	title = "{Improved articulatory models}",
	year = 1988
}

@article{Maeda1979,
	author = "Maeda, Shinji",
	doi = "10.1121/1.2017158",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "S1",
	pages = "S22--S22",
	publisher = "ASA",
	title = "{An articulatory model of the tongue based on a statistical analysis}",
	url = "http://link.aip.org/link/?JAS/65/S22/2",
	volume = "65",
	year = "1979"
}

@article{Steckner1989,
	abstract = "The use of the Hartley Transform (HT) in cepstrum analysis, as a substitute for the more commonly used Fourier Transform (FT), is examined. With this substitution, the input to the cepstrum must be in the real domain only. The benefits of using the HT are: ~50 percent less data memory required and ~40 percent faster program execution, at no loss in accuracy.",
	author = "Steckner, Michael C. and Drost, Dick J.",
	journal = "IEEE Trans. on Acoustics, Speech. and Signal Processing",
	lockkey = "N",
	number = "8",
	title = "{Fast Cepstrum Analysis Using the Hartley Transform}",
	volume = "37",
	year = "1989"
}

@article{Nelson2002,
	abstract = "We present methods, based on the short time Fourier transform, which may be used to analyze the structure of multicomponent FM modulated signals instantaneously in time and frequency. The methods build on previously presented cross-spectral methods. In this paper, we introduce the concept of higher order short time Fourier transform phase derivatives, which may be used to estimate signal trajectories instantaneously in both time and frequency and to determine convergence of the remapped time-- frequency surface. The methods are applied to synthesized data and speech signals.",
	author = "Nelson, Douglas J.",
	journal = "Digital Signal Processing",
	keywords = "cross-spectrum; phase-spectrum; spectral estimation; short time Fourier transform; time--frequency representation; derivatives",
	lockkey = "Y",
	pages = "416--428",
	title = "{Instantaneous Higher Order Phase Derivatives}",
	volume = "12",
	year = 2002
}

@article{Oppenheim1968,
	author = "Oppenheim, A. and Schafer, R. and Stockham, T.",
	journal = "Proceedings of the IEEE",
	keywords = "cepstrum; complexe cepstrum",
	lockkey = "Y",
	number = "8",
	pages = "1264--1291",
	title = "{Nonlinear filtering of multiplied and convolved signals}",
	volume = "56",
	year = 1968
}

@article{Kopec1977,
	author = "Kopec, G. and Oppenheim, A. and Tribolet, J.",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	keywords = "cepstrum; homomorphic prediction",
	lockkey = "Y",
	number = "1",
	pages = "40--49",
	title = "{Speech analysis by homomorphic prediction}",
	volume = "25",
	year = 1977
}

@article{Oppenheim1976,
	author = "Oppenheim, A. and Kopec, G. and Tribolet, J.",
	journal = "IEEE Trans. ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING",
	keywords = "cepstrum; homomorphic prediction",
	lockkey = "Y",
	month = "Aug.",
	number = 4,
	pages = "327--332",
	title = "{Signal Analysis by Homomorphic Prediction}",
	volume = "ASSP-24",
	year = 1976
}

@article{Oppenheim2004,
	author = "Oppenheim, A. and Schafer, R.",
	journal = "IEEE SIGNAL PROCESSING MAGAZINE",
	keywords = "cepstrum",
	lockkey = "Y",
	month = "Sep.",
	pages = "95--106",
	title = "{From Frequency to Quefrency: A History of the Cepstrum}",
	year = 2004
}

@article{Krajnik1992,
	author = "Krajnik, E.",
	journal = "Signal Processing VI: Theories and Applications",
	keywords = "phase; unwrapping",
	lockkey = "Y",
	pages = "917--919",
	title = "{A simple and reliable phase unwrapping algorithm}",
	year = 1992
}

@article{SteiglitzK1982,
	author = "Steiglitz, K. and Dickinson, B.",
	journal = "{IEEE} Trans. Acoustics, Speech and Signal Processing",
	keywords = "phase; unwrapping",
	lockkey = "Y",
	month = "Dec.",
	number = 6,
	pages = "984",
	title = "{Phase Unwrapping by Factorization}",
	volume = "{ASSP-30}",
	year = 1982
}

@article{Tribolet1977,
	author = "Tribolet, J. M.",
	by_date = "Rg",
	by_rev = "Le",
	country = "USA",
	date = "22/09/88",
	descriptors = "Mathematics;",
	enum = "3136",
	journal = "IEEE trans. on Accoustics, Speech and Signal Process.",
	keywords = "phase; unwrapping",
	language = "English",
	location = "UniS-IND",
	lockkey = "Y",
	pages = "170--177",
	references = "1",
	revision = "21/04/91",
	title = "{A New Phase Unwrapping Algorithm}",
	volume = "ASSP-25",
	year = 1977
}

@article{Kemerait1972,
	abstract = "A technique for decomposing a composite signal of unknown multiple wavelets overlapping in time is described. The computation algorithm incorporates the power cepstrum and complex cepstrum techniques. It has been found that the power cepstrum is most efficient in recognizing wavelet arrival times and amplitudes while the complex cepstrum is invaluable in estimating the form of the basic wavelet and its echoes, even if the latter are distorted. Digital data-processing problems such as the detection of multiple echoes, various methods of linear filtering the complex cepstrum, the picket-fence phenomenon, minimum-maximum phase situations, and amplitude- versus phase-smoothing for the additive-noise case are examined empirically and where possible theoretically, and are discussed. A similar investigation is performed for some of the preceding problems when the echo or echoes are distorted versions of the wavelet, thereby giving some insight into the complex problem of separating a composite signal 
composed of several additive stochastic processes. The threshold results are still empirical and the results should be extended to multi-dimensional data. Applications are the decomposition or resolution of signals (e.g., echoes) in radar and sonar, seismology, speech, brain waves, and neuroelectric spike data. Examples of results are presented for decomposition in the absence and presence of noise for specified signals. Results are tendered for the decomposition of pulse-type data appropriate to many systems and for the decomposition of brain waves evoked by visual stimulation.",
	author = "Kemerait, R. and Childers, D.",
	journal = "IEEE Trans. on Information Theory",
	keywords = "cepstrum; complex cepstrum",
	lockkey = "Y",
	month = "Nov.",
	number = 6,
	pages = "745--759",
	title = "{Signal detection and extraction by cepstrum techniques}",
	volume = "18",
	year = 1972
}

@article{Kim2007,
	abstract = "This letter describes a two-band excitation model for HMM-based speech synthesis. The HMM-based speech synthesis system generates speech from the HMM training data of the spectral and excitation parameters. Synthesized speech has a typical quality of ``vocoded sound'' mostly because of the simple excitation model with the voiced/unvoiced selection. In this letter, two-band excitation based on the harmonic plus noise speech model is proposed for generating the mixed excitation source. With this model, we can generate the mixed excitation more accurately and reduce the memory for the trained excitation data as well.",
	address = "Oxford, UK",
	author = "Kim, S.-J. and Hahn, M.",
	doi = "10.1093/ietisy",
	issn = "0916-8532",
	journal = "IEICE - Trans. on Information and Systems",
	keywords = "excitation model; HMM-based speech synthesis; maximum voiced frequency; VUF",
	lockkey = "Y",
	number = 1,
	pages = "378--381",
	publisher = "Oxford University Press",
	title = "{Two-Band Excitation for {HMM}-Based Speech Synthesis}",
	volume = "E90-D",
	year = 2007
}

@inproceedings{Clark2009,
	abstract = "Modulation Ã¯Â¬Âltering is a technique for Ã¯Â¬Âltering slowly-varying en- velopes of frequency subbands of a nonstationary signal, ideally without affecting the signal{\rq}s phase and Ã¯Â¬Âne-structure. Coherent modulation Ã¯Â¬Âltering is a promising subtype of such techniques where subband envelopes are determined through demodulation of the sub- band signal with a coherently detected subband carrier. In this paper we demonstrate how modulation Ã¯Â¬Âltering, when done coherently, is far more effective than standard incoherent methods. We show that empirical results can be made to be almost ideal, and signiÃ¯Â¬Âcantly better than previous coherent attempts, as long as Ã¯Â¬Âne-structure in- formation is retained as side information and the Ã¯Â¬Âlterbank reduces subband interference.",
	author = "Clark, P. and Atlas, L.",
	booktitle = "{IEEE International Conference on Acoustics, Speech and Signal Processing }",
	keywords = "modulation; time-varying Ã¯Â¬Âlters; acoustic signal processing; speech processing",
	lockkey = "Y",
	title = "{A SUM-OF-PRODUCTS MODEL FOR EFFECTIVE COHERENT MODULATION FILTERING}",
	year = 2009
}

@inproceedings{Mitra2009,
	abstract = "In this paper we present a technique for obtaining Vocal Tract (VT) time functions from the acoustic speech signal. Knowledge- based Acoustic Parameters (APs) are extracted from the speech signal and a pertinent subset is used to obtain the mapping between them and the VT time functions. Eight different vocal tract constriction variables consisting of five constriction degree variables, lip aperture (LA), tongue body (TBCD), tongue tip (TTCD), velum (VEL), and glottis (GLO); and three constriction location variables, lip protrusion (LP), tongue tip (TTCL), tongue body (TBCL) were considered in this study. The TAsk Dynamics Application model (TADA [1]) is used to create a synthetic speech dataset along with its corresponding VT time functions. We explore Support Vector Regression (SVR) followed by Kalman smoothing to achieve mapping between the APs and the VT time functions.",
	author = "V.Mitra and {\"O}zbek, Y. and Nam, H. and Zhou, X. and Espy-Wilson, C. Y.",
	booktitle = "{ICASSP}",
	keywords = "Speech inversion; Support Vector Regression; vocal tract time functions; Acoustic-to-articulatory inversion.",
	lockkey = "Y",
	title = "{FROM ACOUSTICS TO VOCAL TRACT TIME FUNCTIONS}",
	year = "2009"
}

@article{Moghtaderi2009,
	abstract = "The evolutionary spectrum (ES) is a time-dependent analogue of the spectrum of a stationary process. Existing estimators of the ES suffer from bias problems in the boundary region of the time-frequency domain, due to windowing effects. We pro- pose a new estimator of the ES of a uniformly modulated pro- cess which mitigates these problems. Our estimator is based on an extrapolation of the ES in time, using an estimate of the time derivative of the ES. We apply our estimator to a simu- lated example of a uniformly modulated process with known ES.",
	address = "Los Alamitos, CA, USA",
	author = "Moghtaderi, A. and Takahara, G. and Thomson, D. J.",
	doi = "10.1109/ICASSP.2009.4960253",
	isbn = "978-1-4244-2353-8",
	journal = "Acoustics, Speech, and Signal Processing, IEEE International Conference on",
	keywords = "Spectral Analysis; Stochastic Processes",
	lockkey = "Y",
	pages = "2993--2996",
	publisher = "IEEE Computer Society",
	title = "{Evolutionary spectrum estimation for uniformly modulated processes with improved boundary performance}",
	volume = "0",
	year = 2009
}

@article{Para2009,
	author = "Parra, H. and Randall, L.",
	journal = "Nature",
	lockkey = "Y",
	title = "{Solo journey to a fifth dimension: Hypermusic Prologue: A Projective Opera in Seven Planes}",
	year = 2009
}

@inproceedings{Thomas2009a,
	abstract = "This paper presents a data-driven approach to the modelling of voice source waveforms. The voice source is a signal that is estimated by inverse-filtering speech signals with an estimate of the vocal tract filter. It is used in speech analysis, synthesis, recognition and coding to decompose a speech signal into its source and vocal tract filter components. Existing approaches parameterize the voice source signal with physically- or mathematically-motivated models. Though the models are well-defined, estimation of their parameters is not well understood and few are capable of reproducing the large variety of voice source waveforms. Here we present a data-driven approach to classify types of voice source waveforms based upon their mel frequency cepstrum coefficients with Gaussian mixture modelling. A set of ldquoprototyperdquo waveform classes is derived from a weighted average of voice source cycles from real data. An unknown speech signal is then decomposed into its prototype components and 
resynthesized. Results indicate that with sixteen voice source classes, low resynthesis errors can be achieved.",
	author = "Thomas, M.R.P. and Gudnason, J. and Naylor, P.A.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2009.4960496",
	issn = "1520-6149",
	keywords = "Gaussian mixture modelling; data-driven voice source waveform modelling; inverse-filtering speech signals; parameter estimation; speech analysis; speech coding; speech synthesis; vocal tract filter estimation; Gaussian processes; filtering theory; parameter estimation; speech coding; speech recognition; speech synthesis; tracking filters",
	lockkey = "Y",
	pages = "3965--3968",
	title = "{Data-driven voice soruce waveform modelling}",
	year = "2009"
}

@article{Sun2009,
	author = "Sun, R. and II, E. Moore and Torres, J. F.",
	journal = "ICASSP",
	lockkey = "Y",
	title = "{INVESTIGATING GLOTTAL PARAMETERS FOR DIFFERENTIATING EMOTIONAL CATEGORIES WITH SIMILAR PROSODICS}",
	year = 2009
}

@inproceedings{Schnell2009,
	author = "Schnell, K. and Lacroix, A.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	comment = "Fais beaucoup penser {\`a} un autre article de Schnell sur l'estimation d'un VTF variable. qu'est ce aue ce ``nouvel'' article apporte ?",
	doi = "10.1109/ICASSP.2009.4960509",
	isbn = "978-1-4244-2353-8",
	keywords = "time-varying filters; speech analysis; speech synthesis",
	lockkey = "Y",
	pages = "4017--4020",
	title = "{Iterative inverse filtering by lattice filters for time-varying analysis and synthesis of speech}",
	year = 2009
}

@inproceedings{Bees1991,
	abstract = "Complex cepstral deconvolution is applied to acoustic dereverberation. It is found that traditional cepstral techniques fail in acoustic dereverberation because segmentation errors in the time domain prevent accurate cepstral computation. An algorithm for speech dereverberation which incorporates a novel approach to the segmentation and windowing procedure for speech is presented. Averaging in the cepstrum is exploited to increase the separation between the speech and impulse response. An estimate of the room impulse response is built, and a least squared error inverse filter is used to remove the estimated impulse response from the reverberant speech. Reduction of reverberation with this technique is demonstrated.",
	author = "Bees, D. and Blostein, M. and Kabal, P.",
	booktitle = "{Acoustics, Speech, and Signal Processing, IEEE International Conference on}",
	comment = "Il {\'e}value notement l'impact de la fen{\{\{\{\{\^e}}}}}tre exponentielle sur le cepstre comlexe, sans se rendre compte que cela d{\'e}place le cercle d'{\'e}valuation ... donc sans compenser l'effet de la fen{\{\{\{\{\^e}}}}}tre.",
	keywords = "dereverberation; complexe cepstrum",
	lockkey = "Y",
	pages = "977--980",
	title = "{Reverberant speech enhancement using cepstral processing}",
	year = 1991
}

@inproceedings{BonadaJ2004,
	abstract = "This paper introduces a method to transform voice based on modeling the radiated voice pulses in frequency domain. This approach tries to combine the strengths of lassical time and frequency domain techniques into a single framework, providing both an independent control of each voice pulse and flexible timbre and phase modification capabilities.",
	author = "Bonada, J.",
	booktitle = "{Proc. Digital Audio Effects (DAFx)}",
	keywords = "mixed-phase model; phase envelope; VOICE TRANSFORMATION",
	lockkey = "Y",
	title = "{High Quality Voice Transformations Based On Modeling Radiated Voice Pulses In Frequency Domain}",
	url = "files/publications/DAFX04-jbonada.pdf",
	year = 2004
}

@inproceedings{Bouzid2004,
	abstract = "Nowadays, new techniques of speech processing such as speech recognition and speech synthesis use the glottal clo- sure and opening instants. Recognition techniques use them for the vocal folds description and for the classification of speaker{\rq}s state or for speaker classification, and speech syn- thesis techniques use them for the speech timbre. In an effort to develop techniques that enhance data-driven techniques in speaker characterisation for speech synthesis, this paper describes a new method for automatically deter- mining the location of the closed phase delimited by the glottal closure and opening instants. The proposed approach for detecting the glottal opening is based on multiscale products of wavelet transform of speech signal at different scales with enhancement of edge detection and estimation. It is shown that the method is effective and robust for speech singularity detection such as glottal open- ing instant as product is a processing which reinforces edge detection.",
	author = "Bouzid, A. and Ellouze, N.",
	booktitle = "{EUSIPCO}",
	journal = "EUSIPCO",
	lockkey = "Y",
	pages = "729--732",
	title = "{Glottal opening instant detection from speech signal}",
	year = 2004
}

@article{Crosby1937,
	abstract = "Theory and experimental data are given which show the improve- ments in signal-noise ratio effected byfrequency modulation over amplitude modula- tion. It is shown that abcve a certain carrier-noise ratio in the frequency modulation receiver which is called the ``improvement threshold,'' the frequency modulation signal- noise ratio is greater than the amplitude modulation signal-noise ratio by a factor equal to the product of a constant and the deviation ratio (the deviation ratio is equal to the ratio between the maximum frequency deviation and the audio modulation band width). The constant depends upon the type of noise, being slightly greater for impulse than for fluctuation noise. In frequency modulation systems with high deviation ratios, a higher carrier level is required to reach the improvement threshold than is required in systems with low deviation ratios; this carrier level is higher for impulse than for fluctuation noise. At carrier-noise ratios below the improvement threshold, the 
peak signal-noise ratio characteristics of the frequency modulation receiver are approximately the same as those of the amplitude modulation receiver, but the energy content of the frequency modulation noise is reduced. An effect which is called ``frequency limiting'' is pointed out in which the peak value of the noise is limited to a value not greater than the peak value of the signal. With impulse noise this phenomenon effects a noise suppression in a manner similar to that in the recent circuits for reducing impulse noise which is stronger than the carrier in amplitude modulation reception. When the power gain obtainable in certain types of transmitters by the use of frequency modulation is taken into account, the frequency modulation improvement factors are increased and the improvement threshold is lowered with respect to the carrier-noise ratio existing in a reference amplitude modulation system.",
	author = "Crosby, M. G.",
	journal = "Proceedings of the Institute of Radio Engineers",
	lockkey = "Y",
	title = "{FREQUENCY MODULATION NOISE CHARACTERISTICS}",
	year = 1937
}

@inproceedings{Fu2003,
	abstract = "An adaptive, pitch-synchronous analysis method is proposed for the simultaneous estimation of vocal tract and voice source parameters from speech waveforms. A time varying autoregressive model with exogenous input (ARX) is chosen for vocal tract modeling because of the capability of such a model for characterising both the formants and antiformants of the vocal tract. The Liljencrants-Fant model for the voice source is integrated into an iterative adaptive estimation procedure. Furthermore, an adaptive inverse filtering technique is put forward to obtain high accuracy estimation of the glottal source waveform, which is necessary for the intended application of the method to pathological voice analysis. The technique is evaluated and compared with a number of other approaches using synthetic speech containing additive noise at the source. The results illustrate the superior performance of the new method.",
	author = "Fu, Q. and Murphy, P.",
	booktitle = "{NOLISP}",
	lockkey = "Y",
	title = "{Adaptive Inverse Filtering for High Accuracy Estimation of the Glottal Source}",
	year = 2003
}

@article{Fulop2007,
	abstract = "Two computational methods for pruning a reassigned spectrogram to show only quasisinusoidal components, or only impulses, or both, are presented mathematically and provided with step-by-step algorithms. Both methods compute the second-order mixed partial derivative of the short-time Fourier transform phase, and rely on the conditions that components and impulses are each well-represented by reassigned spectrographic points possessing particular values of this derivative. This use of the mixed second-order derivative was introduced by Nelson J. Acoust. Soc. Am. 110, 2575--2592 2001 but here our goals are to completely describe the computation of this derivative in a way that highlights the relations to the two most inÃ¯Â¬Âuential methods of computing a reassigned spectrogram, and also to demonstrate the utility of this technique for plotting spectrograms showing line components or impulses while excluding most other points. When applied to speech signals, vocal tract resonances formants or 
glottal pulsations can be effectively isolated in expanded views of the phonation process.",
	author = "Fulop, S. A. and Fitz, K.",
	journal = "Journal of Acoustic Society of America",
	keywords = "reassigned spectrogram; sinusoid analysis",
	lockkey = "Y",
	pages = "1510--1518",
	title = "{Separation of components from impulses in reassigned spectrograms}",
	year = 2007
}

@article{Hermus2007,
	abstract = "We present a new algorithm for the estimation of the voicing cut-off frequency (VCO), i.e., the frequency that separates the harmonic low-frequency part from the aperiodic high-frequency part in voiced speech. The VCO is estimated as the frequency for which the sum of the harmonicity scores of all pitch harmonics below that frequency is maximized. The algorithm is combined with a powerful dynamic programming approach to track the VCO estimates over time. Remarkably accurate and smooth VCO contours are obtained, despite the simplicity of the algorithm. Applications include a.o. (sinusoidal) speech modeling, coding, and synthesis, as well as harmonic speech analysis for, e.g., automatic speech recognition.",
	journal = "IEEE Signal Processing Letters",
	keywords = "VUF",
	lockkey = "Y",
	pages = "820--823",
	title = "{Estimation of the Voicing Cut-Off Frequency Contour Based on a Cumulative Harmonicity Score}",
	year = 2007
}

@article{Hu2008,
	abstract = "In this paper, we evaluate the performance of several objective measures in terms of predicting the quality of noisy speech enhanced by noise suppression algorithms. The objective measures considered a wide range of distortions introduced by four types of real-world noise at two signal-to-noise ratio levels by four classes of speech enhancement algorithms: spectral subtractive, subspace, statistical-model based, and Wiener algorithms. The subjective quality ratings were obtained using the ITU-T P.835 methodology designed to evaluate the quality of enhanced speech along three dimensions: signal distortion, noise distortion, and overall quality. This paper reports on the evaluation of correlations of several objective measures with these three subjective rating scales. Several new composite objective measures are also proposed by combining the individual objective measures using nonparametric and parametric regression analysis techniques.",
	author = "Hu, Y. and Loizou, P. C.",
	booktitle = "{Audio, Speech, and Language Processing, IEEE Trans. on}",
	citeulike-article-id = "5219302",
	citeulike-linkout-1 = "http://ieeexplore.ieee.org/xpls/abs\_all.jsp?arnumber=4389058",
	doi = "10.1109/TASL.2007.911054",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing,",
	keywords = "enhancement; evaluation; pesq; speech; composite",
	lockkey = "Y",
	number = 1,
	pages = "229--238",
	posted-at = "2009-07-21 15:51:17",
	priority = "4",
	title = "{Evaluation of Objective Quality Measures for Speech Enhancement}",
	volume = "16",
	year = 2008
}

@inproceedings{Kawahara2005,
	abstract = "A new method for source information extraction is proposed. The aim of the method is to provide optimal source information for the very high quality speech manipulation system STRAIGHT. The method is based on both time interval and frequency cues, and it provides fundamental frequency and periodicity information within each frequency band, to allow mixed mode excitation. The method is designed to minimize perceptual disturbance due to errors in source information extraction. A preliminary evaluation using a database of simultaneously recorded EGG and speech signals yielded very low gross error rates (0.029\% for females and 0.14\% for males). In addition, the method is designed so as to minimize the perceptual disturbance caused by any such gross error.",
	author = "Kawahara, H. and {de Cheveigne}, A. and Banno, H. and Takahashi, T. and Irino, T.",
	booktitle = "{Proc. Interspeech}",
	journal = "Interspeech",
	keywords = "STRAIGHT",
	lockkey = "N",
	pages = "537--540",
	title = "{Nearly Defect-Free F0 Trajectory Extraction for Expressive Speech Modifications Based on {STRAIGHT}}",
	year = 2005
}

@inproceedings{Laprie2003,
	abstract = "Our goal is to recover articulatory information from the speech signal by acoustic- to-articulatory inversion. Like most inversion methods proposed in the literature, our method relies on the analysis-by-synthesis paradigm. After an overall description of the inversion method the paper presents how inversion can be used to investigate acoustic properties of the articulatory model, which helps us to formulate the way of incorporating effective constraints to obtain phonetically realistic inverse solutions. First, the inversion method has been applied to French vowels in order to study the dispersion of vocal tract shapes corresponding to each of these vowels. Second, in addition to increasing the intrinsic quality of the articulatory table, constraints can be incorporated directly in the dynamic programming stage to obtain more realistic inverse trajectories in a sequence of vowels. These constraints derive from phonetic knowledge, such as the observation of the strong protrusion for /y/, of a 
posterior place of articulation for /u/, of a strong mouth opening for /a/ and so on.",
	author = "Laprie, Y. and Ouni, S. and Potard, B. and Maeda, S.",
	booktitle = "{Proceedings of the 6th International Seminar on Speech Production}",
	lockkey = "Y",
	title = "{Inversion experiments based on a descriptive articulatory model}",
	year = 2003
}

@book{Taylor2007,
	author = "Taylor, P.",
	comment = "Speech processing technology has been a mainstream area of research for more than 50 years. The ultimate goal of speech research is to build systems that mimic (or potentially surpass) human capabilities in understanding, generating and coding speech for a range of human-to-human and human-to-machine interactions. Keywords: TTS",
	lockkey = "Y",
	publisher = "University of Cambridge",
	title = "{Text-to-Speech Synthesis}",
	year = 2007
}

@inproceedings{Maeda1978,
	author = "Maeda, S.",
	booktitle = "{???}",
	lockkey = "Y",
	title = "{Une approche statistique d'{\'e}laboration d'un mod{\`e}le articulatoire du conduit vocal}",
	year = 1978
}

@inproceedings{Maeda1979b,
	author = "Maeda, S.",
	booktitle = "{10{\`e}me journ{\'e}e d'{\'e}tude de la parole}",
	lockkey = "Y",
	title = "{An articulatory model of the tongue with linear components}",
	year = 1979
}

@article{Murphy2005,
	abstract = "Cepstral analysis is used to estimate the harmonics-to-noise ratio (HNR) in speech signals. The inverse Fourier transformed liftered cepstrum ap- proximates a noise baseline from which the harmonics-to-noise ratio is esti- mated. The present study highlights the manner in which the cepstrum-based noise baseline estimate is obtained, essentially behaving like a moving average filter applied to the power spectrum for voiced speech. As such, the noise base- line, which is taken to approximate the noise excited vocal tract, is also shown to be influenced by the window length and the shape of the glottal source spec- trum. Two existing estimation techniques are tested systematically for the first time using synthetically generated glottal flow and voiced speech signals, with a priori knowledge of the HNR. The source influence is removed using pre- emphasis to obtain an improved noise baseline fit. The results indicate accurate HNR estimation using the new approach.",
	author = "Murphy, P. J.",
	journal = "???",
	lockkey = "Y",
	title = "{Quantification of glottal and voiced speech harmonics-to-noise ratios using cepstral-based estimation}",
	year = 2005
}

@article{Potard2007,
	abstract = "Le but de l'inversion acoustique articulatoire est d'obtenir la position des articulateurs {\`a} partir du signal de parole. L'une des difficult{\'e}s majeures de l'inversion est qu'une infinit{\'e} de formes de conduits peut donner un m{\{\{\{\{\^e}}}}}me spectre de parole. Une fa\c{c}on de r{\'e}duire cette difficult{\'e} est de contraindre davantage le probl{\`e}me, en utilisant par exemple des contraintes d'ordre visuel (on suppose conna{\{\{\{\{\^i}}}}}tre en plus du signal de parole, la position des articulateurs visibles ; ce qui peut se faire en utilisant une ou plusieurs cam{\'e}ras), ou d'ordre phon{\'e}tique (les caract{\'e}ristiques phon{\'e}tiques des voyelles du Fran\c{c}ais sont connues, par exemple). Mais cette difficult{\'e} peut aussi se transformer en avantage : en permettant d'obtenir toutes les configurations du conduit vocal correspondant {\`a} un son donn{\'e}, l'inversion fournit potentiellement un moyen d'{\'e}tudier des strat{\'e}gies compensatoires pr{\'e}servant l'
acoustique. Nous montrerons comment l'utilisation de contraintes d'origine phon{\'e}tique permet de r{\'e}duire consid{\'e}rablement l'espace des solutions et d'am{\'e}liorer la pertinence des solutions.",
	author = "Potard, B. and Laprie, Y.",
	journal = "???",
	lockkey = "Y",
	title = "{Inversion acoustique-articulatoire en utilisant des contraintes phon{\'e}tiques}",
	year = 2007
}

@inproceedings{Pleite2002,
	author = "Pleite, J. and Olias, E. and Barrado, A. and Lazaro, A. and Vazquez, J.",
	booktitle = "{Proceedings of the 2002 ACM symposium on Applied computing}",
	lockkey = "Y",
	title = "{A procedure to model the frequency response}",
	year = 2002
}

@inproceedings{Tokuda2002,
	author = "Tokuda, Keiichi and Masuko, Takashi and Miyazaki, Noboru and Kobayashi, Takao",
	booktitle = "{IEICE Trans. on Information and Systems}",
	lockkey = "Y",
	pages = "455--464",
	title = "{Multi-Space Probability Distribution HMM}",
	url = "http://citeseer.ist.psu.edu/tokuda02multispace.html",
	year = 2002
}

@inproceedings{Zhu2004,
	author = "Zhu, Donglai and Paliwal, Kuldip K.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{PRODUCT OF POWER SPECTRUM AND GROUP DELAY FUNCTION FOR SPEECH RECOGNITION}",
	year = 2004
}

@article{Oustaloup2002,
	abstract = "This note proposes a noniterative method to fit a rational transfer function to a specified frequency response. A method using a smoothing of width-modulated pulses of the phase asymptotic-diagram is modified to provide an exact algebraic method. This is then used to synthesize a robust controller and a nonrational transfer function with a fractional differentiation order.",
	author = "Oustaloup, Alain and Lanusse, Patrick and Levron, Fran\c{c}ois",
	journal = "IEEE Trans. ON AUTOMATIC CONTROL",
	keywords = "Approximation; filter synthesis; fractional differentiation; frequency-domain method; model reduction; system identification; Viete root functions",
	lockkey = "Y",
	title = "{Frequency-Domain Synthesis of a Filter Using Viete Root Functions}",
	year = 2002
}

@inproceedings{Takahashi2005,
	abstract = "Reverberation morphing from an impulse response is an inevitable 3D-audio technology as well as reverberation rendering for an immersive communication network. This paper proposes a method for reverberation morphing by relocating the poles and zeros of the transfer function. It assumes that the distance of the pole/zero locations from the unit circle in the z-plane represents the reverberation condition for the transfer function. Exponential time- windowing moves the minimum-phase zeros, while the pole/zero relocation for the all-pass part is possible by the windowing after causal and non-causal cepstrum decom- position. We confirmed that the reverberation effects on the frequency response rendered by the proposing method were similar to those for recorded impulse responses in a variable reverberation room. This morphing is also ap- plied to stable inverse filtering in a reverberant space.",
	author = "Takahashi, Y. and Tohyama, M. and H.Nomura",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{REVERBERATION MORPHING USING CEPSTRUM DECOMPOSITION}",
	year = 2005
}

@techreport{DrugmanT2008b,
	author = "Drugman, T. and Moinet, A. and Dutoit, T.",
	institution = "Faculty Polytechnique de Mons",
	lockkey = "Y",
	title = "{On the use of Machine Learning in Statistical Parametric Speech Synthesis}",
	year = 2008
}

@inproceedings{DrugmanT2009e,
	abstract = "Statistical parametric speech synthesizers have recently shown their ability to produce natural-sounding and Ã¯Â¬Âexible voices. Unfortunately the delivered quality suffers from a typical buzziness due to the fact that speech is vocoded. This paper proposes a new excitation model in order to reduce this undesirable effect. This model is based on the decomposition of pitch-synchronous residual frames on an orthonormal ba- sis obtained by Principal Component Analysis. This basis contains a limited number of eigenresiduals and is computed on a relatively small speech database. A stream of PCA- based coefÃ¯Â¬Âcients is added to our HMM-based synthesizer and allows to generate the voiced excitation during the syn- thesis. An improvement compared to the traditional excita- tion is reported while the synthesis engine footprint remains under about 1Mb.",
	author = "Drugman, T. and Wilfart, G. and Dutoit, T.",
	booktitle = "{EUSIPCO}",
	comment = "il mod{\'e}lise la source par PCA. et injecte les eigenvectors pond{\'e}r{\'e} par des valeures apprises (les eigenvectors sont appris sur un plus petit ensemble de phrases)",
	lockkey = "Y",
	title = "{Eigenresiduals for improved parametric speech synthesis}",
	year = 2009
}

@inproceedings{DrugmanT2009d,
	abstract = "In a previous work, we showed that the glottal source can be estimated from speech signals by computing the Zeros of the Z- Transform (ZZT). Decomposition was achieved by separating the roots inside (causal contribution) and outside (anticausal contribution) the unit circle. In order to guarantee a correct deconvolution, time align- ment on the Glottal Closure Instants (GCIs) was shown to be essential. This paper extends the formalism of ZZT by evaluating the Z-transform on a contour possibly diÃ¯Â¬Âerent from the unit circle. A method is pro- posed for determining automatically this contour by inspecting the root distribution. The derived Zeros of the Chirp Z-Transform (ZCZT)-based technique turns out to be much more robust to GCI location errors.",
	author = "Drugman, T. and Bozkurt, B. and Dutoit, T.",
	booktitle = "{NOLISP}",
	comment = "d{\'e}place l'{\'e}valuation de la ZZT pour {\'e}viter les z{\'e}ros sur le cercle unit{\'e}. am{\'e}liore bcp les r{\'e}sultats par rapport {\`a} la position initiale de la fen{\{\{\{\{\^e}}}}}tre.",
	lockkey = "Y",
	title = "{Chirp Decomposition of Speech Signals for Glottal Source Estimation}",
	year = 2009
}

@inproceedings{Beller2005a,
	author = "Beller, G. and Schwarz, D. and Hueber, T. and Rodet, X.",
	booktitle = "{JIM}",
	journal = "JIM",
	lockkey = "Y",
	title = "{A HYBRID CONCATENATIVE SYNTHESIS SYSTEM ON THE INTERSECTION OF MUSIC AND SPEECH}",
	year = 2005
}

@article{Childers1994,
	abstract = "The quality of synthetic speech is affected by two factors: intelligibility and naturalness. At present, synthesized speech may be highly intelligible, but often sounds unnatural. Speech intelligibility depends on the synthesizer's ability to reproduce the formants, the formant bandwidths, and formant transitions, whereas speech naturalness is thought to depend on the excitation waveform characteristics for voiced and unvoiced sounds. Voiced sounds may be generated by a quasiperiodic train of glottal pulses of specified shape exciting the vocal tract filter. It is generally assumed that the glottal source and the vocal tract filter are linearly separable and do not interact. However, this assumption is often not valid, since it has been observed that appreciable source-tract interaction can occur in natural speech. Previous experiments in speech synthesis have demonstrated that the naturalness of synthetic speech does improve when source-tract interaction is simulated in the synthesis process. 
The purpose of this paper is two-fold: (1) to present an algorithm for automatically measuring source-tract interaction for voiced speech, and (2) to present a simple speech production model that incorporates source-tract interaction into the glottal source model, This glottal source model controls: (1) the skewness of the glottal pulse, and (2) the amount of the first formant ripple superimposed on the glottal pulse. A major application of the results of this paper is the modeling of vocal disorders.",
	author = "Childers, D.G. and Wong, Chun-Fan",
	journal = "IEEE Trans. on Biomedical Engineering",
	lockkey = "Y",
	number = "7",
	pages = "663--671",
	title = "{Measuring and modeling vocal source-tract interaction}",
	volume = "41",
	year = 1994
}

@article{Coleman1993,
	author = "Coleman, T. F. and Li, Yuying",
	journal = "SIAM Journal on Optimization",
	lockkey = "Y",
	title = "{An Interior Trust Region Approach for Nonlinear Minimization Subject to Bounds}",
	year = 1996
}

@article{Forney1973,
	abstract = "The Viterbi algorithm (VA) is a recursive optimal solution to the problem of estimating the state sequence of a discrete-time finite-state Markov process observed in memoryless noise. Many problems in areas such as digital communications can be cast in this form. This paper gives a tutorial exposition of the algorithm and of how it is implemented and analyzed. Applications to date are reviewed. Increasing use of the algorithm in a widening variety of areas is foreseen.",
	author = "Forney, G. D.",
	journal = "Proceedings of the IEEE",
	lockkey = "Y",
	title = "{The Viterbi Algorithm}",
	year = 1973
}

@inproceedings{Schnell2008,
	abstract = "In this contribution, a time-varying linear prediction is proposed for speech analysis and synthesis. In comparison to the time-invariant prediction, the predictor coefficients are time-varying within the frames. For that purpose, the coefficient trajectories can be described by basis functions. This approach leads to discontinuities between the frames if the frames are analyzed independently. Therefore, continuous conditions are defined which force continuous trajectories also between the frames. The estimation of the optimum coefficients of the basis functions is solved analytically by a least mean square approach. The analysis results show that the estimation algorithm achieves smooth trajectories of the vocal-tract resonances together with a high time resolution, which is interesting for a variety of application.",
	author = "Schnell, K. and Lacroix, A.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2008.4518516",
	issn = "1520-6149",
	keywords = "least mean square approach; speech analysis; speech synthesis; time-invariant prediction; time-varying linear prediction; vocal-tract resonance; least mean squares methods; prediction theory; speech synthesis; time-varying filters",
	lockkey = "Y",
	pages = "3941--3944",
	title = "{Time-varying linear prediction for speech analysis and synthesis}",
	year = "2008"
}

@inproceedings{Kalgaonkar2007,
	abstract = "Traditional algorithms simplify the lattice recursion for evaluation of the PARCOR's by localizing the loss in vocal tract at one of its ends, the lips or the glottis. In this paper we present a framework for mapping to pseudo areas the VT transfer function with no rigid constraints on the losses in system, thereby allowing losses to be present at both the lips and glottis. This method allows us to calculate the reflection coefficients at both the glottis (r\_G) and the lips (r\_{Lip}). The area functions obtained from these new PARCOR's, have better temporal (inter-frame) and spatial (intra-frame) predictability.",
	author = "Kalgaonkar, K. and Clements, M.",
	booktitle = "{Proc. Interspeech}",
	keywords = "Vocal tract area function; PARCOR; glottal reÃ¯Â¬Âection coeÃ¯Â¬Âcient",
	lockkey = "Y",
	pages = "550--553",
	title = "{Vocal Tract and Area Function Estimation with both Lip and Glottal Losses}",
	year = 2007
}

@inproceedings{Lu2001,
	abstract = "For the synthesized singing voice to sound breathy, aspiration noise is perceptually most important (see Klatt, D.H. and Klatt, L.C., 1990). We have recently proposed to use pitch-synchronous, amplitude-modulated Gaussian noise to model the aspiration component of the glottal excitation (see Lu, Hui-Ling and Smith, J.O., Proc. Int. Computer Music Conf., p.90-7, 2000). For proper parameterization of the noise residual model, we need to analyze the signal properties of the glottal aspiration noise estimated from real breathy singing recordings. Several wavelet thresholding and best-basis thresholding methods are studied and compared in order to obtain reliable estimates of the glottal aspiration noise. We conclude that the best-basis soft-thresholding method is the most effective way to extract the glottal aspiration noise",
	author = "Lu, Hui-Ling and III, J. O. Smith",
	booktitle = "{2001 IEEE Workshop on the Applications of Signal Processing to Audio and Acoustics}",
	lockkey = "Y",
	title = "{Estimating glottal aspiration noise via wavelet thresholding andbest-basis thresholding}",
	year = 2001
}

@article{Skinner1976,
	author = "SKINNER, D. P. and CHILDERS, D. G.",
	comment = "tr{\`e}s technique, comptes les instructions n{\'e}cessaires, etc.",
	journal = "IEEE Trans. on Acoustics, Speech, and Signal Processing",
	lockkey = "Y",
	pages = "267--270",
	title = "{Real-Time Composite Signal Decomposition}",
	year = 1976
}

@article{Stevens2005,
	author = "Stevens, Kenneth N.",
	comment = "explication g{\'e}n{\'e}rale de la voix",
	journal = "Acoustical science and technology",
	lockkey = "Y",
	title = "{The acoustic/articulatory interface}",
	year = 2005
}

@article{Strube2000,
	abstract = "The scattering equations of the Kelly--Lochbaum segmented tube, including the time-varying extension by Strube, are originally based on the assumption of uniform spatial segments and stepwise time update of the acoustic impedances. Here, it is shown that the same equations can be derived without these assumptions for a nonuniform time-varying tube from the discretization of space and time derivatives by the bilinear z transform or by centered differences along the rotated coordinates ct x. Moreover, the same equations also hold for a chain of lattice circuits or equivalents with appropriate parameters, if time derivatives are discretized by the bilinear z transform. These circuits can also be extended to simulate uniform segments of varying length.",
	author = "Strube, Hans Werner",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	pages = "1850--1855",
	title = "{The meaning of the Kelly--Lochbaum acoustic-tube model}",
	year = 2000
}

@inproceedings{Sturmel2009,
	abstract = "The Lines Of Maximum Amplitude (LOMA) of the wavelet transform are used for glottal closure instant detection. Following Kadambe \& al. (1992), the wavelet transform modulus maxima can be used for singularity detection. The LOMA method extends this idea. All the lines chaining maxima of a wavelet transform across scales are built. Then a back-tracking procedure allows for selection of the optimal line for each pitch period, the top of which indicates the GCI. The LOMA method is then evaluated by comparing its results to the DYPSA (Naylor \& al.) algorithm, with the option of using inverse filtering as preprocessing. The LOMA method compares favorably to DYPSA, particularly on accuracy. One of the advantage of the LOMA method is its ability to deal with variations in the glottal source parameters.",
	author = "Sturmel, N. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Rigaud, F.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	pages = "4517--4520",
	title = "{Glottal closure instant detection using Lines of Maximum Amplitudes (LOMA) of thewavelet transform}",
	year = 2009
}

@book{Vetterli1995a,
	author = "Vetterli, Martin and Kovacevic, Jelena",
	lockkey = "Y",
	publisher = "Prentice Hall",
	title = "{Wavelets and Subband Coding}",
	year = 2007
}

@book{Vetterli1995b,
	author = "Vetterli, Martin and Kovacevic, Jelena",
	lockkey = "Y",
	publisher = "Prentice Hall",
	title = "{Wavelets Subband Coding (Solutions manual)}",
	year = 2007
}

@inproceedings{Wang2008,
	abstract = "Speaker normalization typically focuses on variabilities of the supra-glottal (vocal tract) resonances, which constitute a major cause of spectral mismatch. Recent studies show that the subglottal air- ways also affect spectral properties of speech sounds. This paper presents a speaker normalization method based on estimating the second and third subglottal resonances. Since the subglottal airways do not change for a speciÃ¯Â¬Âc speaker, the subglottal resonances are in- dependent of the sound type (i.e., vowel, consonant, etc.) and remain constant for a given speaker. This context-free property makes the proposed method suitable for limited data speaker adaptation. This method is computationally more efÃ¯Â¬Âcient than maximum-likelihood based VTLN, with performance better than VTLN especially for limited adaptation data. Experimental results conÃ¯Â¬Ârm that this method performs well in a variety of testing conditions and tasks.",
	author = "Wang, Shizhen and Alwan, Abeer and Lulich, Steven M.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{Speaker Normalization Based on Subglottal Resonances}",
	year = 2008
}

@article{Schafer1970,
	abstract = "A system for automatically estimating the lowest three formants and the pitch period of voiced speech is presented. The system is based on a digital computation of the cepstrum (defined as the inverse transform of the log magnitude of the z-transform). The pitch period estimate and smoothed log magnitude are obtained from the cepstrum. Formants are estimated from the smoothed spectral envelope using constraints on formant frequency ranges and relative levels of spectral peaks at the formant frequencies. These constraints allow the detection of cases where two formants are too close together in frequency to be resolved in the initial spectral envelope. In these cases, a new spectral analysis algorithm (the chirp z-transform algorithm) allows the efficient computation of a narrow-band spectrum in which the formant resolution is enhanced. Formant and pitch period data obtained by the analysis system are used to control a digital formant synthesizer. Results, in the form of spectrograms, are 
presented to illustrate the performance of the system.",
	author = "SCHAFER, RONALD W. and RABINER, LAWRENCE R.",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	title = "{System for Automatic Formant Analysis of Voiced Speech}",
	year = 1969
}

@inproceedings{Kaburagi2007,
	abstract = "A model of Ã¯Â¬Âow passing through the glottis is presented by employing the boundary-layer assumption. A thin bound- ary layer near the glottal wall inÃ¯Â¬Âuences the Ã¯Â¬Âow behavior in terms of the Ã¯Â¬Âow separation, jet formation, and pressure distri- bution along the channel. The integral momentum relation has been developed to analyze the boundary layer accurately, and it can be solved numerically for the given core Ã¯Â¬Âow velocity on the basis of the similarity of velocity proÃ¯Â¬Âles. On the other hand, boundary layer reduces the effective size of the channel and increases the Ã¯Â¬Âow velocity. Therefore, the boundary-layer problem entails viscous-inviscid interaction inherently. To in- vestigate the process of voice production, this paper presents a method to solve the boundary-layer problem including such in- teraction. Experiments show that the method is useful for pre- dicting the Ã¯Â¬Âow rate, pressure distribution, and other properties when the glottal conÃ¯Â¬Âguration 
and subglottal pressure are spec- iÃ¯Â¬Âed as the phonation condition.",
	author = "Kaburagi, Tokihiko and Tanabe, Yosuke",
	booktitle = "{Proc. Interspeech}",
	keywords = "voice production; glottal Ã¯Â¬Âow; boundary layer; viscous-inviscid interaction",
	lockkey = "Y",
	pages = "1378--1381",
	title = "{A model of glottal Ã¯Â¬Âow incorporating viscous-inviscid interaction}",
	year = 2007
}

@inproceedings{Ito2007,
	abstract = "In speech production, vowel articulation is mainly characterized by two factors, height and place. These features are known to be correlated with the first and second formant frequencies in acoustical domain. However, there are some difficulties in extracting formant frequencies from natural utterances especially for nonstationary parts such as vowel-to-vowel transition. To overcome this problem, a new method was examined for estimating articulatory feature from a whole spectral shape of the vowels. 360 utterances of two male and two female speakers were analyzed, which consisted of separately uttered vowels and continuously uttered vowel sequences. Utilizing a local vector coding, spectral envelope could be estimated with high accuracy not only for steady-state parts but also for transient parts of the utterances. Based on acoustical variance of the estimated spectral envelopes, articulatory feature vectors were determined for individual speaker. Each spectral envelope was then mapped into a 
point in articulatory feature space by simple inner products with the articulatory feature vectors. In this space, the first and second axes roughly represented articulatory height and place, respectively. The results supported that articulatory feature might be simply estimated from whole spectral shape without extracting formant frequencies.",
	author = "Ito, Masashi and Yano, Masafumi",
	booktitle = "{ICA}",
	keywords = "ARTICULATORY FEATURE ESTIMATION",
	lockkey = "Y",
	title = "{ARTICULATORY FEATURE ESTIMATION FOR NONSTATIONARY VOWELS BASED ON A LOCAL VECTOR CODING}",
	year = 2007
}

@inproceedings{Sciamarella2005,
	abstract = "A method is proposed to extract glottal-Ã¯Â¬Âow spectra from nume- rical simulations of vocal-fold behavior with a two-mass model including dynamic Ã¯Â¬Âow separation. The numerical spectrum, whose general form complies with that of signal glottal-Ã¯Â¬Âow models, allows stylization with three linear segments. The slope of the Ã¯Â¬Ârst segment remains relatively constant when source control parameters are varied, whereas the slope of the last seg- ment (i.e. the spectral tilt) is highly sensitive to the vibrating vocal-fold mass, tension and stiffness. The phase of mobility of the Ã¯Â¬Âow separation position within the glottal cycle may intro- duce, if long enough, a dip in the glottal-Ã¯Â¬Âow spectrum.",
	author = "Sciamarella, Denisse and D{\rq}Alessandro, Christophe",
	booktitle = "{Interspeech}",
	lockkey = "Y",
	title = "{Stylization of glottal-flow spectra produced by a mechanical vocal-fold model}",
	year = 2005
}

@article{Zivanovic2007,
	abstract = "A new approach to adaptive threshold selection for classification of peaks of audio spectra is presented. We here extend the previous work on classification of sinusoidal and noise peaks based on a set of spectral peak descriptors in a twofold way: on one hand we propose a compact sinusoidal model where all the modulation parameters are defined with respect to the analysis window. This fact is of great importance as we recall that the STFT spectra are closely related to the analysis window properties. On the other hand, we design a threshold selection algorithm that allows us to control the decision thresholds in an intuitive manner. The decision thresholds calculated from the relationships established between the noise power in the signal and the distributions of sinusoidal peaks assures that all peaks described as sinusoidal will be correctly classified. We also show that the threshold selection algorithm can be used for different types of analysis windows with only a slight parameter 
readjustment.",
	author = "Zivanovic, M. and Roebel, A. and Rodet, X.",
	journal = "Computer Music Journal",
	lockkey = "Y",
	number = "2",
	pages = "57--67",
	title = "{Adaptive Threshold Determination for Spectral Peak Classification}",
	volume = "32",
	year = 2008
}

@phdthesis{Yeh2008,
	address = "France",
	author = "Yeh, Chunghsin",
	lockkey = "Y",
	school = "UPMC-Ircam",
	title = "{Multiple fundamental frequency estimation of polyphonic recordings}",
	year = "2008"
}

@inproceedings{DrugmanT2009c,
	author = "Drugman, T. and Moinet, A. and Dutoit, T. and Wilfart, G.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{USING A PITCH-SYNCHRONOUS RESIDUAL CODEBOOK FOR HYBRID HMM/FRAME SELECTION SPEECH SYNTHESIS}",
	year = 2009
}

@article{Gonzalvo2007,
	abstract = "Hidden Markov Models based text-to-speech (HMM-TTS) syn- thesis is one of the techniques for generating speech from trained statistical models where spectrum and prosody of ba- sic speech units are modelled altogether. This paper presents the advances in our Spanish HMM-TTS and a perceptual test is conducted to compare it with an extended PSOLA-based con- catenative (E-PSOLA) system. The improvements have been performed on phonetic information and contextual factors ac- cording to the Castilian Spanish language and speech genera- tion using a mixed excitation (ME) technique. The results show the preference of the new HMM-TTS system in front of the previous system and a better MOS in comparison with a real E-PSOLA in terms of acceptability, intelligibility and stability.",
	author = "Gonzalvo, X. and Socoro, J. and Iriondo, I. and Monzo, C. and Martinez, E.",
	journal = "ISCA SSW6",
	lockkey = "Y",
	title = "{Linguistic and Mixed Excitation Improvements on a HMM-based speech synthesis for Castillan Spanish}",
	year = 2007
}

@phdthesis{Yoshimura2002,
	abstract = "A text-to-speech(TTS) system is one of the human-machine interfaces using speech. In recent years, TTS system is developed as an output device of human-machine interfaces, and it is used in many application such as a car navigation system, in- formation retrieval over the telephone, voice mail, a speech-to-speech translation system and so on. However, although most text-to-speech systems still cannot syn- thesize speech with various voice characteristics such as speaker individualities and emotions. To obtain various voice characteristics in text-to-speech systems based on the selection and concatenation of acoustical units, a large amount of speech data is necessary. However, it is diÃ¯Â¬Âcult to collect, segment, and store it. From these points of view, in order to construct a speech synthesis system which can generate various voice characteristics, an HMM-based text-to-speech system has been proposed. This dissertation presents the construction of the HMM-based text-to-speech system, in 
which spectrum, fundamental frequency and duration are modeled simultaneously in a uniÃ¯Â¬Âed framework of HMM. In the system, mainly three techniques are used; (1) a mel-cepstral analysis/synthesis technique, (2) speech parameter modeling using HMM and (3) a speech parameter generation algorithm from HMM. Since the system uses above three techniques, the system has several capabilities. First, since the TTS system uses the speech parameter generation algorithm, the generated spectral and pitch paramters from the trained HMMs can be similar to those of real speech. Second, by transforming HMM parameters appropriately, voice characteristics of synthetic speech can be changed since the system generates speech from the HMMs. Third, this system is trainable. In this thesis, Ã¯Â¬Ârst, the above three techniques are presented, and simultaneous modeling of phonetic and prosodic parameters in a framework of HMM is proposed. Next, to improve of the quality of synthesized speech, the mixed excitation model of the 
speech coder MELP and postÃ¯Â¬Âlter are incorporated into the system. Experimen- tal results show that the mixed excitation model and postÃ¯Â¬Âlter signiÃ¯Â¬Âcantly improve the quality of synthesized speech. Finally, for the purpose of synthesizing speech with various voice characteristics such as speaker individualities and emotions, the TTS system based on speaker interpolation is presented.",
	address = "Japan",
	author = "Yoshimura, Takayoshi",
	comment = "A text-to-speech(TTS) system is one of the human-machine interfaces using speech. In recent years, TTS system is developed as an output device of human-machine interfaces, and it is used in many application such as a car navigation system, in- formation retrieval over the telephone, voice mail, a speech-to-speech translation system and so on. However, although most text-to-speech systems still cannot syn- thesize speech with various voice characteristics such as speaker individualities and emotions. To obtain various voice characteristics in text-to-speech systems based on the selection and concatenation of acoustical units, a large amount of speech data is necessary. However, it is diÃ¯Â¬Âcult to collect, segment, and store it. From these points of view, in order to construct a speech synthesis system which can generate various voice characteristics, an HMM-based text-to-speech system has been proposed. This dissertation presents the construction of the HMM-based text-to-speech system, in which 
spectrum, fundamental frequency and duration are modeled simultaneously in a uniÃ¯Â¬Âed framework of HMM. In the system, mainly three techniques are used; (1) a mel-cepstral analysis/synthesis technique, (2) speech parameter modeling using HMM and (3) a speech parameter generation algorithm from HMM. Since the system uses above three techniques, the system has several capabilities. First, since the TTS system uses the speech parameter generation algorithm, the generated spectral and pitch paramters from the trained HMMs can be similar to those of real speech. Second, by transforming HMM parameters appropriately, voice characteristics of synthetic speech can be changed since the system generates speech from the HMMs. Third, this system is trainable. In this thesis, Ã¯Â¬Ârst, the above three techniques are presented, and simultaneous modeling of phonetic and prosodic parameters in a framework of HMM is proposed. Next, to improve of the quality of synthesized speech, the mixed excitation model of the speech 
coder MELP and postÃ¯Â¬Âlter are incorporated into the system. Experimen- tal results show that the mixed excitation model and postÃ¯Â¬Âlter signiÃ¯Â¬Âcantly improve the quality of synthesized speech. Finally, for the purpose of synthesizing speech with various voice characteristics such as speaker individualities and emotions, the TTS system based on speaker interpolation is presented.",
	lockkey = "Y",
	school = "Nagoya Institute of Technology",
	title = "{Simultaneous modeling of phonetic and prosodic parameters, and characteristic conversion for hmm-based text-to-speech systems}",
	year = 2002
}

@techreport{Maia2007b,
	abstract = "One of the drawbacks to the speech synthesis technique wherein speech parameters are directly generated from hidden Markov models (HMM-based speech synthesis) is the unnat- uralness of the synthesized speech. This problem occurs owing to the rough excitation model employed during the waveform generation stage. This report introduces a new excitation ap- proach that attempt to solve this problem. The proposed scheme consists in feeding the mel log spectrum approximation (MLSA) Ã¯Â¬Âlter with mixed excitation, obtained through a set of state-dependent Ã¯Â¬Âlters. The Ã¯Â¬Âlters are derived from the speech database through a closed-loop procedure where the likelihood of the residual is maximized.",
	author = "Maia, R.",
	institution = "???",
	lockkey = "Y",
	month = "May",
	title = "{A Novel Excitation Approach for HMM-Based Speech Synthesis}",
	year = 2007
}

@article{Cabral2007,
	abstract = "This paper proposes the use of the Liljencrants-Fant model (LF- model) to represent the glottal source signal in HMM-based speech synthesis systems. These systems generally use a pulse train to model the periodicity of the excitation signal of voiced speech. However, this model produces a strong and uniform harmonic structure throughout the spectrum of the excitation which makes the synthetic speech sound buzzy. The use of a mixed band excitation and phase manipulation reduces this ef- fect but it can result in degradation of the speech quality if the noise component is not weighted carefully. In turn, the LF- waveform has a decaying spectrum at higher frequencies, which is more similar to the real glottal source excitation signal. We conducted a perceptual experiment to test the hypoth- esis that the LF-model can perform as well as or better than the pulse train in a HMM-based speech synthesizer. In the syn- thesis, we used the mean values of the LF-parameters, calcu- lated by measurements of 
the recorded speech. The result of this study is important not only regarding the improvement in speech quality of these type of systems, but also because the LF-model can be used to model many characteristics of the glot- tal source, such as voice quality, which are important for voice transformation and generation of expressive speech.",
	author = "Cabral, J. P. and Renals, S. and Richmond, K. and Yamagishi, J.",
	journal = "CSTR",
	keywords = "LF-model; Statistical parametric speech synthesis; HMM-based speech synthesis",
	lockkey = "Y",
	title = "{Towards an Improved Modeling of the Glottal Source in Statistical Parametric Speech Synthesis}",
	year = 2007
}

@inproceedings{Raitio2008,
	abstract = "This paper describes an HMM-based speech synthesis sys- tem that utilizes glottal inverse Ã¯Â¬Âltering for generating natural sounding synthetic speech. In the proposed system, speech is Ã¯Â¬Ârst parametrized into spectral and excitation features using a glottal inverse Ã¯Â¬Âltering based method. The parameters are fed into an HMM system for training and then generated from the trained HMM according to text input. Glottal Ã¯Â¬Âow pulses ex- tracted from real speech are used as a voice source, and the voice source is further modiÃ¯Â¬Âed according to the all-pole model parameters generated by the HMM. Preliminary experiments show that the proposed system is capable of generating natural sounding speech, and the quality is clearly better compared to a system utilizing a conventional impulse train excitation model.",
	author = "Raitio, T. and Suni, A. and Pulakka, H. and Vainio, M. and Alku, P.",
	booktitle = "{Proc. Interspeech}",
	keywords = "speech synthesis; glottal inverse Ã¯Â¬Âltering; HMM",
	lockkey = "Y",
	pages = "1881--1884",
	title = "{{HMM}-based Finnish Text-to-Speech System Utilizing Glottal Inverse Filtering}",
	year = 2008
}

@inproceedings{Pozo2008,
	author = "{del Pozo}, A. and Young, S.",
	booktitle = "{Proc. Interspeech}",
	lockkey = "Y",
	pages = "1457--1460",
	title = "{The Linear Transformation of LF Glottal Waveforms for Voice Conversion}",
	year = 2008
}

@article{KawaharaH1999,
	author = "Kawahara, H. and Masuda-Katsuse, I and {de Cheveigne}, A.",
	journal = "Speech Communication",
	lockkey = "Y",
	number = "3-4",
	page = "187-207",
	pages = "187--207",
	title = "{Restructuring speech representations using a pitch-adaptative time-frequency smoothing and an instantaneous-frequency-based f0 extraction: {P}ossible role of a repetitive structure in sounds}",
	volume = "27",
	year = 1999
}

@inproceedings{CabralJP2008gss,
	abstract = "This paper presents a method to control the characteristics of synthetic speech flexibly by integrating articulatory features into a Hidden Markov Model (HMM)-based parametric speech synthesis system. In contrast to model adaptation and interpolation approaches for speaking style control, this method is driven by phonetic knowledge, and target speech samples are not required. The joint distribution of parallel acoustic and articulatory features considering cross-stream feature dependency is estimated. At synthesis time, acoustic and articulatory features are generated simultaneously based on the maximum-likelihood criterion. The synthetic speech can be controlled flexibly by modifying the generated articulatory features according to arbitrary phonetic rules in the parameter generation process. Our experiments show that the proposed method is effective in both changing the overall character of synthesized speech and in controlling the quality of a specific vowel.",
	address = "Brisbane, Australia",
	author = "Cabral, J. and Renals, S. and Richmond, K. and Yamagishi, J.",
	booktitle = "{Proc. Interspeech}",
	categories = "HMM speech synthesis, Glottal Spectral Separation, LF-model",
	key = "cabral:renals:richmond:yamagishi:2008a",
	lockkey = "Y",
	month = sep,
	pages = "1829--1832",
	pdf = "http://www.cstr.inf.ed.ac.uk/downloads/publications/2008/IS081086.PDF",
	title = "{Glottal Spectral Separation for Parametric Speech Synthesis}",
	year = 2008
}

@inproceedings{Maia2007a,
	author = "Maia, R.",
	booktitle = "{SSW6}",
	lockkey = "Y",
	title = "{An Excitation Model for HMM-Based Speech Synthesis Based on Residual Modeling}",
	year = "2007"
}

@inproceedings{DrugmanT2008a,
	abstract = "This paper addresses the problem of estimating the voice source directly from speech waveforms. A novel principle based on Anticausality Dominated Regions (ACDR) is used to estimate the glottal open phase. This technique is compared to two other state-of-the-art well-known methods, namely the Zeros of the Z-Transform (ZZT) and the Iterative Adaptive Inverse Filtering (IAIF) algorithms. Decomposition quality is assessed on synthetic signals through two objective measures: the spectral distortion and a glottal formant determination rate. Technique robustness is tested by analyzing the inÃ¯Â¬Âuence of noise and Glottal Closure Instant (GCI) location errors. Besides impacts of the fundamental frequency and the Ã¯Â¬Ârst formant on the performance are evaluated. Our proposed approach shows signiÃ¯Â¬Âcant improvement in robustness, which could be of a great interest when decomposing real speech.",
	author = "Drugman, T. and Dubuisson, T. and Moinet, A. and d'Alessandro, N. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Dutoit, T.",
	booktitle = "{Proc. International Conference on Signal Processing and Multimedia Applications (SIGMAP)}",
	keywords = "Glottal Formant; Speech Analysis; Speech Processing; Voice Source",
	lockkey = "Y",
	title = "{Glottal source estimation robustness}",
	year = 2008
}

@article{AlkuP1999,
	author = "Alku, P. and Tiitinen, H. and Naatanen, R.",
	doi = "10.1016/S1388-2457(99)00088-7",
	issn = "1388-2457",
	journal = "Clinical Neurophysiology",
	keywords = "Mismatch negativity",
	lockkey = "Y",
	number = "8",
	pages = "1329--1333",
	title = "{A method for generating natural-sounding speech stimuli for cognitive brain research}",
	url = "http://www.sciencedirect.com/science/article/B6VNP-3WWVBN3-2/2/ae6126bea7cdd91536fb8f96faa53d39",
	volume = "110",
	year = "1999"
}

@inproceedings{AirasM2005,
	abstract = "Voice inverse filtering is a process in which the effects of the vocal tract are cancelled from the speech signal to estimate the airflow through the glottis. Although inverse filtering has many applications in both research and clinical examination of voice production, few voice inverse filtering software packages exist. In the present paper, we propose a flexible software package, HUT Voice Source Analysis and Parametrisation Toolkit (Aparat) for use in the MATLAB environment. It implements glottal inverse filtering and several time-based parameters of the voice source in a graphical user interface. The software package is available under an open source licence at http://www.acoustics.hut.fi/software/aparat/.",
	author = "Airas, M. and Pulakka, H. and Backstrom, T. and Alku, P.",
	booktitle = "{Proc. Interspeech}",
	lockkey = "Y",
	pages = "2145--2148",
	title = "{Toolkit for voice inverse filtering and parametrisation}",
	year = "2005"
}

@inproceedings{Laroche2003,
	abstract = "This paper presents new frequency-domain voice modiÃ¯Â¬Âcation tech- niques that combine the high-quality usually obtained by time- domain techniques such as TD-PSOLA with the Ã¯Â¬Âexibility pro- vided by the frequency-domain representation. The technique only works for monophonic sources (single-speaker), and relies on a (possibly online) pitch detection. Based on the pitch, and ac- cording to the desired pitch and formant modiÃ¯Â¬Âcations, individ- ual harmonics are selected and shifted to new locations in the spectrum. The harmonic phases are updated according to a pitch- based method that aims to achieve time-domain shape-invariance, thereby reducing or eliminating the usual artifacts associated with frequency-domain and sinusoidal-based voice modiÃ¯Â¬Âcation tech- niques. The result is a fairly inexpensive, Ã¯Â¬Âexible algorithm which is able to match the quality of time-domain techniques, but pro- vides vastly improved Ã¯Â¬Âexibility in the array of available modiÃ¯Â¬Â- cations.",
	author = "Laroche, Jean",
	booktitle = "{DAFx}",
	lockkey = "Y",
	title = "{FREQUENCY-DOMAIN TECHNIQUES FOR HIGH-QUALITY VOICE MODIFICATION}",
	year = 2003
}

@inproceedings{Zhu2002,
	abstract = "Relative to the speech production and perception models, spectral envelopes play an important role in speech analysis, synthesis, and coding. Recently, spectral envelope estimation technique has made a rapid progress. There are several ways to obtain spectral envelope. These ways include SEEVOC technique, discrete cepstrum method, regularized discrete cepstum estimation, DAP, MVDR, etc. In this paper, we compared the different spectral estimation techniques by using the different spectral-distortion measures. It aims to compare the different envelope estimation techniques from some different perspective. The work is implemented in a low bit-rate coder based on the sinusoidal model by using the different techniques to captures the spectral amplitudes.",
	author = "{Shaohui Zhu}, Wenju Liu Bo Xu",
	booktitle = "{ISCSLP}",
	journal = "ISCSLP 2002",
	lockkey = "Y",
	title = "{International Symposium on Chinese Spoken Language Processing}",
	year = 2002
}

@inproceedings{Zhang1998,
	abstract = "In most low bit rate coders, the quality of the synthetic speech depends greatly on the performance of the spectral coding stage, in which the spectral envelope is estimated and encoded. The Spectral Envelope Estimation Vocoder (SEEVOC) is a successful spectral envelope estimation method that plays an important role in low bit rate speech coding based on the sinusoidal model. This paper investigates the properties and limitations of the SEEVOC algorithm, and shows that it can be generalized and optimized by changing the search range parameters ÃÂ± and ÃÂ². Rules for the optimum choice of ÃÂ± and ÃÂ² are derived, based on both analysis and experimental results. The effects of noise on the SEEVOC algorithm are also investigated. Experimental results show that the SEEVOC algorithm performs better for voiced speech in the presence of noise than linear prediction (LP) analysis.",
	author = "Zhang, Weihua and Holmes, W. Harvey",
	booktitle = "{ICSLP}",
	keywords = "envelope; SEEVOC",
	lockkey = "Y",
	title = "{PERFORMANCE AND OPTIMIZATION OF THE SEEVOC ALGORITHM}",
	year = 1998
}

@article{Takemoto2006,
	abstract = "The acoustic effects of the laryngeal cavity on the vocal tract resonance were investigated by using vocal tract area functions for the five Japanese vowels obtained from an adult male speaker. Transfer functions were examined with the laryngeal cavity eliminated from the whole vocal tract, volume velocity distribution patterns were calculated, and susceptance matching analysis was performed between the laryngeal cavity and the vocal tract excluding the laryngeal cavity (vocal tract proper). It was revealed that the laryngeal cavity generates one of the formants of the vocal tract, which is the fourth in the present study. At this formant, the resonance of the laryngeal cavity (the 1/4 wavelength resonance) induces the open-tube resonance of the vocal tract proper (the 3/2 wavelength resonance). At the other formants, on the other hand, the vocal tract proper acts as a closed tube, because the laryngeal cavity has only a small contribution to generating these formants and the effective closed 
end of the whole vocal tract is the junction between the laryngeal cavity and the vocal tract proper.",
	author = "Takemoto, Hironori and Adachi, Seiji and Kitamura, Tatsuya and Mokhtari, Parham and Honda, Kiyoshi",
	doi = "10.1121/1.2261270",
	journal = "Journal of the Acoustical Society of America",
	keywords = "speech processing; speech; physiological models; transfer functions",
	lockkey = "Y",
	number = "4",
	pages = "2228--2238",
	publisher = "ASA",
	title = "{Acoustic roles of the laryngeal cavity in vocal tract resonance}",
	url = "http://link.aip.org/link/?JAS/120/2228/1",
	volume = "120",
	year = "2006"
}

@inproceedings{Tooher2003,
	abstract = "The following paper presents the results of a study of glot- tal source parameters and their behaviour across vowels, con- texts and fundamental frequency. The utterances collected con- sisted of multiple recordings of three vowels in 4 different con- texts, across seven different pitches from one male speaker. The vowels were extracted and subsequently inverse Ã¯Â¬Âltered using a Kalman Ã¯Â¬Âlter based linear prediction technique, and the Liljencrants-Fant model was Ã¯Â¬Âtted to the resulting glottal Ã¯Â¬Âow derivative yielding the glottal Ã¯Â¬Âow parameters. Variation of these parameters was studied across F0, vowel quality and phonetic context.",
	author = "Tooher, M. and McKenna, J. G.",
	booktitle = "{Proc. ISCA Voice Quality: Functions, Analysis and Synthesis (VOQUAL)}",
	lockkey = "Y",
	pages = "41--46",
	title = "{Variation of the glottal {LF} parameters across F0, vowels, and phonetic environment}",
	year = 2003
}

@article{Vaidyanathan1985,
	abstract = "A/~racr -A general representation of a class of low passband sensitivity digital filter structures is proposed. The proposed representation for a transfer function of order N consists of an (N + l)-pair memoryless system terminated at N-pairs by delays. The (N + l)-pair system contains only adders and multipliers, and is described by an orthogonal transfer matrix. The set of terminating delays can be looked upon as an N-pair system with transfer matrix t- {\lq}1. Certain wave digital filter structures, Gray-Markel lattice structures and the coupled-form biquadratic section belong to the general form advanced here. Several properties satisfied in these special cases are derived in a unified manner using the generalized representation. Also, a quantization scheme that makes the structure free from zero-input limit cycles even under time-varying conditions is advanced, unifying similar such results independently reported for the above well-known structures.",
	author = "VAIDYANATHAN, P. P. and MITRA, SANJIT K.",
	journal = "IEEE Trans. on Circuits and Systems",
	lockkey = "Y",
	title = "{Passivity Properties of Low-Sensitivity Digital Filter Structures}",
	year = 1985
}

@inproceedings{Silen2009,
	abstract = "HMM-based speech synthesis offers a way to generate speech with different voice qualities. However, sometimes databases contain certain inherent voice qualities that need to be parametrized properly. One example of this is vocal fry typi- cally occurring at the end of utterances. A popular mixed exci- tation vocoder for HMM-based speech synthesis is STRAIGHT. The standard STRAIGHT is optimized for modal voices and may not produce high quality with other voice types. Fortu- nately, due to the Ã¯Â¬Âexibility of STRAIGHT, different F0 and aperiodicity measures can be used in the synthesis without any inherent degradations in speech quality. We have replaced the STRAIGHT excitation with a representation based on a robust F0 measure and a carefully determined two-band voicing. Ac- cording to our analysis-synthesis experiments, the new param- eterization can improve the speech quality. In HMM-based speech synthesis, the quality is signiÃ¯Â¬Âcantly improved espe- cially due to the better modeling of 
vocal fry.",
	author = "{Hanna Sil{\'e}n}, Elina Helander Jani Nurminen Moncef Gabbouj",
	booktitle = "{Interspeech}",
	keywords = "speech synthesis; hidden Markov models; vocal fry; mixed excitation; STRAIGHT",
	lockkey = "Y",
	title = "{Parameterization of Vocal Fry in HMM-Based Speech Synthesis}",
	year = 2009
}

@inproceedings{Niu2005,
	abstract = "Accurate estimation of velar movements is useful for automatic speech recognition, speech enhancement, and diagnosis of cer- tain speech disorders. This paper reports on initial results of a project on estimation of velar movements, for two-microphone setups where the microphones are differentially positioned to pick up nasal and oral speech output. Toward this goal, we pro- pose a method that allows detailed estimation of the acoustic properties of the nasal tract in the simpliÃ¯Â¬Âed condition where the two microphone signals exhibit complete source separation. We successfully test the method against synthetic speech, generated by an articulatory synthesizer in which the acoustic properties of the simulated nasal tract are known.",
	author = "Niu, Xiaochuan and Kain, A. and {van Santen}, J. P. H.",
	booktitle = "{Proc. Interspeech}",
	lockkey = "Y",
	pages = "1045--1048",
	title = "{Estimation of the Acoustic Properties of the Nasal Tract during the Production of Nasalized Vowels}",
	year = 2005
}

@misc{Cappe1997,
	author = "{Olivier Capp{\'e}}, Marine Oudot Eric Moulines",
	howpublished = "ASPAA",
	lockkey = "Y",
	title = "{Spectral Envelope Estimation using a Penalized Likelihood Criterion}",
	year = 1997
}

@article{Matsuzaki2007,
	abstract = "MRI data on the vocal tract during the production of Japanese vowels indicate coupling between the oral cavity and the nasal cavity. A large number of studies have been carried out on the nasalized vowels on the basis of a one- dimensional speech production model. Acoustic analysis of the three-dimensional nasal tract has also been performed by the Ã¯Â¬Ânite element method (FEM) [1,2]. Moreover, acoustic coupling between the oral and nasal cavities in the radiation space has been studied using simpliÃ¯Â¬Âed Ã¯Â¬Ânite element models [3]. However, as for the case with three-dimensional radiation from the lips and nostrils, the acoustic characteristics of vocal- tract shape based on MRI data are not clear. Simulations based on a detailed vocal-tract shape with proper boundary conditions are important for studying the acoustic character- istics of speech, especially at high frequencies where individual information possibly exists. In this paper, using vowel MRI data of the vocal tract with the 
nasal cavity during phonation of the Japanese /a/, we examine the eÃ¯Â¬Âects of the nasal cavity on the acoustic characteristics of the speech production system. The acoustic analysis of three-dimensional geometrical vocal-tract models is performed by the FEM. Two types of models are composed on the basis of MRI data. One is a model with a three- dimensional nasal cavity, and the other, for the purpose of comparison, is without a nasal cavity. The nasal cavity is also coupled to the oral cavity through a space between the lips and the nostrils in a three-dimensional volume of radiation. The eÃ¯Â¬Âects of the wall impedance of the vocal tract are also examined.",
	author = "Matsuzaki, Hiroki and Motoki, Kunitoshi",
	journal = "Acoustic sciences \& Technics",
	keywords = "Acoustic analysis; Three-dimensional FEM; Vowel; Nasal cavity; Vocal tract; Wall impedance",
	lockkey = "Y",
	title = "{Study of acoustic characteristics of vocal tract with nasal cavity during phonation of Japanese /a/}",
	year = 2007
}

@article{Lim1993,
	abstract = "Abstract- In this paper we established a theory on lossless pole-zero modeling of speech signals for the description of nasal sounds. The theory is based on a generalized vocal tract tube model which consists of the main vocal tract, the oral tract, and the nasal tract. We first derived a new pole-zero type transfer function, which turned out to be a generalized version of the existing all-pole type transfer function. We then investigated fundamental properties of the generalized vocal tract model employing the concept of discrete-time reactance. Based on those properties, we outlined a procedure to evaluate the reflection coefficients for the model. The assumption of losslessness in the modeling led us to the following two important properties. First, the combination of two lattice structures representing the oral and the nasal tracts form one larger lattice structure when viewed at their joint point called the branch boundary, and secondly, the oral and the nasal tract respectively render 
discrete-time reactances Gc(z ) and GD( z ) , whose convex combination generates the discrete-time reactance G 4 ( z ) at the branch boundary. The first property enabled us to compute G `` ( z ) , and the second property helped us separate G1(z) into G c ( z ) and G D ( z ) .",
	author = "Lim, Il-Taek and Lee, Byeong Gi",
	journal = "IEEE Trans. on Speech and Audio Processing",
	lockkey = "Y",
	number = "3",
	pages = "269--276",
	title = "{Lossless Pole-Zero Modeling of Speech Signals}",
	volume = "1",
	year = 1993
}

@article{Jahanshahi2004,
	abstract = "There are some physical phenomena and engineering problems whose math- ematical models appear as diÃ¯Â¬Âerence equations with variable coeÃ¯Â¬Âcients. In this paper, at Ã¯Â¬Ârst we deÃ¯Â¬Âne the concept of discrete multiplicative derivative and discrete multiplicative integration, then the invariant function with respect to this derivative is introduced. Next diÃ¯Â¬Âerential equations with this type of derivative are considered. In the Ã¯Â¬Ânal section, we consider some initial and boundary value problems which include diÃ¯Â¬Âerence equations with variable coeÃ¯Â¬Âcients. At the end, by making use of linear algebra and numerical diÃ¯Â¬Âerentiation and discrete multiplicative integration, we present an analytic-numerical method for solving these diÃ¯Â¬Âer- ence equations.",
	author = "{M. Jahanshahi}, N. Aliev and Khatami, H. R.",
	journal = "Dynamical Systems and Applications",
	keywords = "DiÃ¯Â¬Âerence equation; Invariant function; Discrete multiplicative diÃ¯Â¬Âerentiation; Discrete multiplicative integration",
	lockkey = "Y",
	title = "{An Analytic-Numerical Method for Solving DiÃ¯Â¬Âerence Equations with Variable CoeÃ¯Â¬Âcients by Discrete Multiplicative Integration}",
	year = 2004
}

@article{Aliev2007,
	abstract = "Linear and Non-linear diÃ¯Â¬Âerence equations are appeared in many Ã¯Â¬Âelds of applied mathematics, engineering and physical problems such as natural phenomena, social and economical systems which have essen- tially discrete elements. In this paper by making use of invariant functions for discrete deriva- tives [6], we present an analytical method to solve the general form of the n-th order non-homogenous linear diÃ¯Â¬Âerence equations and some non-linear diÃ¯Â¬Âerence equations.",
	author = "{N. Aliev}, N. Azizi and Jahanshahi, M.",
	journal = "International Mathematical Forum",
	keywords = "Discrete derivatives; Invariant functions; DiÃ¯Â¬Âerence equations",
	lockkey = "Y",
	title = "{Invariant Functions for Discrete Derivatives and Their Applications to Solve Non-Homogenous Linear and Non-Linear DiÃ¯Â¬Âerence Equations}",
	year = 2007
}

@article{Hillman1983,
	author = "Hilman, R. E. and Oesterie, E. and Feth, L. L.",
	journal = "JASA",
	keywords = "glottal noise",
	lockkey = "Y",
	title = "{Characteristics of the glottal turbulent noise spectrum}",
	year = 1983
}

@article{Benidir1987,
	abstract = "Abstruct-Using the lattice representation of an ARMA filter, it is well known that the necessary and sufficient condition so that the po are inside the unit circle is 1 ki I < 1, 1 \_I i n where the kls,are the reflection coefficients. The filter is said to be wide sense stable if no pole is located outside the unit circie, and it is interesting to charac- terize this stability by an appropriate necessary and sufficient condi- tion. To establish this condition, the concept of canonical reflection coefficient is introduced, which eliminates the problems appearing wh the Levinson recursion is not inversible. Some examples are discussed and a simple and practicaltest for wide sense stability is given.",
	author = "PICINBONO, MESSAOUD BENIDIR AND BERNARD",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	title = "{Extensions of the Stability Criterion for ARMA Filters}",
	year = 1987
}

@inproceedings{DrugmanT2009b,
	abstract = "Speech generated by parametric synthesizers generally suffers from a typical buzziness, similar to what was encountered in old LPC-like vocoders. In order to alleviate this problem, a more suited modeling of the excitation should be adopted. For this, we hereby propose an adaptation of the Deterministic plus Stochastic Model (DSM) for the residual. In this model, the excitation is divided into two distinct spectral bands delimited by the maximum voiced frequency. The deterministic part con- cerns the low-frequency contents and consists of a decompo- sition of pitch-synchronous residual frames on an orthonormal basis obtained by Principal Component Analysis. The stochas- tic component is a high-pass Ã¯Â¬Âltered noise whose time struc- ture is modulated by an energy-envelope, similarly to what is done in the Harmonic plus Noise Model (HNM). The proposed residual model is integrated within a HMM-based speech syn- thesizer and is compared to the traditional excitation through a subjective test. 
Results show a signiÃ¯Â¬Âcative improvement for both male and female voices. In addition the proposed model requires few computational load and memory, which is essential for its integration in commercial applications.",
	author = "Drugman, Thomas and Wilfart, Geoffrey and Dutoit, Thierry",
	booktitle = "{Interspeech}",
	journal = "Interspeech",
	keywords = "HMM-based speech synthesis; residual modeling; Deterministic plus Stochastic model",
	lockkey = "Y",
	title = "{A Deterministic plus Stochastic Model of the Residual Signal for Improved Parametric Speech Synthesis}",
	year = 2009
}

@inproceedings{DrugmanT2009a,
	abstract = "Homomorphic analysis is a well-known method for the sep- aration of non-linearly combined signals. More particularly, the use of complex cepstrum for source-tract deconvolution has been discussed in various articles. However there exists no study which proposes a glottal Ã¯Â¬Âow estimation methodology based on cepstrum and reports effective results. In this pa- per, we show that complex cepstrum can be effectively used for glottal Ã¯Â¬Âow estimation by separating the causal and anticausal components of a windowed speech signal as done by the Ze- ros of the Z-Transform (ZZT) decomposition. Based on exactly the same principles presented for ZZT decomposition, window- ing should be applied such that the windowed speech signals exhibit mixed-phase characteristics which conform the speech production model that the anticausal component is mainly due to the glottal Ã¯Â¬Âow open phase. The advantage of the complex cepstrum-based approach compared to the ZZT decomposition is its much higher speed.",
	author = "Drugman, T. and Bozkurt, B. and Dutoit, T.",
	booktitle = "{Proc. Interspeech}",
	journal = "Interspeech",
	keywords = "Glottal Source Estimation; Homomorphic Processing; Speech Analysis",
	lockkey = "Y",
	pages = "116--119",
	title = "{Complex Cepstrum-based Decomposition of Speech for Glottal Source Estimation}",
	year = 2009
}

@article{Klatt1990,
	abstract = "Voice quality variations include a set of voicing sound source modifications ranging from laryngealized to normal to breathy phonation. Analysis of reiterant imitations of two sentences by ten female and six male talkers has shown that the potential acoustic cues to this type of voice quality variation include: (1) increases to the relative amplitude of the fundamental frequency component as open quotient increases; (2) increases to the amount of aspiration noise that replaces higher frequency harmonics as the arytenoids become more separated; (3) increases to lower formant bandwidths; and (4) introduction of extra pole zeros in the vocal-tract transfer function associated with tracheal coupling. Perceptual validation of the relative importance of these cues for signaling a breathy voice quality has been accomplished using a new voicing source model for synthesis of more natural male and female voices. The new formant synthesizer, KLSYN88, is fully documented here. Results of the perception 
study indicate that, contrary to previous research which emphasizes the importance of increased amplitude of the fundamental component, aspiration noise is perceptually most important. Without its presence, increases to the fundamental component may induce the sensation of nasality in a high-pitched voice. Further results of the acoustic analysis include the observations that: (1) over the course of a sentence, the acoustic manifestations of breathiness vary considerably--tending to increase for unstressed syllables, in utterance-final syllables, and at the margins of voiceless consonants; (2) on average, females are more breathy than males, but there are very large differences between subjects within each gender; (3) many utterances appear to end in a ``breathy-laryngealized'' type of vibration; and (4) diplophonic irregularities in the timing of glottal periods occur frequently, especially at the end of an utterance. Diplophonia and other deviations from perfect periodicity may be important aspects of 
naturalness in synthesis.",
	author = "Klatt, Dennis H. and Klatt, Laura C.",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "2",
	pages = "820--857",
	title = "{Analysis, synthesis, and perception of voice quality variations among female and male talkers}",
	volume = "87",
	year = "1990"
}

@article{Fant1979,
	author = "Fant, G.",
	journal = "STL-QPSR",
	lockkey = "Y",
	number = "3-4",
	pages = "31--53",
	title = "{Vocal source analysis - a progress report}",
	volume = "20",
	year = "1979"
}

@inproceedings{Hedelin1984,
	abstract = "A procedure is suggested for improving LPC speech quality. The central theme is to introduce a parametric model of voiced excitation - a glottal source model. In the analysis this allows for a different method than the AR-estimation used in conventional LPC. Here, a method known as AR-X-estimation is used. A complete analysis and coding method is presented. It is found that the additional glottal parameters can be coded effectively such that the total bit rate is in the same range as for conventional LPC. The glottal LPC-vocoder does significantly improve synthesis quality as compared to standard LPC. It should be emphasized, however, that the glottal vocoder requires high quality speech as input, recorded in a phase linear system. Moreover, the computational complexity is high.",
	author = "Hedelin, P",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	pages = "21--24",
	title = "{A glottal {LPC}-vocoder}",
	volume = "9",
	year = 1984
}

@article{Ananthapadmanabha1984,
	author = "Ananthapadmanabha, T. V.",
	comment = "A voice source model intended to capture the variations in the inverse filter output (derivativeof glottal pulses) of the acoustic speech data is described. The voice source modelling is proped in two stages: (a) analysis stage identifying five analysis variables, and (b) synthesis stage for reconstructing source pulses from the analysis variables. With such a distinction, the same analysis variables may be related to the parameters of already existing glottal pulse models or may be used to develop new models with a common set of variables. A specific computational scheme for the measurement of analysis variables from the acoustic data is proposed. Unlike the usual approach, the modelling is done directly on the inverse filter output rather than on its integral, the glottal pulses. Also, an important analysis variable is related to the nonabrupt glottal closure gesture which is highly correlated to the relative abduction state of the vocal folds. The present model thus allows an indirect tracking 
of the degree of abduc- tion. Male, female and children's speech have accordingly been analysed and synthesised which has rendered high quality natural sounding speech.",
	institution = "KTH STL-QPSR",
	journal = "STL-QPSR",
	lockkey = "Y",
	number = "2-3",
	pages = "1--24",
	title = "{Acoustic analysis of voice source dynamics}",
	volume = "25",
	year = 1984
}

@article{Rosenberg1971,
	abstract = "A pitch-synchronous analysis was carried out over the vowel portions of the CVC utterances HAYED, HOD, HODE and the sentence FEW THIEVES ARE NEVER SENT TO THE JUG recorded by a male speaker. For every pitch period, the analysis provides formant frequencies and the waveform of the vocal-cord excitation. The excitation waveform was replaced by a simulated excitation waveform, with which the utterances were resynthesized. In Expt. I, six simulated waveforms with pulse shapes differing in the number and location of slope discontinuities were investigated. Listening tests indicated that simulated excitations with pulse shapes with a single slope discontinuity at closure are preferred. In Expt. II, simulated excitations with 16 combinations of opening and closing times of a preferred pulse shape were investigated. Listening tests indicated that very small opening or closing times, or opening times approximately equal to or less than closing times, are not preferred. In general, it was demonstrated 
that good-quality synthetic speech can be generated by using simple excitation waveforms specified uniformly over an utterance. The use of tournament testing strategies for perceptual evaluation of speech samples is also described.",
	author = "Rosenberg, A. E.",
	doi = "10.1121/1.1912389",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "2B",
	pages = "583--590",
	publisher = "ASA",
	title = "{Effect of Glottal Pulse Shape on the Quality of Natural Vowels}",
	url = "http://link.aip.org/link/?JAS/49/583/1",
	volume = "49",
	year = "1971"
}

@article{Fant1997,
	author = "Fant, G.",
	journal = "Speech Communication",
	lockkey = "Y",
	title = "{The voice source in connected speech}",
	year = "1997"
}

@inproceedings{Fujisaki1986,
	abstract = "Speech analysis for high quality speech synthesis or high accuracy speech recognition requires realistic models not only for the vocal tract but also for the voice source. In the present paper, we investigate models for the glottal volume velocity waveform. Previously proposed models are reviewed and classified according to their level of elaboration in expressing the glottal characteristics. A new model is then proposed which possesses all the important features of previously proposed models. A method is also described for simultaneously estimating the glottal source and vocal: tract parameters. Using this method, evaluation of glottal model parameters is carried out on real speech by varying the number of parameters in the proposed model. The results indicate the importance of detailed modeling of the period of glottal closure for accurate analysis.",
	author = "Fujisaki, H. and Ljungqvist, M.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	pages = "1605--1608",
	title = "{Proposal and evaluation of models for the glottal source waveform}",
	volume = "11",
	year = "1986"
}

@article{Plumpe1999,
	abstract = "An automatic technique for estimating and modeling the glottal flow derivative source waveform from speech, and applying the model parameters to speaker identification, is presented. The estimate of the glottal flow derivative is decomposed into coarse structure, representing the general flow shape, and fine structure, comprising aspiration and other perturbations in the flow, from which model parameters are obtained. The glottal flow derivative is estimated using an inverse filter determined within a time interval of vocal-fold closure that is identified through differences in formant frequency modulation during the open and closed phases of the glottal cycle. This formant motion is predicted by Ananthapadmanabha and Fant (1982) to be a result of time-varying and nonlinear source/vocal tract coupling within a glottal cycle. The glottal flow derivative estimate is modeled using the Liljencrants-Fant (1986) model to capture its coarse structure, while the fine structure of the flow derivative is 
represented through energy and perturbation measures. The model parameters are used in a Gaussian mixture model speaker identification (SID) system. Both coarse- and fine-structure glottal features are shown to contain significant speaker-dependent information. For a large TIMIT database subset, averaging over male and female SID scores, the coarse-structure parameters achieve about 60\% accuracy, the fine-structure parameters give about 40\% accuracy, and their combination yields about 70\% correct identification. Finally, in preliminary experiments on the counterpart telephone-degraded NTIMIT database, about a 5\% error reduction in SID scores is obtained when source features are combined with traditional mel-cepstral measures",
	author = "Plumpe, M.D. and Quatieri, T.F. and Reynolds, D.A.",
	doi = "10.1109/89.784109",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "Gaussian mixture model; Liljencrants-Fant model; aspiration; automatic technique; coarse structure; energy measures; error reduction; fine structure; fine-structure parameters; formant frequency modulation; formant motion; general flow shape; glottal cycle; glottal flow derivative source waveform; glottal flow derivative waveform; inverse filter; large TIMIT database subset; mel-cepstral measures; model parameters; nonlinear source/vocal tract coupling; perturbation measures; perturbations; speaker identification; speech waveform; telephone-degraded NTIMIT database; time interval; time-varying source/vocal tract coupling; vocal-fold closure; waveform estimation; waveform modeling; Gaussian processes; filtering theory; inverse problems; parameter estimation; speaker recognition; speech processing; waveform analysis",
	lockkey = "Y",
	number = "5",
	pages = "569--586",
	title = "{Modeling of the glottal flow derivative waveform with application to speaker identification}",
	volume = "7",
	year = "1999"
}

@article{Lindqvist1965,
	author = "Lindqvist-Gauffin, J.",
	journal = "STL-QPSR",
	lockkey = "Y",
	title = "{Studies of the voice source by means of inverse filtering}",
	year = 1965
}

@phdthesis{Gobl2003,
	author = "Gobl, C",
	comment = "This thesis explores, through a number of production and perception studies, the nature of the voice source signal and how it varies in spoken communication. Research is also presented that deals with the techniques and methodologies for analysing and synthesising the voice source. The main analytic technique involves interactive inverse filtering for obtaining the source signal, which is then parameterised to permit the quantification of source characteristics. The para- meterisation is carried by means of model matching, using the four-parameter LF model of differentiated glottal flow. The first three analytic studies focus on segmental and suprasegmental determinants of source variation. As part of the prosodic variation of utterances, focal stress shows for the glottal excitation an enhancement between the stressed vowel and the surrounding consonants. At a segmental level, the voice source characteristics of a vowel show potentially major differences as a function of the voiced/voiceless 
nature of an adjacent stop. Cross-language differences in the extent and directionality of the observed effects suggest different underlying control strategies in terms of the timing of the laryngeal and supralaryngeal gestures, as well as in the laryngeal tensions settings. Different classes of voiced consonants also show differences in source characteristics: here the differences are likely to be passive consequences of the aerodynamic conditions that are inherent to the consonants. Two further analytic studies present voice source correlates for six different voice qualities as defined by Laver{\rq}s classification system. Data from stressed and unstressed contexts clearly show that the transformation from one voice quality to another does not simply involve global changes of the source parameters. As well as providing insights into these aspects of speech production, the analytic studies provide quantitative meas- ures useful in technology applications, particularly in speech synthesis. The perceptual 
experiments use the LF source implementation in the KLSYN88 synthesiser to test some of the analytic results and to harness them to explore the paralinguistic dimension of speech communication. A study of the perceptual salience of different parameters associated with breathy voice indicates that the source spectral slope is critically important and that, sur- prisingly, aspiration noise contributes relatively little. Further perceptual tests using stimuli with different voice qualities explore the mapping between voice quality and its paralinguistic function of expressing emotion, mood and attitude. The results of these studies highlight the crucial role of voice quality in expressing affect as well as providing pointers to how it combines with f 0 for this purpose. The last section of the thesis focuses on the techniques used for the analysis and synthesis of the source. A semi-automatic method for inverse filtering is presented, which is novel in that it optimises the inverse filter by exploiting the 
knowledge that is typically used by the experimenter when carrying out manual interactive inverse filtering. A further study looks at the properties of the modified LF model in the KLSYN88 synthesiser: it highlights how it differs from the stan- dard LF model and discusses the implications for synthesising the glottal source signal from LF model data. Effective and robust source parameterisation for the analysis of voice quality is the topic of the final paper: the effectiveness of global, amplitude-based, source parameters is exam- ined across speech tokens with large differences in f 0. Additional amplitude-based parameters are proposed to enable a more detailed characterisation of the glottal pulse. Keywords: Voice source dynamics, glottal source parameters, source-filter interaction, voice quality, phonation, perception, affect, emotion, mood, attitude, paralinguistic, inverse filtering, knowledge-based, formant synthesis, LF model, fundamental frequency, f 0.",
	lockkey = "Y",
	school = "KTH",
	title = "{The voice source in speech communication}",
	year = 2003
}

@inproceedings{Bognar1986,
	abstract = "The purpose of the research reported here was to find out some acoustical and perceptual characteristics of the French nasal vowels. Acoustic analysis was made using a Pole-Zero Analysis-by-Synthesis procedure : below 4 kHz (in the case of male adult informants) the main acoustic correlates of the nasal vowels are the formant shifts and the introduction of two pole-zero pairs, one below F1, the other between F2 and F3. By means of a pole-zero synthesizer, synthetic stimuli were generated : two of them have the spectral characteristics of the real vowels [varepsilon] and [tilde{varepsilon}], while the others are stimuli whose spectral characteristics are between those of [varepsilon] and [tilde{varepsilon}]. Phonemic and phonetic perceptual tests were conducted. Their results show that formant shifts and pole-zero separation contribute almost equally to the decision on the phonemic identity of /varepsilon/ versus /tilde{varepsilon}/, whereas pole-zero separation has a stronger effect than formant 
shifts in the phonetic judgment on nasality.",
	author = "Bognar, E. Fujisaki H.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{Analysis, synthesis and perception of the French nasal vowels}",
	year = "1986"
}

@article{Wong1979,
	abstract = "Covariance analysis as a least squares approach for accurately performing glottal inverse filtering from the acoustic speech waveform is discussed. Best results are obtained by situating the analysis window within a stable closed glottis interval. Based on a linear model of speech production, it is shown that both the moment of glottal closure and opening can be determined from the normalized total squared error with proper choices of analysis window length and filter order. Results from actual speech are presented to illustrate the technique.",
	author = "Wong, D. and Markel, J. D. and Gray, A. H.",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "4",
	pages = "350--355",
	title = "{Least squares glottal inverse filtering from the acoustic speech waveform}",
	volume = "27",
	year = "1979"
}

@phdthesis{Liljencrants1985,
	address = "Sweden",
	author = "Liljencrants, Johan",
	lockkey = "Y",
	school = "KTH - Royal Institute of Technology",
	title = "{Speech synthesis with a reflection-type line analog}",
	year = "1985"
}

@article{Belbin2009,
	author = "Belbin",
	journal = "Nature",
	lockkey = "Y",
	title = "{Credit where credit is due}",
	year = 2009
}

@book{Fant1970,
	author = "Fant, G.",
	lockkey = "Y",
	publisher = "Mouton, The Hague",
	title = "{Acoustic theory of speech production}",
	year = "1970"
}

@inproceedings{Rahman2005,
	abstract = "A two-pass least square method have been proposed for estimating the vocal tract parameters. An often encountered problem in using the conventional linear prediction analysis is due to the harmonic structure of the excitation source of voiced speech. This harmonic characteristic is coupled with the estimation of autoregressive (AR) coefficients that results in difficulties in estimating the vocal tract filter. This paper models the effective voice source from the residual obtained through the covariance analysis in the first-pass which is then used as input to the second-pass least square analysis. A better source-filter separation is thus achieved. The formant frequencies and bandwidths estimated using the proposed method for synthetic. These vowels are found to be accurate up to a factor of more than three (in percent) compared to the conventional method. Since the source characteristic is taken into account, local variations due to the positioning of analysis window are reduced significantly. 
The validity of the proposed method is also verified by inspecting the spectra obtained from natural vowel sounds uttered by high-pitched female speaker",
	author = "Rahman, M.S. and Shimamura, T.",
	booktitle = "{IEEE Conference on Signals, Systems and Computers}",
	lockkey = "Y",
	pages = "305--309",
	title = "{Voice Source Modeling for Accurate Speech Analysis}",
	year = "2005"
}

@article{Rahman2006,
	abstract = "A new system identification based method has been proposed for accurate estimation of vocal tract parameters. An often encountered problem in using the conventional linear prediction analysis is due to the harmonic structure of the excitation source of voiced speech. This harmonic characteristic is coupled with the estimation of autoregressive (AR) coefficients that results in difficulties in estimating the vocal tract filter. This paper models the effective voice source from the residual obtained through the covariance analysis in the first-pass which is then used as input to the second-pass least-square analysis. A better source-filter separation is thus achieved. The formant frequencies and corresponding bandwidths obtained using the proposed method for synthetic vowels are found to be accurate up to a factor of more than three (in percent) compared to the conventional method. Since the source characteristic is taken into account, local variations due to the positioning of analysis window are 
reduced significantly. The validity of the proposed method is also examined by inspecting the spectra obtained from natural vowel sounds uttered by high-pitched female speaker.",
	author = "Rahman, M.S. and Shimamura, T.",
	journal = "IEICE - Trans. on Information and Systems",
	keywords = "glottal waveform; eÃ¯Â¬Âective voice source; linear prediction; least square method; system identiÃ¯Â¬Âcation",
	lockkey = "Y",
	number = "3",
	pages = "1107--1115",
	title = "{Speech Analysis Based on Modeling the Effective Voice Source}",
	volume = "E89-D",
	year = "2006"
}

@article{Rahman2007,
	abstract = "A two-stage least square identification method is proposed for estimating ARMA (autoregressive moving average) coefficients from speech signals. A pulse-train like input sequence is often employed to account for the source effects in estimating vocal tract parameters of voiced speech. Due to glottal and radiation effects, the pulse train, however, does not represent the effective voice source. The authors have already proposed a simple but effective model of voice source for estimating AR (autoregressive) coefficients. This letter extends our approach to ARMA analysis to wider varieties of speech sounds including nasal vowels and consonants. Analysis results on both synthetic and natural nasal speech are presented to demonstrate the analysis ability of the method.",
	author = "Rahman, M.S. and Shimamura, T.",
	journal = "IEICE - Trans. on Information and Systems",
	keywords = "ARMA modeling; effective voice source; glottal waveform; least square identification; linear prediction",
	lockkey = "Y",
	number = "5",
	pages = "863--867",
	title = "{Identification of ARMA Speech Models Using an Effective Representation of Voice Source}",
	volume = "E90-D",
	year = "2007"
}

@article{Titze2007,
	abstract = "A theory of interaction between the source of sound in phonation and the vocal tract filter is developed. The degree of interaction is controlled by the cross-sectional area of the laryngeal vestibule (epilarynx tube), which raises the inertive reactance of the supraglottal vocal tract. Both subglottal and supraglottal reactances can enhance the driving pressures of the vocal folds and the glottal flow, thereby increasing the energy level at the source. The theory predicts that instabilities in vibration modes may occur when harmonics pass through formants during pitch or vowel changes. Unlike in most musical instruments (e.g., woodwinds and brasses), a stable harmonic source spectrum is not obtained by tuning harmonics to vocal tract resonances, but rather by placing harmonics into favorable reactance regions. This allows for positive reinforcement of the harmonics by supraglottal inertive reactance (and to a lesser degree by subglottal compliant reactance) without the risk of instability. The 
traditional linear source--filter theory is encumbered with possible inconsistencies in the glottal flow spectrum, which is shown to be influenced by interaction. In addition, the linear theory does not predict bifurcations in the dynamical behavior of vocal fold vibration due to acoustic loading by the vocal tract.",
	author = "Titze, Ingo R.",
	doi = "10.1121/1.2832337",
	journal = "Journal of the Acoustical Society of America",
	keywords = "bifurcation; biological organs; filtering theory; harmonics; nonlinear acoustics; speech; stability; vibrations",
	lockkey = "Y",
	number = "5",
	pages = "2733--2749",
	publisher = "ASA",
	title = "{Nonlinear source--filter coupling in phonation: Theory}",
	url = "http://link.aip.org/link/?JAS/123/2733/1",
	volume = "123",
	year = "2008"
}

@article{Wakita1978,
	abstract = "Computer simulations of a vocal-tract model have given a further insight in the relative importance of the glottal imped- ance, the subglottal system, and the vocal cavity walls a s boundary conditions. The shift in frequency and bandwidth of vocal resonances associated with these terminations have been studied. It was found that the subglottal system contributed r a t h e r little but that the glottal impedance h a s a pronounced in- f luence in vowels [o] and [a] , where the characteristic im- pedance of the pharyngeal constriction may match the parallel glottal resistance. Formant bandwidths derived from the model match those of Fujimura and Lindqvist ( 1 97 1) with a tendency to fall in the 1ower p a r t of the distribution.",
	author = "Wakita, H. and Fant, G.",
	journal = "STL-QPSR",
	lockkey = "Y",
	number = "1",
	pages = "9--29",
	title = "{Toward a better vocal tract model}",
	volume = "19",
	year = "1978"
}

@techreport{Ghosh1999,
	address = "USA",
	author = "Ghosh, S. S.",
	institution = "Boston University",
	lockkey = "Y",
	note = "http://speechlab.bu.edu/VTCalcs.php",
	title = "{{VTCALCS} for Matlab v1.0}",
	year = "1999"
}

@article{Stevens1971,
	abstract = "A number speech of sounds generated creating are by turbulentairflowin the vicinityof a constriction in the vocaltract. The equations relatingthe airflowthroughsucha constriction, pressure the drop across the constriction, the dimensions the constriction reviewed are summarized graphical and of are and in form.Previous theoretical experimental on turbulence and data noisegeneration a constriction ob- at or structionin a tube are described.Thesedata are consistent with a modelthat represents turbulence a noisesource the vocaltractas an equivalent in sound-pressure whose source magnitude proportional is to the pressure across constriction obstruction. characteristicsthe sound drop the or The of radiated from the mouthopening determined the source are by location radiation and characteristics,wellas by the as properties the source. airflowand acoustic of The characteristics various for classes speech of sounds pro- ducedwith turbulence noise the glottisor at a supraglottal at constriction discussed 
the light of are in thesefindings.",
	author = "Stevens, Kenneth N.",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "4",
	pages = "1180--1192",
	title = "{Airflow and Turbulence Noise for Fricative and Stop Consonants: Static Considerations}",
	volume = "50",
	year = "1971"
}

@inproceedings{Rao2003,
	abstract = "This paper proposes a technique for prosodic (pitch and duration) manipulation using instants of significant excitation. Instants of significant excitation correspond to the instants of glottal closure (epochs) in voiced speech and to some random excitations like burst onset in the case of nonvoiced speech. Instants of significant excitation are computed from the average group delay of minimum phase signals. The manipulation of pitch and duration is achieved by modifying the linear prediction (LP) residual with the help of instants of significant excitation as pitch markers. The modified residual is used to excite the time-varying filter whose parameters are derived from the original speech signal. Perceptual quality of the synthesized speech is found to be natural, and is without any distortion. The original and corresponding synthesized speech signals from the proposed approach are available for listening at http://speech.cs.iitm.ernet.in/Main/Results/Prosody.html.",
	author = "Rao, K. S. and Yegnanarayana, B.",
	booktitle = "{ICME}",
	lockkey = "Y",
	title = "{Prosodic manipulation using instants of significant excitation}",
	year = 2003
}

@article{RahmanMS2007lpra,
	abstract = "This paper proposes a new technique for improving the performance of linear prediction analysis by utilizing a refined version of the autocorrelation function. Problems in analyzing voiced speech using linear prediction occur often due to the harmonic structure of the excitation source, which causes the autocorrelation function to be an aliased version of that of the vocal tract impulse response. To estimate the vocal tract characteristics accurately, however, the effect of aliasing must be eliminated. In this paper, we employ homomorphic deconvolution technique in the autocorrelation domain to eliminate the aliasing effect occurred due to periodicity. The resulted autocorrelation function of the vocal tract impulse response is found to produce significant improvement in estimating formant frequencies. The accuracy of formant estimation is verified on synthetic vowels for a wide range of pitch frequencies typical for male and female speakers. The validity of the proposed method is also 
illustrated by inspecting the spectral envelopes of natural speech spoken by high-pitched female speaker. The synthesis filter obtained by the current method is guaranteed to be stable, which makes the method superior to many of its alternatives.",
	author = "Rahman, M.S. and Shimamura, T.",
	journal = "EURASIP Journal on Audio, Speech, and Music Processing",
	lockkey = "Y",
	title = "{Linear prediction using refined autocorrelation function}",
	year = 2007
}

@article{Sondhi1975,
	abstract = "The glottal volume flow is usually estimated by inverse--filtering the speech wave, by taking a motion picture of the vocal--cord vibration, or by a variety of other methods that estimate the size of the glottal opening. We present a much simpler alternative based on the following idea: The effect of the vocal--tract resonances on the glottal pulse is considerably reduced by speaking into a reflectionless uniform tube. If, in addition, the tract is held in a neutral position, the effect is almost entirely eliminated and the glottal waveform may be recorded by a microphone in the uniform tube. Some examples are presented of glottal pulses recorded in this manner. The new method is compared to the ones available heretofore, and some potential uses of the method are suggested.",
	author = "Sondhi, M. M.",
	journal = "JASA",
	lockkey = "Y",
	title = "{Measurement of the glottal waveform}",
	year = 1975
}

@article{Titze2008,
	abstract = "Nonlinear source-filter theory is applied to explain some acoustic differences between two contrasting male singing productions at high pitches: operatic style versus jazz belt or theater belt. Several stylized vocal tract shapes (caricatures) are discussed that form the bases of these styles. It is hypothesized that operatic singing uses vowels that are modified toward an inverted megaphone mouth shape for transitioning into the high-pitch range. This allows all the harmonics except the fundamental to be ``lifted'' over the first formant. Belting, on the other hand, uses vowels that are consistently modified toward the megaphone (trumpet-like) mouth shape. Both the fundamental and the second harmonic are then kept below the first formant. The vocal tract shapes provide collective reinforcement to multiple harmonics in the form of inertive supraglottal reactance and compliant subglottal reactance. Examples of lip openings from four well-known artists are used to infer vocal tract area functions 
and the corresponding reactances.",
	author = "Titze, I. R and Worley, A. S.",
	journal = "JASA",
	lockkey = "Y",
	title = "{Modeling source-filter interaction in belting and high-pitched operatic male singing}",
	year = 2008
}

@article{Hannukainen2006,
	abstract = "This article describes modal analysis of acoustic waves in the human vocal tract while the subject is pronouncing [{\o}[lengthening]]. The model used is the wave equation in three dimensions, together with physically relevant boundary conditions. The geometry is reconstructed from anatomical MRI data obtained by other researchers. The computations are carried out using the finite element method. The model is validated by comparing the computed modes with measured data.",
	author = "Hannukainen, A. and Lukkari, T. and Malinen, J. and Palo, P.",
	journal = "JASA",
	lockkey = "Y",
	title = "{Vowel formants from the wave equation}",
	year = 2006
}

@article{Pincas2006,
	abstract = "The two principal sources of sound in speech, voicing and frication, occur simultaneously in voiced fricatives as well as at the vowel-fricative boundary in phonologically voiceless fricatives. Instead of simply overlapping, the two sources interact. This paper is an acoustic study of one such interaction effect: the amplitude modulation of the frication component when voicing is present. Corpora of sustained and fluent-speech English fricatives were recorded and analyzed using a signal-processing technique designed to extract estimates of modulation depth. Results reveal a pattern, consistent across speaking style, speaker, and place of articulation, for modulation at f0 to rise at low voicing strengths and subsequently saturate. Voicing strength needed to produce saturation varied 60--66 dB across subjects and experimental conditions. Modulation depths at saturation varied little across speakers but significantly for place of articulation (with [z] showing particularly strong modulation) 
clustering at approximately 0.4--0.5 (a 40\%--50\% fluctuation above and below unmodulated amplitude); spectral analysis of modulating signals revealed weak but detectable modulation at the second and third harmonics (i.e., 2f0 and 3f0)",
	author = "Pincas, J. and Jackson, P. J. B.",
	journal = "JASA",
	lockkey = "Y",
	title = "{Amplitude modulation of turbulence noise by voicing in fricatives}",
	year = 2006
}

@inproceedings{El-Masri1996,
	abstract = "Most traditional theories of speech production are currently based on plane waves and on one-dimensional analysis. It is however well-known that when the frequency of sound reaches a cut-on frequency, higher acoustical modes start to propagate and can become predominant. It is therefore important to evaluate the effects of these higher modes, especially in order to improve acoustical models of the vocal tract. The paper describes a new numerical method to study the propagation and the radiation of speech sounds, and to compute acoustic characteristics of the vocal tract. This method, named transmission line matrix or modelling (TLM), has been used for simulating electromagnetic wave propagation and is used for the first time in acoustics. The TLM method provides time domain solutions in 2D and 3D spaces. The main advantage of this method is the simplicity of formulation and programming for a large range of applications. The authors first describe the principle on which the TLM method is based. 
The method as well as the boundary conditions used are validated using classical tests. A systematic study of higher order mode propagation and radiation is then presented. They focus on the influence of some critical parameters such as vocal tract width and location of the sound source. In particular, they show how, using TLM simulation, it is possible to derive modal reflection and transmission characteristics of the vocal tract. A typical example of simulation is presented and discussed",
	author = "El-Masri, S. and Pelorson, X. and Saguet, P. and Badin, P.",
	booktitle = "{Proc. International Conference on Spoken Language Processing (ICSLP)}",
	lockkey = "Y",
	pages = "953--956 vol. 2",
	title = "{Vocal tract acoustics using the transmission line matrix ({TLM}) method}",
	year = 1996
}

@inproceedings{Pelorson2002,
	abstract = "The TLM method, originally developed for electromagnetism applications, has been adapted to simulate the acoustics of the vocal tract. Although the TLM method cannot overcome traditional techniques such as FEM or FDM in terms of computational costs, it is shown that this method can be a very useful and simple tool for acoustical investigations. Specific examples concerning the effects of a bend in the vocal tract, of the teeth or of 3-D propagation will be presented and discussed.",
	author = "X., PELORSON and P., BADIN and P., SAGUET and S., ElMasri",
	booktitle = "{Forum Acusticum}",
	lockkey = "Y",
	title = "{Numerical simulation of the vocal tract acoustics using the {TLM} Method}",
	year = 2002
}

@inbook{Mathews2004a,
	author = "Mathews, J. H. and Fink, K. D.",
	chapter = "Numerical difference",
	comment = "numeric derivative approximation",
	lockkey = "Y",
	publisher = "Prentice-Hall",
	title = "{Numerical Methods Using Matlab}",
	year = 2004
}

@inproceedings{Ding1997,
	abstract = "A new pitch-synchronous method of joint estimation is described to estimate vocal tract and voice source parameters from speech signals based on an autoregressive model with an exogenous input (ARX) model. The method uses Kalman filtering to estimate the time-varying coefficients and simulated annealing to deal with the non-linear optimization of Rosenberg-Klatt parameters. A compact method is suggested in the algorithm in order to reduce the computation cost. Further, an automatic model order selection method is proposed to determine the proper analysis pole-order of the ARX model, based on the estimated formant bandwidths. The new method has been shown to be much faster than our previous method and the order selection technique has been shown to be effective. Finally, an ATR two-channel speech database including varying sentence-level prominence patterns is used to verify the proposed method",
	author = "Ding, W. and Campbell, N. and Higuchi, N. and Kasuya, H.",
	booktitle = "{IEEE International Conference on Acoustics, Speech, and Signal Processing}",
	journal = "ICASSP",
	lockkey = "Y",
	title = "{Fast and robust joint estimation of vocal tract and voice sourceparameters}",
	year = 1997
}

@article{Lindqvist1972,
	abstract = "Sweep-frequency measurements of the t r a n s f e r function of nasals and nasalized vowels have been found to show a more complex pole - z e r o pat- t e r n than can be predicted with a traditional model of the nasal t r a c t which consists of two parallel tubes coupled to the o r a l cavities. In this paper we put forward the hypothesis that the m o r e complex t r a n s f e r function can be explained with reference to the shunting effect of the sinus maxillares and the sinus frontales. The two maxillar sinuses a r e situated in the bone symmetrically on the right and left side of the nasal tract. The two frontal sinuses a r e situated above the nasal t r a c t in the bone of the forehead. These cavities a r e acoustically coupled to the nasal t r a c t via short channels in the bone. Direct sweep-tone data on the transfer function of the nasal t r a c t support this hypothesis.",
	author = "Lindqvist-Gauffin, J. and Sundberg, J.",
	journal = "STL-QPSR",
	lockkey = "Y",
	number = "1",
	pages = "13--17",
	title = "{Acoustic properties of the nasal tract}",
	volume = "13",
	year = "1972"
}

@book{Rabiner1978,
	author = "Rabiner, Lawrence R. and Schafer, Ronald W.",
	catalogue-url = "http://nla.gov.au/nla.cat-vn987815",
	isbn = "0132136031",
	language = "English",
	life-dates = "1978 -",
	lockkey = "Y",
	pages = "xvi, 512 p. :",
	publisher = "Prentice-Hall",
	subjects = "Speech processing systems.; Digital electronics.",
	title = "{Digital processing of speech signals}",
	type = "Book",
	year = "1978"
}

@inproceedings{Rossato1999,
	abstract = "In most of studies on nasal vowel production, the nasal tract area at the uvula is used. The ratio between the nasal and the oral tract areas is also proposed. The aim of this paper is to determine which velar variable is more relevant of acoustic changes in nasal vowel transfer functions. It can be considered that each value of a velar variable corresponds to a probability distribution in the acoustic space. Samples of transfer functions representative of this probability distribution are generated by an articulatory model and the statistical Friedman-Rafsky test gives an objective criterion to the approximate notion of ``separation'' of two multivariate samples. Results show that when the nasal area increases, the sensibility of acoustic transfer functions to nasal area variations decreases and the area ratio becomes a more reliable parameter of acoustics changes in transfer functions.",
	author = "Rossato, S. and Feng, G.",
	booktitle = "{ICPhS}",
	lockkey = "Y",
	title = "{Nasal Vowel Transfer Functions: a statistical comparison between the nasal area and the area ratio}",
	year = "1999"
}

@mastersthesis{Elie2009,
	abstract = "Vocal tract acoustics is very important in speech since vocal tract resonances play a major influence on segment perception. Very often, the vocal tract is only considered as a filter independent from the glottal source (Fant, 1960 [21]), enhancing the energy of the voice around resonance frequencies of the vocal tract. This simple source-filter theory of phonation does not account for exchanges of energy between the vocal tract and the vocal folds vibration, which are above all a resonator and an excitation source. Such source-filter interactions occur in efficient techniques of production. In particular, singers and speakers have been shown to adjust the frequency of vocal tract resonances very close to voice harmonics in several singing techniques (Smith, 2007 [47], Henrich, 2006 [31], Joliveau, 2004 [33], Garnier, submitted [26], Miller, 1990 [41]) or speaking modes (Garnier, 2008 [28]). Theoretical models support the idea that such ``formant tunings'' (Carlsson, 1992 [5]) make the vocal 
folds vibration easier and improve phonation efficiency (Titze, 1992 [49], Titze, 2008 [50]).",
	address = "France/Australia",
	author = "Elie, Benjamin",
	lockkey = "Y",
	school = "UPMC/UNSW",
	title = "{Characterisation of vocal tract acoustics in the case of oro-nasal coupling}",
	year = "2009"
}

@inproceedings{Desccut1976,
	abstract = "Two methods are described for determining the vocal tract area function from measurements at the lips of the response to an impulsive acoustic pressure wave: - In one case, the impulse response at the lips obtained by deconvolution is used to compute the area function at all points; - Alternatively, the vocal tract is modeled by successive approximation, a search is made for the constrictions by decreasing order of importance rather than sequentially from the lips. Results obtained with both methods are good, the area functions are measured in absolute values rather than in arbitrary units. Advantages, difficulties and limitations of both methods are discussed.",
	author = "Desccut, R. and Tousignant, B. and Lecours, M.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{Vocal tract area function measurements: Two time-domain methods}",
	year = "1976"
}

@article{Mermelstein1966,
	author = "Mermelstein, P.",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	title = "{Determination of the Vocal-Tract Shape from Measured Formant Frequencies}",
	year = "1966"
}

@inproceedings{Maeda1982b,
	abstract = "The acoustic wave propagation inside the vocal tract was simulated assuming plane waves. When an acoustic tube having appropriate area function but no side branching cavities was used as the nasal tract, the low frequency nasal formant below the first formant of low vowels as observed in natural speech could not be simulated. The relatively short nasal tract with both ends open cannot produce the low nasal formant. We therefore employed a side cavity for the nasal tract system, which gave rise to the nasal formant in the expected frequency region. The computed output signals for different nasalized vowels sounded very naturally nasal.",
	author = "Maeda, S.",
	booktitle = "{IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1982.1171561",
	lockkey = "Y",
	month = may,
	pages = "911--914",
	title = "{The role of the sinus cavities in the production of nasal vowels}",
	volume = "7",
	year = "1982"
}

@article{Fujimura1970,
	abstract = "The vocal tract was excited transcutaneously at a point just above the glottis by an external sweep-tone signal, in order to measure its transfer characteristics acoustically as continuous frequency functions. An analysis-by-synthesis procedure derived reliable data of vowels, in particular of the formant bandwidths, for three male and three female normal subjects. It has been shown for the closed glottis condition that the first formant bandwidths are higher for close vowels (typically 70 Hz for male subjects) than for semi-open vowels (typically 35 Hz for male subjects). Stationary consonantal articulations including stops, nasals, and nasalized vowels also have been studied, as well as the effect of opening the glottis on the vocal-tract transfer characteristics. The stop articulations give rise to a first-formant frequency slightly below 200 Hz. This fact and the high dissipation of the first formant is explained by assuming nonrigidness of the surrounding wall. Characteristics of nasalized 
vowels and nasal murmurs are also discussed based on the data obtained in this experiment.",
	author = "Fujimura, O. and Lindqvist, J.",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "2B",
	pages = "541--558",
	title = "{Sweep-Tone Measurements of Vocal-Tract Characteristics}",
	volume = "49",
	year = "1971"
}

@article{Sondhi1979,
	abstract = "It is well known that the transfer function of a lossless vocal tract (much less that of a tract with losses) does not uniquely specify its area function. Further, the speech wave does not uniquely specify the transfer function. In spite of this proven nonuniqueness, several investigators during the past few years have proposed methods for estimating area functions from the speech wave. In this paper we will critically examine some of the tacit assumptions on which these proposals are based. The validity of the assumptions is not easily tested, nor is it feasible to estimate the effects of departures from them. For reliable recovery, therefore, we will argue for a renewed interest in the method based on the measured driving point impulse response at the lips. This method recovers the area function exactly under the plane wave approximation for a lossless vocal tract, as well as for tracts with certain types of distributed losses. We will briefly review this method and present evidence that 
departures from the basic assumptions do not drastically affect the reconstructed area functions. We will also point out the practical problems that still remain to be solved.",
	author = "Sondhi, M.",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "3",
	pages = "268--273",
	title = "{Estimation of vocal-tract areas: The need for acoustical measurements}",
	volume = "27",
	year = "1979"
}

@article{Wakita1979,
	author = "Wakita, H.",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	title = "{Estimation of vocal-tract shapes from acoustical analysis of the speech wave: The state of the art}",
	year = "1979"
}

@phdthesis{Matignon1994,
	abstract = "Le but de ce travail est l'{\'e}tablissement de proc{\'e}dures syst{\'e}matiques d'{\'e}criture explicite de mod{\`e}les physiques de r{\'e}sonateurs d'instruments {\`a} vent en vue d'une synth{\`e}se sonore de qualit{\'e}. La repr{\'e}sentation en variables d'{\'e}tat (VE) est choisie car, s'implantant facilement et permettant une estimation param{\'e}trique a posteriori, elle allie les avantages des mod{\`e}les de signaux et des mod{\`e}les physiques. Nous d{\'e}veloppons une {\'e}criture modulaire des syst{\`e}mes de propagation d'ondes interconnect{\'e}s, et une proc{\'e}dure de construction r{\'e}currente de la repr{\'e}sentation en VE de r{\'e}seaux de syst{\`e}mes {\'e}l{\'e}mentaires. Cette {\'e}criture prend en compte les pertes viscothermiques au cours de la propagation des ondes dans l'air. Cette hypoth{\`e}se acoustique est mod{\'e}lis{\'e}e par une Equation aux D{\'e}riv{\'e}es Partielles Fractionnaire (EDPF), ce qui nous conduit {\`a} envisager deux aspects th{\'e}oriques int{\'e}
ressants: les treillis {\`a} plusieurs variables, et la d{\'e}rivation fractionnaire. En premier lieu, nous montrons l'{\'e}quivalence entre les lignes de transmission avec pertes et des filtres en treillis g{\'e}n{\'e}ralis{\'e}s, constitu{\'e}s d'unit{\'e}s de retard et de filtrage: leur description par des polyn{\{\{\{\{\^o}}}}}mes {\`a} plusieurs variables ind{\'e}pendantes permet de donner une condition suffisante de stabilit{\'e}. En second lieu, nous approfondissons la th{\'e}orie de la d{\'e}rivation fractionnaire. Nous donnons une d{\'e}finition au sens des distributions causales, et proposons une autre d{\'e}finition adapt{\'e}e {\`a} des fonctions continues d{\'e}veloppables en s{\'e}rie fractionnaire (DSF), ce qui introduit naturellement des coefficients dans le d{\'e}veloppement. La caract{\'e}risation des fonctions propres de ces deux op{\'e}rateurs de d{\'e}rivation permet de r{\'e}soudre toute Equation Diff{\'e}rentielle Fractionnaire (EDF) par des moyens alg{\'e}briques ; d'un point de vue 
analytique, nous interpr{\'e}tons les conditions initiales non-enti{\`e}res par les premiers coefficients du DSF, et donnons le comportement asymptotique des solutions par la position des p{\{\{\{\{\^o}}}}}les fractionnaires dans un domaine spectral fractionnaire. Enfin, pour une EDPF, nous proposons une extension {\`a} la dimension infinie: l'ensemble des p{\{\{\{\{\^o}}}}}les fractionnaires est alors d{\'e}nombrable ; ceci constitue une analyse modale d'ordre fractionnaire",
	author = "Matignon, D.",
	lockkey = "Y",
	school = "Parix XI Orsay",
	title = "{Repr{\'e}sentations en variables d'{\'e}tat de mod{\`e}les de guides d'ondes avec d{\'e}rivation fractionnaire}",
	year = "1994"
}

@inproceedings{Laine1982,
	author = "Laine, U. K.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{Modelling of lip radiation impedance in Z-domain}",
	year = "1982"
}

@article{Rodet1997a,
	author = "Rodet, Xavier",
	journal = "Applied Signal Processing",
	lockkey = "Y",
	pages = "131--141",
	title = "{Sinusoidal+Residual Models for Musical Sound Signals Analysis/Synthesis}",
	volume = "4",
	year = "1997"
}

@article{McAulay1986,
	abstract = "A sinusoidal model for the speech waveform is used to develop a new analysis/synthesis technique that is characterized by the amplitudes, frequencies, and phases of the component sine waves. These parameters are estimated from the short-time Fourier transform using a simple peak-picking algorithm. Rapid changes in the highly resolved spectral components are tracked using the concept of ``birth'' and ``death'' of the underlying sine waves. For a given frequency track a cubic function is used to unwrap and interpolate the phase such that the phase track is maximally smooth. This phase function is applied to a sine-wave generator, which is amplitude modulated and added to the other sine waves to give the final speech output. The resulting synthetic waveform preserves the general waveform shape and is essentially perceptually indistinguishable from the original speech. Furthermore, in the presence of noise the perceptual characteristics of the speech as well as the noise are maintained. In addition, 
it was found that the representation was sufficiently general that high-quality reproduction was obtained for a larger class of inputs including: two overlapping, superposed speech waveforms; music waveforms; speech in musical backgrounds; and certain marine biologic sounds. Finally, the analysis/synthesis system forms the basis for new approaches to the problems of speech transformations including time-scale and pitch-scale modification, and midrate speech coding [8], [9].",
	author = "McAulay, R. and Quatieri, T.",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "4",
	pages = "744--754",
	title = "{Speech analysis/Synthesis based on a sinusoidal representation}",
	volume = "34",
	year = "1986"
}

@inproceedings{Chebira2010,
	abstract = "Besides basis expansions, frames representations play a key role in signal processing. We thus consider the problem of frame domain signal processing, which is more complex and challenging than trans- form domain processing. Examples of such processing abound, from overlap-add/save convolution, to frequency domain LMS, and frame magnitude reconstruction. We develop a uniÃ¯Â¬Âed view of all these sit- uations by using a common Hilbert space view of the problem, and consider algorithms in this common framework. In addition to a syn- thetic view of multiple signal processing methods in frames, we de- rive several original results. This include a direct solution to spectral modiÃ¯Â¬Âcation (which usually uses an iterative algorithm) and a unicity condition for reconstruction from frame coefÃ¯Â¬Âcient magnitudes.",
	author = "Chebira, Amina and Fickus, Matthew and Vetterli, Martin",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{FRAME DOMAIN SIGNAL PROCESSING: FRAMEWORK AND APPLICATIONS}",
	year = "2010"
}

@inproceedings{Arakawa2010,
	abstract = "This paper describes a high-quality manipulation method of voice quality base on the vocal tract area function (VTAF) obtained from sub-band LSP of STRAIGHT spectrum. Our research group had de- veloped the manipulation technique of voice quality based on VTAF that can generate natural formant transition. However, it is observed that the generated sound sometimes results in degradation when the input signal has a high sampling frequency. Therefore, we develop a new method that extracts VTAF properly from such input signal. This method Ã¯Â¬Ârstly divides the input spectral envelope represented by STRAIGHT spectrum into lower and higher frequency bands, secondly extracts the Line spectrum pair (LSP) in each frequency band after spectral Ã¯Â¬Âattening that is appropriate for the frequency band, thirdly concatenates a pair of the sub-band LSP, and Ã¯Â¬Ânally obtains VTAF from PARCOR coefÃ¯Â¬Âcients converted from the con- catenated LSP. A subjective experiment proved that the proposed method is 
high quality enough.",
	author = "Arakawa, A. and Uchimura, Y. and Banno, H. and Itakura, F. and Kawahara, H.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{HIGH QUALITY VOICE MANIPULATION METHOD BASED ON THE VOCAL TRACT AREA FUNCTION OBTAINED FROM SUB-BAND LSP OF STRAIGHT SPECTRUM}",
	year = "2010"
}

@inproceedings{Berezina2010,
	abstract = "It is well known that the classical linear predictive model for speech fails to take into account the quasi-periodic nature of the glottal Ã¯Â¬Âow typical of voiced speech. In this article we describe how to incorpo- rate an estimate of the glottal Ã¯Â¬Âow directly into the traditional linear prediction framework, through the use of Ã¯Â¬Âexible basis function ex- pansions that admit efÃ¯Â¬Âcient estimation procedures. As we show, this not only allows for improved estimation of vocal tract transfer func- tion parameters in a manner that is robust to pitch variation, but also precludes the need for nonlinear optimization procedures typically required in glottal waveform estimation. We illustrate our approach with experiments using synthesized and real speech waveforms, and show how it may be used to directly estimate the relative degree of voicing and aspiration present in a given utterance.",
	author = "Berezina, M. A. and Rudoy, D. and Wolfe, P. J.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	pages = "5042--5045",
	title = "{Autoregressive modeling of voiced speech}",
	year = "2010"
}

@inproceedings{Pedersen2010,
	abstract = "In recent studies, a non-parametric speech waveform representation (rep.) based on zeros of the z-transform (ZZT) has been proposed. The ZZT rep. has successfully been applied in separating mixed phase signals, e.g. pitch-synchronously windowed speech, into min/max phase by using the unit circle as discriminant. As the ZZT rep. is obtained by factorization of the z-transform, relations to the complex cepstrum (CC) exist. The present paper interrelates the ZZT rep. with the CC via factorization of the z-transform, and demonstrates that unit circle discrimination of a ZZT rep. can be formulated as a CC based separation by causality. A numerical experiment supplements theory by separating a range of LF glottal flow waveforms into their opening and closing phase constituents. Further, randomized mixed phase sequences are separated. As the CC based separation also can be obtained via FFT it has a lower time and space complexity than the ZZT based counterpart.",
	author = "Pedersen, C.F. and Andersen, O. and Dalsgaard, P.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2010.5495060",
	issn = "1520-6149",
	keywords = "FFT; LF glottal flow waveforms; causality; complex cepstrum based separation; mixed phase signal sequence separation; nonparametric speech waveform representation; phase constituents; pitch-synchronously windowed speech; space complexity; time complexity; unit circle; z-transform factorization; Z transforms; fast Fourier transforms; sequences; source separation; speech processing",
	lockkey = "Y",
	pages = "5050--5053",
	title = "{Separation of mixed phase signals by zeros of the z-transform - {A} reformulation of complex cepstrum based separation by causality}",
	year = "2010"
}

@inproceedings{Pawi2010,
	abstract = "This paper proposes a set of higher-order modified moments as alternative objective criteria for pitch extraction and explores the impact of the speech window length on pitch estimation error. To obtain the Kth order modified moment, each speech frame is split into a positive-valued signal and a negative-valued signal. The magnitudes of the Kth order moments for the positive and the negative valued signals are obtained and combined. The proposed objective criteria form a relatively sharp peak around the true pitch value compared to the correlation function. For calculation of errors, pitch reference ({\lq}ground truth{\rq}) values are calculated from manually-corrected estimates of the periods obtained from laryngograph signals. The results obtained for the third order modified moment are compared with the results for correlation and magnitude difference criteria and the YIN method. The modified moments provide improved pitch accuracy with less occurrence of large errors (e.g. half or double 
pitch estimation errors).",
	author = "Pawi, A. and Vaseghi, S. and Milner, B.",
	booktitle = "{ICASSP}",
	keywords = "f0 fundamental frequency",
	lockkey = "Y",
	title = "{PITCH EXTRACTION USING MODIFIED HIGHER ORDER MOMENTS}",
	year = "2010"
}

@inproceedings{Shue2010,
	abstract = "There are numerous models of varying complexities which seek to efficiently represent the voice source signal. These models are typically based on data and observations which can come from air-flow masks, electroglottographs, mechanical systems, and the inverse-filtering of speech signals. The first part of this study examines observations from the high-speed imaging of the larynx and proposes a new source model, which is shown to provide a better fit for the observed data than existing models. The proposed source model is then used in an automatic source estimation application, based on methods introduced in an earlier study [1]. Results, on average, show that the proposed model provides a more accurate estimation of the source signal compared with the Liljencrants-Fant model.",
	author = "Shue, Yen-Liang and Alwan, A.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2010.5495030",
	issn = "1520-6149",
	keywords = "automatic source estimation application; larynx high speed imaging; voice source estimation; voice source model; voice source signal representation; acoustic signal processing; bioacoustics; speech; speech processing",
	lockkey = "Y",
	pages = "5134--5137",
	title = "{A new voice source model based on high-speed imaging and its application to voice source estimation}",
	year = "2010"
}

@article{Bouabana1998,
	abstract = "The frame-by-frame variation of tongue proÃÂ®les derived from X-ray ÃÂ®lm data is described in terms of the temporal patterns of four articulatory parameters. The temporal variation of each parameter, i.e., movement, is assumed to be the output of a time-invariant auto-regressive ÃÂ®lter. Each ÃÂ®lter is excited by a sequence of pulses, representing articu- latory commands. The ÃÂ®lter coeÃÂcients, and the position and amplitude of the pulses are determined by applying an MLPC method. The curve of synthesis error for each movement shows a rapid decrease up to a number of pulses cor- responding to that of the syllables in the sentence and then the decreasing rate becomes distinctively slower suggesting the presence of syllable-size motor organization. The minimum number of pulses is determined by using an acoustic criterion. It depends on the number of the phonetic features, in the sentence, of which their realization is crucially re- lated to their pertinent parameters. {\'O} 1998 
Elsevier Science B.V. All rights reserved.",
	author = "Bouabana, S. and Maeda, S.",
	journal = "Speech Communication",
	lockkey = "Y",
	pages = "227--248",
	title = "{Multi-pulse LPC modeling of articulatory movements}",
	volume = "24",
	year = "1998"
}

@inproceedings{Regnier2010,
	abstract = "We propose a new method to group partials produced by each in- strument of a polyphonic audio mixture. This method works for pitched and harmonic instrument and is specially adapted to singing voice. In our approach we model time-varying frequencies of par- tial as a slowly varying frequency plus a sinusoidal modulation. The parameters obtained with this model plus some common Auditory Scene Analysis type cues are used to deÃ¯Â¬Âne a similarity measure be- tween partials. This multi-criterion based measure is then used to built the input similarity matrix of a clustering algorithm. Clusters obtained are group of harmonically related partials. The ability of parameters/similarity measure/clustering to group partial into source is evaluated when one of the source is singing voice. We show that partial clustering is a promising approach for singing voice detection and separation.",
	author = "Regnier, L. and Peeters, G.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{PARTIAL CLUSTERING USING A TIME-VARYING FREQUENCY MODEL FOR SINGING VOICE DETECTION}",
	year = "2010"
}

@inproceedings{Yegnanarayana2010,
	abstract = "Instantaneous fundamental frequency (F0 ) in voiced speech can be obtained from the sequence of epochs correspond- ing to the instants of signiÃ¯Â¬Âcant excitation. The epoch sequence can be derived using the recently proposed epoch extraction method based on zero frequency Ã¯Â¬Âltering. The epoch extraction method is robust against additive noise degradation. But in a multispeaker mixed signal, the degradation is caused due to overlapping impulse-like excitations of two or more speakers. The feasibility of extracting the instantaneous F0 contours from the two speaker mixed signal using zero frequency Ã¯Â¬Âltering is studied in this paper. The present study is based on deriving speaker- speciÃ¯Â¬Âc Hilbert Envelope (HE) signal which emphasizes peaks due to impulse-like excitation of one speaker and suppresses peaks due to other speaker. The epochs from this speaker-speciÃ¯Â¬Âc signal are obtained using the approach based on zero frequency Ã¯Â¬Âltering. The results of the proposed method is 
demonstrated for three different cases of mixed signals of two speakers data.",
	author = "Yegnanarayana, B. and Prasanna, S. R. Mahadeva",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{Analysis of instantaneous F0 contours from two speakers mixed signal using zero frequency Ã¯Â¬Âltering}",
	year = "2010"
}

@inproceedings{Zhou2010,
	abstract = "The production of the lateral sounds generally involves a linguo-alveolar contact and one or two lateral channels along the parasagittal sides of the tongue. The acoustic effect of these articulatory features is not clearly understood. In this study, we compare two productions of /l/ in American English by one subject, one for a dark /l/ and the other for a light /l/. Three- dimensional vocal tract models derived from the magnetic resonance images were analyzed. It was shown that zeros in the vocal tract acoustic response are produced in the F3-F5 region in both /l/ productions, but the number of zeros and their frequencies are affected by the length of the linguo-alveolar contact and by the presence or absence of lateral linguopalatal contacts. The dark /l/ has one zero below 5 kHz, produced by the cross mode posterior to the linguo-alveolar contact, while the light /l/ has three zeros below 5 kHz, produced by the asymmetrical lateral channels, the supralingual cavity and the cross mode 
posterior to linguo-alveolar contact.",
	author = "Zhou, X. and Espy-Wilson, C. Y. and Tiede, M. and Boyce, S.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{AN MRI-BASED ARTICULATORY AND ACOUSTIC STUDY OF LATERAL SOUND IN AMERICAN ENGLISH}",
	year = "2010"
}

@phdthesis{Mullen2006,
	abstract = "Acoustical physical modelling synthesis uses mathematical algorithms to describe a real-world sound production process or propagational environ- ment. Digital waveguides can be used to form a 1D model of the vocal tract, simplistically represented as a series of cylindrical tubes of varying radius along a straight axis. This 1D signal propagating element can also be extended to create a digital waveguide mesh (DWM), giving acoustical synthesis of a higher dimensional structure, such as a 2D surface or 3D space. The work contained in this thesis is an investigation into the effects of increased dimensionality in the 1D waveguide vocal tract paradigm. A 2D DWM is conÃ¯Â¬Âgured as a model of the tract, such that shape characteristics are set within the width of the mesh. Wave propagation and reÃ¯Â¬Âection is simulated along the tract from the glottis to the lips, as well as across it, between the two inner walls, thereby removing plane-wave limitations inherent in the 1D model. The 2D tract is 
found to give accurate formant synthesis, producing vowels that give a good match to real-world targets. However, problems associated with high sampling frequency limitations and discontinuous dynamic operation are identiÃ¯Â¬Âed. Movements readily occurring in speech, such as diphthongs, are not easily accommodated by the static mesh structure. A novel alternative approach is also presented which maintains a rect- angular mesh, but maps the changing tract shapes onto the waveguide impedances. This allows for stable dynamic manipulation of the modelled space. Furthermore, sampling frequency limitations are removed, such that real-time operation and interaction with the 2D tract model is achieved.",
	author = "Mullen, Jack",
	lockkey = "Y",
	school = "University of York",
	title = "{Physical Modelling of the Vocal Tract with the 2D Digital Waveguide Mesh}",
	year = "2006"
}

@mastersthesis{Sainath2005,
	author = "Sainath, Tara N.",
	lockkey = "Y",
	school = "MIT",
	title = "{Acoustic Landmark Detection and Segmentation using the McAulay-Quatieri Sinusoidal Model}",
	year = "2005"
}

@article{Akande2005,
	abstract = "A new method for determining the vocal tract transfer function for voiced speech is proposed. The method exploits the frequency domain characteristics of voiced speech and the concepts of minimum-phase systems. The short-time spectrum of voiced speech contains information about the glottal source and vocal tract filter components. In voiced speech there is usually a small frequency gap between the glottal source peak frequency response and the first formant of the vocal tract. The inherent inability of linear prediction parametric modelling in discriminating between closely spaced frequency components can make accurate modelling/estimation of the first formant (in the presence of a close and elevated peak due to the glottal flow) in voiced speech very difficult. A fixed pre-emphasis (single-pole, high-pass filter), commonly used in existing inverse filtering methods to reduce the influence of the glottal source, is not guaranteed to give the desired result across a range of voice types e.g. 
breathy, pressed and modal. The proposed method overcomes this problem by suppressing the glottal wave contribution using a dynamic, multi-pole, zero-phase lag high-pass filter, prior to analysis. In addition to minimising the influence of the glottal source, an expanded analysis region is provided in the form of a pseudo-closed phase. The technique also takes into cognizance the time varying nature of the vocal tract filter by determining, adaptively, an optimum vocal tract filter function using the properties of minimum phase systems. The performance of the new method is evaluated using synthesized and real speech. The results show that, under certain conditions, the method estimates the vocal tract formants and bandwidths more accurately than an existing closed phase inverse filtering technique.",
	author = "Akande, O. O. and Murphy, P. J.",
	journal = "Speech Communication",
	keywords = "Formant estimation; Glottal volume velocity; Inverse filtering",
	lockkey = "Y",
	number = "1",
	pages = "15--36",
	title = "{Estimation of the vocal tract transfer function with application to glottal wave analysis}",
	volume = "46",
	year = "2005"
}

@phdthesis{Deng2005,
	address = "Canada",
	author = "Deng, Hui Qun",
	lockkey = "Y",
	school = "University of British Columbia",
	title = "{Estimations of glottal waves and vocalt-tract area functions from speech signals}",
	year = "2005"
}

@inproceedings{MehtaD2005,
	abstract = "Breathiness is an aspect of voice quality that is difficult to analyze and synthesize, especially since its periodic and noise components are typically overlapping in frequency. The decomposition and manipulation of these two components is of importance in a variety of speech application areas such as text- to-speech synthesis, speech encoding, and clinical assessment of disordered voices. This paper first investigates the perceptual relevance of a speech production model that assumes the speech noise component is modulated by the glottal airflow waveform. After verifying the importance of noise modulation in breathy vowels, we use the modulation model to address the particular problem of pitch modification of this signal class. Using a decomposition method referred to as pitch-scaled harmonic filtering to extract the additive noise component, we introduce a pitch modification algorithm that explicitly modifies the modulation characteristic of this noise component. The approach applies envelope 
shaping to the noise source that is derived from the inverse-filtered noise component. Modification examples using synthetic and real breathy vowels indicate promising performance with spectrally-overlapping periodic and noise components.",
	author = "Mehta, D. and Quatieri, T. F.",
	booktitle = "{Proc. IEEE Work. on App. of Sig. Proc. to Audio and Acoustics (WASPAA)}",
	lockkey = "Y",
	pages = "199--202",
	title = "{Synthesis, analysis, and pitch modification of the breathy vowel}",
	year = "2005"
}

@phdthesis{Ljunqvist1986,
	address = "Japan",
	author = "Ljungvist, Mats Gunner",
	lockkey = "Y",
	school = "University of Tokyo",
	title = "{Speech Analysis-Synthesis based on modeling of voice source and vocal-tract characteristics}",
	year = "1986"
}

@inproceedings{Henrich1999,
	author = "Henrich, N. and Doval, B. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro",
	booktitle = "{Proc. Workshop on Models and Analysis of Vocal Emissions for Biomedical Applications}",
	lockkey = "Y",
	pages = "12--17",
	title = "{Glottal open quotient estimation using linear prediction}",
	year = "1999"
}

@inproceedings{Alku2005,
	abstract = "The estimation of glottal flow with inverse filtering requires typically subjective evaluation of the obtained flow waveforms by the experimenter. In this paper, we propose a straightforward method that yields an objective analysis tool to be used in the assessment of the quality of inverse filtered glottal flow estimates. The method computes the negative derivative of the phase response, the group delay function, over a single glottal cycle of the estimated flow. Incorrect settings of the anti-resonances of the inverse filter result in distortion of the group delay function. This distortion is easily detectable from the group delay function and can therefore be used in a straightforward manner to analyse how well the zeros of the inverse filter match the poles of the vocal tract.",
	author = "Alku, P. and Airas, M. and Backstrom, T. and Pulakka, H.",
	booktitle = "{Proc. Interspeech}",
	lockkey = "Y",
	pages = "1053--1056",
	title = "{Group Delay Function as a Means to Assess Quality of Glottal Inverse Filtering}",
	year = "2005"
}

@article{Stevens1960,
	abstract = "An approach to the design of a machine for the recognition and synthesis of speech is proposed, with particular emphasis on problems of acoustical analysis. As a recognizer, the proposed machine accepts a speech wave at its input and generates a sequence of phonetic symbols at its output; as a synthesizer it accepts a sequence of symbols at its input and generates speech wave. Coupling between the acoustical speech signal and the machine is achieved through two peripheral units: one an analog filter set or equivalent, and the other a model of the vocal tract. Between the analog filters and the phonetic output the signal undergoes an intermediate form of representation that is related to vocal-tract configurations and excitations but is not necessarily described specifically in these terms. Each stage of analysis is performed by synthesis of a number of alternative signals or patterns according to rules stored within the machine and by comparison of the synthesized patterns with the input signals 
that are under analysis. Possible advantages of the proposed method of analysis are discussed. An experimental study based on the general analysis approach is described in an Appendix. In this study a method for the determination of the frequencies of vocal-tract resonances from the speech wave is simulated on a digital computer.",
	author = "Stevens, Kenneth N.",
	doi = "10.1121/1.1907874",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "1",
	pages = "47--55",
	publisher = "ASA",
	title = "{Toward a Model for Speech Recognition}",
	url = "http://link.aip.org/link/?JAS/32/47/1",
	volume = "32",
	year = "1960"
}

@article{Bell1961,
	abstract = "Procedures described reducing speech to a specification are for the wave in terms thetime-varying of vocal-tractresonances source and characteristics. basic The method, which been has called analysisby synthesis,involves comparisonspeech the of spectra a series spectra aresynthesized with of that within the analyzer.Each comparison spectrum generated is according a set of rulesbased an acoustical to on theory speech of production. result theanalysis each The of of inputspectrum a setof parameters is that describes synthesized the spectrum providing best the match. oneversion themethod In of convergence, towards bestmatchis controlled the experimenter; another the by in versionconvergence a matchis ac- to complished automaticallywithout the intervention the experimenter. the operations of All have been programmed a general-purpose on digitalcomputer and have beenappliedto the analysis vowels of and someconsonants. The advantages the aualysistechniques discussed. of are",
	author = "Bell, C. G. and Fujisaki, H. and Heinz, J. M. and Stevens, K. N. and House, A. S.",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "12",
	pages = "1725--1736",
	title = "{Reduction of speech spectra by Anaylis-by-Synthesis techniques}",
	volume = "33",
	year = "1961"
}

@article{Mathews1961,
	abstract = "A study of vowel soundsby meansof a spectralanalysiskeyed sequence zeros characterlng the izglottat excitation. The fre- of synchronously the voicepitch has beencarriedout. Spectraare to quencies the vocal tract polesagreedwith previousmeasure- of obtainedby Fourier analysisof individual pitch periodswhich ments, but the dampingfactorswere not entirely consistent with were establishedby visual inspection of oscillograms. digital A earlier estimates.The zerosshowedapproximatelyuniform fre- computer servedas the analyzer.The spectraare represented a by quencyspacing,particularly at high frequencies. theoretical A pattern of zeros and poles obtained by a processof successive development indicated that this characteristic to be expected was approximation, againcarriedout by computer.The contributions from the known structure of the glottal excitation. The zero from vocaltract and glottal source can be uniquelyseparated and pattern was usedto estimatethe ratio of open-to-closed time for examined. 
These resultsshow that vowel sounds can be repre- the glottis during voicing. sentedby a sequence polesarisingfrom the vocal tract and a of",
	author = "Mathews, M. V. and Miller, Joan E. and {E. E. David}, Jr.",
	doi = "10.1121/1.1908614",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "2",
	pages = "179--186",
	publisher = "ASA",
	title = "{Pitch Synchronous Analysis of Voiced Sounds}",
	url = "http://link.aip.org/link/?JAS/33/179/1",
	volume = "33",
	year = "1961"
}

@inproceedings{Itakura1968,
	author = "Itakura, F. and Saito, S.",
	booktitle = "{Int. Cong. Acoustic}",
	lockkey = "Y",
	title = "{Analysis Synthesis Telephony Based Upon the Maximum Likelihood Method}",
	year = "1968"
}

@article{MiyanagaY1986,
	abstract = "We propose an adaptive algorithm to estimate time-varying ARMA parameters for speech signals. It estimates both input excitations and underlying system parameters. The proposed algorithm is an extended form of the Kalman filter algorithm. We assume the input is either a white Gaussian process or a pseudoperiodical pulse-train as commonly adopted in LPC processing. The time variation of parameters is monitored by a likelihood function. In order to estimate optimal parameters in a small amount of data, AR and MA orders of an estimator are set to be higher than those of a true system. Parsimonious ARMA parameters are calculated from parameters obtained by the high-order ARMA model. Examples of synthetic and real speech sounds are given to demonstrate the tracking ability of this algorithm.",
	author = "Miyanaga, Y. and Miki, N. and Nagai, N.",
	doi = "10.1109/TASSP.1986.1164831",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "3",
	pages = "423--433",
	title = "{Adaptive identification of a time-varying {ARMA} speech model}",
	volume = "34",
	year = "1986"
}

@article{Funaki1999,
	abstract = "A sophisticated new speech analysis method based on a Glottal-ARMAX (Auto Regressive and Moving Average eXogenous) model with phase compensation is proposed in this paper. A Glottal-ARMAX model consists of two kinds of inputs, i.e., glottal source model excitation and a white Gaussian input, and a vocal tract ARMAX model. The proposed method can estimate the phase-compensated excitation of a glottal source model and vocal tract parameters simulta- neously with pitch synchronous. In the method, ARMAX identiÃ¯Â¬Âcation using a modiÃ¯Â¬Âed MIS (Model IdentiÃ¯Â¬Âcation System) method is adopted to estimate ARMAX parameters, and the hybrid approach of genetic algorithm (GA) and simulated annealing (SA) is employed to solve eÃ¯Â¬Âciently the non-linear simultaneous optimization between glottal sources and the parameters of vocal tract ARMAX model. Furthermore, in order to compensate phase distortion, phase compensation using an all-pass Ã¯Â¬Âlter is introduced within a generation loop in the GA 
method. Experiments using the Glottal-ARMAX synthetic speech and natural speech uttered by a male speaker demonstrate the eÃ¯Â¬Âciency of the proposed method.",
	author = "Funaki, K. and Miyanaga, Y. and Tochinai, K.",
	journal = "Elsevier Signal Processing",
	lockkey = "Y",
	pages = "279--295",
	title = "{Recursive {ARMAX} speech analysis based on a glottal source model with phase compensation}",
	volume = "74",
	year = "1999"
}

@inproceedings{Fant2005,
	abstract = "This is a report summarising results from studies of true subglottal pressure, supraglottal pressure and speech wave data. We have derived co-variation patterns, which allow a prediction of intensity from subglottal pressure and F0, and conversely a prediction of a subglottal pressure contour from F0 and intensity. Of special interest is the significance of a mid-point in a speakers{\rq} available F0 range at which the relations change. In the lower F0 range subglottal pressure and intensity rise with F0, whilst in the upper part they tend to saturate. In connected speech we find a build-up of subglottal pressure well in advance of a stressed word, and a decay of subglottal pressure in the final part of a phrase starting already in the falling branch of an F0 peak.",
	author = "Fant, G. and Kruckenberg, A.",
	booktitle = "{Interspeech}",
	lockkey = "Y",
	title = "{Covariation of subglottal pressure, F0 and intensity}",
	year = "2005"
}

@article{Kanai1987,
	abstract = "This paper describes a new method of accurately estimat- ing the parametersof an autoregressive (AR) process contaminated by high-level white noise. Based on the phase matching technique, it min- imizes the difference between the phase of the all-zero model and the phase of the maximum phase signal reconstructed from the power spectrum of the observed signal. The parametersof the AR model are obtained from the finite length sequence estimated all-zero modeof the The proposed method works only when the order of the A R model is known a priori at present. However, since the phase matching tech- nique satisfies the conditions needed to apply the least mean-square low method, the AR parameters are estimated accurately even at a signal-to-noise ratio. With the iterativeor noniterative methods as dis- cussed in the recent literature, it is not possible to reconstruct the azero model from the power spectrum when there are dips and peaks of having no correlation with the poles original AR signal in the 
power spectrum. The method proposed in this paper allows one to accuratereconstruct the phase from the power spectrum in such cases. Finallyit is confirmed with computer simulations and experiments that the proposed method is useful for accurate estimation of the AR parameters.",
	author = "Kanai, H. and Abe, M. and Kido, K.",
	journal = "IEEE Trans. on Acoustics, Speech, and Signal Processing",
	lockkey = "Y",
	pages = "1264--1272",
	title = "{Accurate Autoregressive Spectrum Estimation at Low Signal-to-Noise Ratio Using a Phase Matching Technique}",
	year = "1987"
}

@article{Gardner1997,
	abstract = "This paper introduces noncausal all-pole models that are capable of efÃ¯Â¬Âciently capturing both the magnitude and phase information of voiced speech. It is shown that noncausal all-pole Ã¯Â¬Âlter models are better able to match both magnitude and phase information and are particularly appropriate for voiced speech due to the nature of the glottal excitation. By modeling speech in the frequency domain, the standard difÃ¯Â¬Âculties that occur when using noncausal all-pole Ã¯Â¬Âlters are avoided. Several algorithms for determining the model parameters based on frequency-domain information and the masking effects of the ear are described. Our work suggests that high-quality voiced speech can be produced using a 14th-order noncausal all-pole model.",
	author = "Gardner, W. R. and Rao, B. D.",
	journal = "IEEE Trans. on Acoustics, Speech. and Signal Processing",
	lockkey = "Y",
	title = "{Noncausal All-Pole Modeling of Voiced Speech}",
	year = "1997"
}

@inproceedings{Gudnason2009,
	abstract = "The paper presents a voice source waveform modeling techniques based on principal component analysis (PCA) and Gaussian mixture modeling (GMM). The voice source is obtained by inverse-filteirng speech with the estimated vocal tract filter. This decomposition is useful in speech analysis, synthesis, recognition and coding. Existing models of the voice source signal are based on function-fitting or physically motivated assumptions and although they are well defined, estimation of their parameters is not well understood and few are capable of reproducing the large variety of voice source waveforms. Here, a data-driven approach is presented for signal decomposition and classification based on the principal components of the voice source. The principal components are analyzed and the {\lq}prototype{\rq} voice source signals corresponding to the Gaussian mixture means are examined. We show how an unknown signal can be decomposed into its components and/or prototypes and resynthesized. We show how the 
techniques are suited for both low bitrate or high quality analysis/synthesis schemes.",
	author = "Gudnason, J. and Thomas, M. R. P. and Naylor, P. A. and Ellis, D. P. W.",
	booktitle = "{Interspeech}",
	keywords = "Voice source; inverse-filtering; closed-phase analysis; PCA; GMM",
	lockkey = "Y",
	title = "{Voice Source Waveform Analysis and Synthesis using Principal Component Analysis and Gaussian Mixture Modelling}",
	year = "2009"
}

@techreport{FlanaganJL1966,
	author = "Flanagan, J. L. and Golden, R. M.",
	institution = "The Bell System Technical Journal",
	lockkey = "Y",
	title = "{Phase Vocoder}",
	year = "1966"
}

@inproceedings{Valbret1992,
	abstract = "Whereas speaker adaptation has received much attention for speech recognition few studies have been devoted to voice transformation for speech synthesis, despite the potential interests of such techniques. The authors propose a voice conversion system which combines the time-domain pitch synchronous overlap and add (TD-PSOLA) technique with a source-filter decomposition. The first technique allows prosodic modifications while the second enables spectral envelope transformations. Two approaches to learn spectral alteration are compared: the linear multivariate regression (LMR) and the dynamic frequency warping (DFW).",
	author = "Valbret, H. and Moulines, E. and Tubach, J.P.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1992.225951",
	isbn = "0-7803-0532-9",
	lockkey = "Y",
	pages = "145--148",
	title = "{Voice transformation using {PSOLA} technique}",
	year = "1992"
}

@article{PantazisY2010iqhm,
	abstract = "While the problem of estimating the amplitudes of sinusoidal components in signals, given an estimation of their frequencies, is linear and tractable, it is biased due to the unavoidable, in practice, errors in the estimation of frequencies. These errors are of great concern for processing signals with many sinusoidal like components as is the case of speech and audio. In this letter, we suggest using a time-varying sinusoidal representation which is able to iteratively correct frequency estimation errors. Then the corresponding amplitudes are computed through Least Squares. Experiments conducted on synthetic and speech signals show the suggested model's effectiveness in correcting frequency estimation errors and robustness in additive noise conditions.",
	author = "Pantazis, Y. and Rosec, O. and Stylianou, Y.",
	doi = "10.1109/LSP.2010.2043153",
	issn = "1070-9908",
	journal = "IEEE Signal Processing Letters",
	keywords = "additive noise; amplitude estimation; frequency estimation; frequency estimation error; least squares; least squares approximations; signal representation; sinusoidal signal parameter estimation; speech signal; synthetic signal; time-varying sinusoidal representation",
	lockkey = "Y",
	month = "may",
	number = "5",
	pages = "461--464",
	title = "{Iterative Estimation of Sinusoidal Signal Parameters}",
	volume = "17",
	year = "2010"
}

@article{Milenkovic1986,
	abstract = "Glottal inverse filtering is a technique by which the flow past the time varying glottal constriction is estimated by a filtering operation on the acoustic signal in human speech. The filtering operation removes the effects of the vocal tract resonances to reveal the underlying voice source signal. A linear model of a glottal pulse waveform is described along with a procedure for jointly determining an AR model of the vocal tract response together with the parameters of the glottal pulse model. This technique is applied to inverse filtering in human speech and the results are compared to covariance method LPC analysis.",
	author = "Milenkovic, P.",
	doi = "10.1109/TASSP.1986.1164778",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "1",
	pages = "28--42",
	title = "{Glottal inverse filtering by joint estimation of an AR system with a linear input model}",
	volume = "34",
	year = "1986"
}

@article{Konvalinka1979,
	abstract = "A new algorithm is proposed for the simultaneous estimation of poles and zeros in speech analysis. The algorithm is based on estimating the unknown system input and improvement of this estimate through the iterations. Thus, the algorithm does not require any type of preliminary deconvolution of the speech waveform, such as synchronization with pitch period or homomorphic deconvolution. Detailed analysis of a simulated system, as well as a preliminary analysis of initial nasal consonants /m/ and /n/, are presented. These analyses have shown that the ITIF algorithm gives a very accurate fit of the spectra of the systems analyzed. The iterative inverse filtering algorithm (ITIF) is a new technique for modeling linear systems having unknown input with a flat spectral envelope, such as pulse train or white noise input, by applying the pole-zero model. The ITIF algorithm in each iteration solves two linear parameter estimation problems: in the first one the unknown system input is estimated; in the 
second one the estimated input is used to determine the parameters of the pole-zero model. Experiments made so far have shown that the algorithm converges in a small number of iterations.",
	author = "Konvalinka, I. and Matausek, M.",
	doi = "10.1109/TASSP.1979.1163276",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "5",
	pages = "485--492",
	title = "{Simultaneous estimation of poles and zeros in speech analysis and {ITIF}-iterative inverse filtering algorithm}",
	volume = "27",
	year = "1979"
}

@inproceedings{Peeters1998,
	author = "Peeters, G.",
	booktitle = "{Journ{\'e}es d'Informatique Musicale}",
	keywords = "PSOLA",
	lockkey = "Y",
	title = "{Analyse et synth{\`e}se des sons musicaux par la m{\'e}thode PSOLA}",
	year = "1998"
}

@inproceedings{Moore2004,
	abstract = "An automated glottal waveform estimation algorithm is presented that improves on a previous manual glottal extraction technique which produced excellent glottal waveform estimates. The algorithm uses only basic approximations of glottal closure regions and successive iterations to find the best candidate for a glottal waveform estimate within a speech frame. Visual comparisons of the glottal waveform estimates created by the algorithm and those generated from the use of glottal closure information provided by an electroglottograph (EGG) reveal that the algorithm produced virtually identical estimates.",
	author = "Moore, E. and Clements, M.",
	booktitle = "{Acoustics, Speech, and Signal Processing, 2004. Proceedings. (ICASSP '04). IEEE International Conference on}",
	doi = "10.1109/ICASSP.2004.1325932",
	issn = "1520-6149",
	keywords = "automatic glottal waveform estimation; basic approximations; electroglottograph; glottal closure information; speech analysis; speech frame; successive iterations; approximation theory; iterative methods; parameter estimation; speech processing",
	lockkey = "Y",
	month = "may",
	pages = "I--101--4 vol.1",
	title = "{Algorithm for automatic glottal waveform estimation without the reliance on precise glottal closure information}",
	volume = "1",
	year = "2004"
}

@article{Cummings1995,
	abstract = "Glottal modeling has been an important topic of research in digital speech processing for many years. The ability to accurately model the glottal excitation is important for applications as varied as acoustic and articulatory speech synthesis, speech coding, and speech analysis. Many glottal models that differ in form and complexity have been suggested over the years. Possible models range from simple parametric models of the glottal volume velocity or the glottal flow derivative that assume linear separability of the glottal source and the vocal tract to more complex parametric function and mechanical models that allow for interaction between the glottal source and the vocal tract to very complex models that are based directly on the physiological properties of the glottis. This paper will provide a historical survey of glottal models, discussing their form and complexity along with the applications for which each is appropriate. This paper will also present a discussion of the problem of 
modeling the glottal excitation of different styles of speech, a topic that is important for applications such as natural, high-quality speech synthesis. A glottal model that is capable of modeling eleven commonly encountered styles of speech will be presented.",
	author = "Cummings, K. E. and Clements, M. A.",
	doi = "10.1006/dspr.1995.1003",
	issn = "1051-2004",
	journal = "Digital Signal Processing",
	lockkey = "Y",
	number = "1",
	pages = "21--42",
	title = "{Glottal Models for Digital Speech Processing: A Historical Survey and New Results}",
	url = "http://www.sciencedirect.com/science/article/B6WDJ-45S92M3-T/2/ed6b51ea181cbb9ea400b39e8c3edb2b",
	volume = "5",
	year = "1995"
}

@article{Fujimura1965,
	author = "Fujimura, O. and Lindqvist-GaufÃ¯Â¬Ân, J.",
	journal = "STL-QPSR",
	keywords = "VTF",
	lockkey = "Y",
	title = "{Sweep-tone measurements of the vocal tract characteristics}",
	year = "1965"
}

@inproceedings{Jinachitra2005,
	abstract = "In this paper, a joint parameter estimation of the derivative glottal source waveform and the vocal tract filter is presented where aspiration noise and observation noise are taken into account within a state-space model. The Rosenberg-Klatt glottal model is used in conjunction with an all-pole filter to model voice production. The EM algorithm is employed to iteratively estimate the model parameters in a maximum-likelihood sense, utilizing a Kalman smoother in the expectation step. The model and estimator allow for improved estimates of model parameters for resynthesis, yielding an output which sounds natural and remains flexible for modification, a desirable property for expressive vocal synthesis.",
	author = "Jinachitra, P. and Smith, J. O. III",
	booktitle = "{IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}",
	doi = "10.1109/ASPAA.2005.1540235",
	keywords = "all-pole filter; aspiration noise; EM algorithm; expectation-maximisation algorithm; glottal source waveform; joint parameter estimation; Kalman filters; Kalman smoothing; maximum-likelihood sense; observation noise; Rosenberg-Klatt glottal model; smoothing methods; speech synthesis; state-space model; vocal synthesis; vocal tract filter; voice production",
	lockkey = "Y",
	pages = "327--330",
	title = "{Joint estimation of glottal source and vocal tract for vocal synthesis using Kalman smoothing and EM algorithm}",
	year = "2005"
}

@article{Karlsson1996,
	abstract = "The voice source for different voice qualities has been investigated. The glottal signal has been attained using inverse filtering of the speech signal. Two different methods for modelling the results are demonstrated. An acoustic model, the LF voice source model, h s been fitted to the inverse filtered waveform and the LF parameters have been used to describe the voice pulse. The parameters of a vocal cord model, the Liljencrants model, has been manipulated to produce glottal pulses similar to the natural pulses. The parameter settings are discussed.",
	author = "Karlsson, I. and Liljencrants, J.",
	journal = "TMH-QPSR",
	lockkey = "Y",
	number = "2",
	pages = "143--146",
	title = "{Diverse voice qualities: models and data}",
	volume = "37",
	year = "1996"
}

@article{MillerRL1959,
	abstract = "The shape of the vocal cord wave is an important parameter in a true analog representation of the vocal mechanism, since the final speech wave is a function of both the generator wave shape and the transfer impedance of the vocal tract. The shape of this wave has been determined by two independent methods: (1) by the derivation and use of a network having a characteristic which is the inverse of the first vocal resonance, and (2) by measuring the area of the vocal cord opening as a function of time through the use of motion picture studies. Harmonic analysis of some of the typical shapes obtained indicate that a uniform distribution of harmonic amplitudes is a rarity; instead there is a tendency for the distribution to have a cyclical variation of the form (sinkn/kn2). The results obtained through the use of the inverse network indicate that the main excitation of the higher resonances occurs at the point of vocal cord closure and that the magnitude of this excitation can be controlled by the 
talker over wide ranges.",
	author = "Miller, R. L.",
	doi = "10.1121/1.1907771",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "6",
	pages = "667--677",
	publisher = "ASA",
	title = "{Nature of the Vocal Cord Wave}",
	url = "http://link.aip.org/link/?JAS/31/667/1",
	volume = "31",
	year = "1959"
}

@article{Flanagan1957,
	abstract = "The synthesis of vowel sounds by lumped-constant electrical networks having transfer functions similar to the transmission properties of the vocal tract is considered. A comparison is made between cascade and parallel connections of simple electrical resonators for producing vowel sounds. The cascade arrangement of resonators is shown to yield vowel sounds having formants of proper amplitude when information specifying the formant frequencies only is known.",
	author = "Flanagan, J. L.",
	doi = "10.1121/1.1908864",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "2",
	pages = "306--310",
	publisher = "ASA",
	title = "{Note on the Design of ``Terminal-Analog'' Speech Synthesizers}",
	url = "http://link.aip.org/link/?JAS/29/306/1",
	volume = "29",
	year = "1957"
}

@article{Weibel1955,
	author = "Weibel, E. S.",
	doi = "10.1121/1.1908056",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "5",
	pages = "858--865",
	publisher = "ASA",
	title = "{Vowel Synthesis by Means of Resonant Circuits}",
	url = "http://link.aip.org/link/?JAS/27/858/1",
	volume = "27",
	year = "1955"
}

@article{Dunn1950,
	abstract = "By treating the vocal tract as a series of cylindrical sections, or acoustic lines, it is possible to use transmission line theory in finding the resonances. With constants uniformly distributed along each section, resonances appear as modes of vibration of the tract taken as a whole. Thus, the fundamental mode of the smaller cavity may be affected considerably by a higher mode of the larger; and in addition, higher resonances are found without postulating additional cavities. This is an advantage over the lumped constant treatment, where it is necessary to postulate a different cavity for each resonance, and where the interaction terms in the equation do not include the higher modes of vibration. Under the distributed treatment, dimensions for each vowel may be taken from x-ray photographs of the vocal tract. The calculations then yield at least three resonances which lie in the frequency regions known for the vowel, from analyses of normal speech. Dependence of the different resonances upon 
the different cavities is discussed in some detail in the paper.An electrical circuit based on the transmission line analogy has been made to produce acceptable vowel sounds. This circuit is useful in confirming the general theory and in research on the phonetic effects of articulator movements. The possibility of using such a circuit as a phonetic standard for vowel sounds is discussed.",
	author = "Dunn, H. K.",
	doi = "10.1121/1.1906681",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "6",
	pages = "740--753",
	publisher = "ASA",
	title = "{The Calculation of Vowel Resonances, and an Electrical Vocal Tract}",
	url = "http://link.aip.org/link/?JAS/22/740/1",
	volume = "22",
	year = "1950"
}

@inproceedings{Backstrom2005,
	author = "Backstrom, T. and Airas, M. and Lehto, L. and Alku, P.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	comment = "Horrible paper",
	doi = "10.1109/ICASSP.2005.1415259",
	issn = "1520-6149",
	keywords = "filtering theory; glottal flow estimation; glottal flow kurtosis; glottal inverse filtering; manual parameter tuning; objective heuristics; parameter estimation; phase-plane analysis; speech; speech pressure signals; speech processing; statistical analysis; vocal tract all-pole model; vocal tract model order; voice source estimation",
	lockkey = "Y",
	pages = "897--900",
	title = "{Objective Quality Measures for Glottal Inverse Filtering of Speech Pressure Signals}",
	year = "2005"
}

@phdthesis{Mignot2009,
	abstract = "Ce travail porte sur la modÃÅœlisation physique des tubes acoustiques pour la simulation numÃÅœrique e e en temps-rÃÅœel. Le but principal est la synth`se sonore d{\rq}instruments ` vent, avec un mod`le rÃÅœaliste, une e e a ee mÃÅœthode modulaire et une implÃÅœmentation numÃÅœrique faible coÃÂ t. Le mod`le acoustique de ``Webster- e e e u e Lokshin'', utilisÃÅœ ici, est un mod`le ` 1 dimension prenant en compte ` la fois la ``courbure'' du proÃ¯Â¬Âl e ea a et les ``pertes visco-thermiques'' ` la paroi. Pour ce mod`le acoustique, une structure de simulation a e compatible avec l{\rq}approche des ``Guides d{\rq}Ondes'' est obtenue : un tube y est reprÃÅœsentÃÅœ par un syst`me e e e bouclÃÅœ, avec retards, faisant intervenir plusieurs sous-syst`mes sans retard interne. Une diÃ¯Â¬ÂcultÃÅœ est e e e la prÃÅœsence de sous-syst`mes de dimension inÃ¯Â¬Ânie qui se comportent comme des sommes inÃ¯Â¬Ânies de e e syst`mes du premier ou du second ordre. Dans un premier temps, ils sont 
approximÃÅœs par des syst`mes e e e de dimension Ã¯Â¬Ânie, puis leur ``reprÃÅœsentation d{\rq}ÃÅœtat'' ` temps discret est obtenue. EnÃ¯Â¬Ân, en utilisant e e a des outils standard de l{\rq}automatique, ces reprÃÅœsentations nous permettent de faciliter la connexion e d{\rq}ÃÅœlÃÅœments acoustiques et de rÃÅœduire les coÃÂ ts de calcul de la simulation numÃÅœrique. Dans ce travail, ee e u e l{\rq}ÃÅœtude de la stabilitÃÅœ et de la passivitÃÅœ est faite. Pour des cas paticuliers de tubes, un probl`me e e e e survient : mÃÂme si les relations entrÃÅœes/sorties du tube sont stables, certains sous-syst`mes internes e e e poss`dent une inÃ¯Â¬ÂnitÃÅœ de singularitÃÅœs ` l{\rq}origine d{\rq}instabilitÃÅœs internes. Nous prÃÅœsentons une explication e e ea e e de ce phÃÅœnom`ne et ceci nous am`ne a proposer une nouvelle dÃÅœcomposition en sous-syst`mes pour e e e` e e lever ce probl`me. e",
	author = "Mignot, R.",
	lockkey = "Y",
	school = "Telecom ParisTech",
	title = "{R{\'e}alisation en guides d'ondes num{\'e}riques stables d'un mod{\`e}le acoustique r{\'e}aliste pour la simulation en temps-r{\'e}el d'instruments {\`a} vent}",
	year = "2009"
}

@article{Deller1981,
	abstract = "Berouti et al. [2]-[4] and Wong et al. [5] have reported procedures for the ``closed phase'' identification of the all-pole model of the vocal tract. These procedures are shown to be equivalent in a certain case. We argue for the superior performance of Wong's method when modeling errors exist. Finally, a modification to Berouti's method is suggested.",
	author = "Deller, J. Jr.",
	issn = "0096-3518",
	journal = "Acoustics, Speech and Signal Processing, IEEE Trans. on",
	lockkey = "Y",
	month = "aug",
	number = "4",
	pages = "917--919",
	title = "{Some notes on closed phase glottal inverse filtering}",
	volume = "29",
	year = "1981"
}

@article{Thomas2009,
	abstract = "Accurate estimation of glottal closure instants (GCIs) and opening instants (GOIs) is important for speech processing applications that benefit from glottal-synchronous processing. The majority of existing approaches detect GCIs by comparing the differentiated EGG signal to a threshold and are able to provide accurate results during voiced speech. More recent algorithms use a similar approach across multiple dyadic scales using the stationary wavelet transform. All existing approaches are however prone to errors around the transition regions at the end of voiced segments of speech. This paper describes a new method for EGG-based glottal activity detection which exhibits high accuracy over the entirety of voiced segments, including, in particular, the transition regions, thereby giving significant improvement over existing methods. Following a stationary wavelet transform-based preprocessor, detection of excitation due to glottal closure is performed using a group delay function and then true and 
false detections are discriminated by Gaussian mixture modeling. GOI detection involves additional processing using the estimated GCIs. The main purpose of our algorithm is to provide a ground-truth for GCIs and GOIs. This is essential in order to evaluate algorithms that estimate GCIs and GOIs from the speech signal only, and is also of high value in the analysis of pathological speech where knowledge of GCIs and GOIs is often needed. We compare our algorithm with two previous algorithms against a hand-labeled database. Evaluation has shown an average GCI hit rate of 99.47\% and GOI of 99.35\%, compared to 96.08 and 92.54 for the best-performing existing algorithm.",
	author = "Thomas, M.R.P. and Naylor, P.A.",
	doi = "10.1109/TASL.2009.2022430",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing,",
	keywords = "EGG signal; Gaussian mixture modeling; SIGMA algorithm; electroglottographic signal; glottal activity detector; glottal closure instant estimation; glottal opening instant estimation; glottal-synchronous processing; group delay function; hand-labeled database; multiscale analysis algorithm; pathological speech analysis; speech processing application; stationary wavelet transform; Gaussian processes; medical signal processing; speech processing; wavelet transforms",
	lockkey = "Y",
	month = "nov.",
	number = "8",
	pages = "1557--1566",
	title = "{The SIGMA Algorithm: A Glottal Activity Detector for Electroglottographic Signals}",
	volume = "17",
	year = "2009"
}

@article{Frohlich2001,
	abstract = "A new method ``simultaneous inverse filtering and model matching'' (SIM) is proposed that allows one to calculate voice source measures without any user interaction. It is based on the discrete all-pole modeling (DAP) technique for inverse filtering (IF), which is modified to include a model of the glottal flow as integral part [LF model, Fant et al., STL-QPSR (Stockholm) 4/1985, 1--13 (1986)]. As the correct LF parameters are initially unknown, they are estimated in an iterative procedure using multi-dimensional optimization techniques that are initialized according to the results of an exhaustive search. The error criteria applied reflect how well the IF is performed after the spectral contribution of the glottal flow has been removed. The resulting optimal LF parameter constellation serves as the basis to calculate 11 voice source measures. The performance was evaluated using synthesized signals and recordings of natural utterances. For the synthesized signals, the accuracy to reproduce the 
original parameters was high (correlations exceeding 0.88) for measures where the starting point of the glottal cycle did not enter explicitly. Errors were smaller compared to conventional estimation methods where the measures were estimated from the IF signal. The analysis of natural utterances indicates that problems still exist with regard to robustness, but that under advantageous conditions the open quotient, the speed quotient, the closing quotient, the parabolic spectral parameter, and the negative peak amplitude of the glottal flow derivative can indeed be determined automatically by the SIM method.",
	author = "Frohlich, M. and Michaelis, D. and Strube, H. W.",
	doi = "10.1121/1.1379076",
	journal = "Journal of the Acoustical Society of America",
	keywords = "physiological models; speech processing",
	lockkey = "Y",
	number = "1",
	pages = "479--488",
	publisher = "ASA",
	title = "{{SIM}-simultaneous inverse filtering and matching of a glottal flow model for acoustic speech signals}",
	url = "http://link.aip.org/link/?JAS/110/479/1",
	volume = "110",
	year = "2001"
}

@inproceedings{Moore2003,
	author = "Moore, E. and Clements, M. and Peifer, J. and Weisser, L.",
	booktitle = "{Conference on Engineering in Medicine and Biology}",
	lockkey = "Y",
	pages = "2849--2852",
	title = "{Investigating the role of glottal features in classifying clinical depression}",
	year = "2003"
}

@phdthesis{Cook1991,
	author = "Cook, P. R.",
	lockkey = "Y",
	school = "Stanford University (CCRMA)",
	title = "{Identification of control parameters in an articulatory vocal tract model with applications to the synthesis of singing}",
	year = "1991"
}

@article{Edwards1996,
	abstract = "The problem of a subjective, as against an objective, analysis of glottal waveforms obtained through inverse filtering of the acoustic waveform is discussed. It is shown that a dynamical system phase-plane plot can be used to view the residual resonance characteristics and hence assess the quality of the glottal waveform",
	author = "Edwards, J.A. and Angus, J.A.S.",
	issn = "0013-5194",
	journal = "Electronics Letters",
	keywords = "acoustic waveform; dynamical system; glottal inverse filtering; phase-plane plots; residual resonance characteristics; subjective analysis; acoustic resonance; acoustic signal processing; filtering theory; speech processing",
	lockkey = "Y",
	month = "feb",
	number = "3",
	pages = "192--193",
	title = "{Using phase-plane plots to assess glottal inverse filtering}",
	volume = "32",
	year = "1996"
}

@inproceedings{Shue2009,
	abstract = "The open quotient (OQ), loosely defined as the proportion of time the glottis is open during phonation, is an important parameter in many source models. Accurate estimation of OQ from acoustic signals is a non-trivial process as it involves the separation of the source signal from the vocal-tract transfer function. Often this process is hampered by the lack of direct physiological data with which to calibrate algorithms. In this paper, an analysis-by-synthesis method using a codebook of harmonically-based Liljencrants-Fant (LF) source models in conjunction with a constrained optimizer was used to obtain estimates of OQ from four subjects. The estimates were compared with physiological measurements from high-speed imaging. Results showed relatively high correlations between the estimated and measured values for only two of the speakers, suggesting that existing source models may be unable to accurately represent some source signals.",
	author = "Shue, Y.-L and Kreiman, J. and Alwan, A.",
	booktitle = "{Proc. Interspeech}",
	keywords = "open quotient; voice source; speech analysis",
	lockkey = "Y",
	pages = "2895--2898",
	title = "{A Novel Codebook Search Technique for Estimating the Open Quotient}",
	year = "2009"
}

@inproceedings{Thomas2008,
	abstract = "Accurate estimation of glottal closure instants (GCIs) in voiced speech is important for speech analysis applications which bene- Ã¯Â¬Ât from glottal-synchronous processing. Electroglottograph (EGG) recordings give a measure of the electrical conductance of the glot- tis, providing a signal which is proportional to its contact area. EGG signals contain little noise or distortion, providing a good refer- ence from which GCIs can be extracted to evaluate GCI estimation from speech recordings. Many approaches impose a threshold on the differentiated EGG signal which provide accurate results dur- ing voiced speech but are prone to errors at the onset and end of voicing; modern algorithms use a similar approach across multi- ple dyadic scales using the stationary wavelet transform. This pa- per describes a new method for EGG-based GCI estimation named SIGMA, which is based upon the stationary wavelet transform, peak detection with a group delay function and Gaussian Mixture Mod- elling for 
discrimination between true and false GCI candidates. In most real-world environments, it is necessary to estimate GCIs from a speech signal recorded with a microphone placed at some distance from the talker. The presence of reverberation, noise and Ã¯Â¬Âltering by the vocal tract render GCI detection from real speech signals relatively difÃ¯Â¬Âcult to achieve compared with the EGG, so EGG-based references have often been used to evaluate GCI detection from speech signals. Evaluation against 500 hand- labelled sentences has shown an accuracy of 99.35\%, a 4.7\% im- provement over a popular existing method.",
	author = "Thomas, M. R. P. and Naylor, P. A.",
	booktitle = "{EUSIPCO}",
	lockkey = "Y",
	title = "{The SIGMA algorithm for estimation of reference-quality glottal closure instants from electroglottograph signals}",
	year = "2008"
}

@inproceedings{Kreiman2008,
	author = "Kreiman, J. and Gerratt, B. R. and Iseli, M. and Neubauer, J. and Shue, Y.-L. and Alwan, A.",
	booktitle = "{ICVPB}",
	lockkey = "Y",
	title = "{The relationship between open quotient and H1*-H2*}",
	year = "2008"
}

@article{Walker2007,
	abstract = "Glottal inverse Ã¯Â¬Âltering is of potential use in a wide range of speech processing applications. As the process of voice production is, to a Ã¯Â¬Ârst order approximation, a source-Ã¯Â¬Âlter process, then obtaining source and Ã¯Â¬Âlter components provides for a Ã¯Â¬Âexible representation of the speech signal for use in processing applications. In certain applications the desire for accurate inverse Ã¯Â¬Âltering is more immediately obvious, e.g., in the assessment of laryngeal aspects of voice quality and for cor- relations between acoustics and vocal fold dynamics, the resonances of the vocal tract should Ã¯Â¬Ârstly be removed. Similarly, for assessment of vocal performance, trained singers may wish to obtain quantitative data or feedback regarding their voice at the level of the larynx.",
	author = "Walker, J. and Murphy, P.",
	journal = "Lecture Notes in Computer Science",
	lockkey = "Y",
	title = "{A Review of Glottal Waveform Analysis}",
	year = "2007"
}

@article{Banno2007,
	abstract = "Abstract: A very high quality speech analysis, modiÃ¯Â¬Âcation and synthesis system---STRAIGHT--- has now been implemented in C language and operated in realtime. This article Ã¯Â¬Ârst provides a brief summary of STRAIGHT components and then introduces the underlying principles that enabled realtime operation. In STRAIGHT, the built-in extended pitch synchronous analysis, which does not require analysis window alignment, plays an important role in realtime implementation. A detailed description of the processing steps, which are based on the so-called {\lq}{\lq}just-in-time{\rq}{\rq} architecture, is presented. Further, discussions on other issues related to realtime implementation and performance measures are also provided. The software will be available to researchers upon request.",
	author = "{H. Banno}, H. Hata M. Morise T. Takahashi T. Irino and Kawahara, H.",
	journal = "The Acoustical Society of Japan",
	keywords = "STRAIGHT speech manipulation system; Realtime; Pitch synchronous analysis; F0 extraction; Voice conversion",
	lockkey = "Y",
	title = "{Implementation of realtime STRAIGHT speech manipulation system: Report on its Ã¯Â¬Ârst implementation}",
	year = "2007"
}

@phdthesis{StylianouY1996,
	address = "France",
	author = "Stylianou, Y.",
	lockkey = "Y",
	school = "TelecomParis",
	title = "{Harmonic plus Noise Models for Speech combined with Statistical Methods, for Speech and Speaker Modification}",
	year = "1996"
}

@inproceedings{Agiomyrgiannakis2008,
	abstract = "This paper presents an ARX-LF-based model of speech that is amenable to low-bit-rate quantization and speech modifications directly at the parametric domain. The new model successfully addresses the non-deterministic part of voiced speech by modulating noise with the glottal flow, while unvoiced speech and transients are synthesized by modulating noise with a signal-derived time envelope. The presented work is essentially a high-quality vocoder that can be used for low complexity coding/synthesis/modification of speech suitable for embedded text-to-speech applications. Index Terms: speech coding, LF, LPC vocoder, embedded speech synthesis, text-to-speech, modulated noise, pitch/time scaling, speech transformation/modification",
	author = "Agiomyrgiannakis, Y. and Rosec, O.",
	booktitle = "{Proc. Interspeech}",
	lockkey = "Y",
	pages = "1849--1852",
	title = "{Towards Flexible Speech Coding for Speech Synthesis: an {LF} + Modulated Noise Vocoder}",
	year = "2008"
}

@inproceedings{AgiomyrgiannakisY2009,
	abstract = "Two ARX-LF-based source/filters models for speech signals are presented. A robust glottal inversion technique is used to deconvolve the signal into an excitation component and a filter component. The excitation component is further decomposed into an LF part and a residual part. The first model, referred to as the LF-vocoder, is a high quality vocoder that replaces the residual part with modulated noise. The second model uses a sinusoidal harmonic representation of the residual signal. The latter does not degrade the signal during analysis/synthesis and provides higher quality for small modification factors, while the former has the advantage of being a compact, fully parametric representation that is suitable for low-bit-rate speech coding as well as parametric speech synthesis applications.",
	author = "Agiomyrgiannakis, Y. and Rosec, O.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2009.4960402",
	isbn = "978-1-4244-2353-8",
	lockkey = "Y",
	pages = "3589--3592",
	title = "{{ARX-LF}-based source-filter methods for voice modification and transformation}",
	year = "2009"
}

@article{Laroche1999,
	abstract = "The phase vocoder is a well established tool for time scaling and pitch shifting speech and audio signals via modification of their short-time Fourier transforms (STFTs). In contrast to time-domain time-scaling and pitch-shifting techniques, the phase vocoder is generally considered to yield high quality results, especially for large modification factors and/or polyphonic signals. However, the phase vocoder is also known for introducing a characteristic perceptual artifact, often described as ldquo;phasiness rdquo;, ldquo;reverberation rdquo;, or ldquo;loss of presence rdquo;. This paper examines the problem of phasiness in the context of time-scale modification and provides new insights into its causes. Two extensions to the standard phase vocoder algorithm are introduced, and the resulting sound quality is shown to be significantly improved. Moreover, the modified phase vocoder is shown to provide a factor-of-two decrease in computational cost",
	author = "Laroche, J. and Dolson, M.",
	doi = "10.1109/89.759041",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "audio coding; audio signals; computational cost reduction; Fourier transforms; loss of presence; perceptual artifact; phase vocoder; phasiness; pitch shifting; reverberation; short-time Fourier transforms; sound quality; speech signals; standard phase vocoder algorithm; time-scale modification; time scaling; vocoders",
	lockkey = "Y",
	number = "3",
	pages = "323--332",
	title = "{Improved phase vocoder time-scale modification of audio}",
	volume = "7",
	year = "1999"
}

@article{Wen1995,
	abstract = "A novel adaptive pitch-synchronous analysis method is proposed to estimate simultaneously vocal tract (formant/antiformant) and voice source parameters from speech waveforms. We use the parametric Rosenberg-Klatt (RK) model to generate a glottal waveform and an autoregressive-exogenous (ARX) model to represent voiced speech production process. The Kalman filter algorithm is used to estimate the formant/antiformant parameters from the coefficients of the ARX model, and the simulated annealing method is employed as a nonlinear optimization approach to estimate the voice source parameters. The two approaches work together in a system identification procedure to find the best set of the parameters of both the models. The new method has been compared using synthetic speech with some other approaches in terms of accuracy of estimated parameter values and has been proved to be superior. We also show that the proposed method can estimate accurately the parameters from natural speech sounds. A major 
application of the analysis method lies in a concatenative formant synthesizer which allows us to make flexible control of voice quality of synthetic speech.",
	author = "Wen, D. and Hideki, K. and Shuichi, A.",
	issn = "09168532",
	journal = "IEICE Trans. on information and systems",
	lockkey = "Y",
	number = "6",
	pages = "738--743",
	publisher = "The Institute of Electronics, Information and Communication Engineers",
	title = "{Simultaneous Estimation of Vocal Tract and Voice Source Parameters Based on an ARX Model}",
	url = "http://ci.nii.ac.jp/naid/110003209531/en",
	volume = "78",
	year = "1995"
}

@inproceedings{Rozak2007,
	abstract = "CircumReality is a niche-market massively-multiplayer online role-playing game (MMORPG or MMOG) that relies heavily on text-to-speech (TTS) for narration, non-player character (NPC) speech, and text chat between players. Associated speech technologies enable voice chat and voice transformation/disguise. Most contemporary TTS engines are geared towards hand-held devices or telephony, resulting in technology that is not ideally suited for games. This paper discusses how a game-oriented TTS engine differs from a telephony or device-oriented TTS engine, and how those differences affect the technology.",
	author = "Rozak, Mike",
	booktitle = "{Blizzard}",
	lockkey = "Y",
	title = "{Text-to-speech Designed For a Massively Multiplayer Online Role-Playing Game (MMORPG)}",
	year = "2007"
}

@article{Cappe1996,
	abstract = "Traditional spectral envelope estimation methods suffer from significant drawbacks in (high-pitched) voiced segments: spectral peaks tend to be biased toward pitch harmonics. To alleviate this drawback, discrete modeling techniques have been proposed. The discrete cepstrum method consists in fitting a spectral envelope parameterized by cepstrum coefficients to a discrete set of spectral points using a log-spectral distortion criterion. Unfortunately, this estimation problem is ill conditioned in many cases of interest. The article introduces a simple regularization technique that guarantees that the spectral envelope is well behaved. A modification of the basic regularization criterion is proposed in order to take into account a possible prior knowledge of the spectral tilt of the envelope",
	author = "Cappe, O. and Moulines, E.",
	doi = "10.1109/97.489060",
	issn = "1070-9908",
	journal = "IEEE Signal Processing Letters",
	keywords = "cepstrum coefficients; discrete cepstrum estimation; discrete cepstrum method; discrete modeling techniques; high pitched voiced segments; ill conditioned problem; log-spectral distortion criterion; parametric model; pitch harmonics; regularization criterion; regularization techniques; spectral envelope estimation methods; spectral peaks; spectral tilt; cepstral analysis; parameter estimation; speech processing",
	lockkey = "Y",
	month = "apr",
	number = "4",
	pages = "100--102",
	title = "{Regularization techniques for discrete cepstrum estimation}",
	volume = "3",
	year = "1996"
}

@article{Rivet2007,
	abstract = "In this paper, we study the distribution of the log-modulus of a Gaussian complex random variable. In the circular case, it is a Log-Rayleigh (LR) variable, whose probability distribution function (pdf) depends on only one parameter. In the noncircular case, the pdf is more complicated, although we show that it can be adequately modeled by an LR pdf, for which the optimal fitting parameter is derived. These results can be used in any application using the log-modulus of discrete Fourier transform coefficients, e.g., for speech/audio signals, and suggest that a mixture of LR pdf kernels is preferable to more classical models such as mixtures of Gaussian kernels, which are more costly and less efficient",
	author = "Rivet, Bertrand and Girin, Laurent and Jutten, Christian",
	doi = "10.1109/TASL.2006.885922",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing,",
	keywords = "Gaussian complex random variable; Gaussian kernels; discrete Fourier transform coefficient; log-Rayleigh distribution; log-modulus distribution; log-spectral coefficients; optimal fitting parameter; probability distribution function; statistical representation; Gaussian processes; discrete Fourier transforms; signal processing; statistical analysis; statistical distributions",
	lockkey = "Y",
	month = "march",
	number = "3",
	pages = "796--802",
	title = "{Log-Rayleigh Distribution: A Simple and Efficient Statistical Representation of Log-Spectral Coefficients}",
	volume = "15",
	year = "2007"
}

@article{Smaragdis2005,
	abstract = "In this paper we examine the problem of identifying trajectories of sound sources as captured from microphone arrays. Instead of employing traditional localization techniques we attack this prob- lem with a statistical modeling approach of phase measurements. As in many signal processing applications that require the use of phase there is the issue of phase-wrapping. Even though there ex- ists a signiÃ¯Â¬Âcant amount of work on unwrapping wrapped phase estimates, when it comes to stochastic modeling this can introduce an additional level of undesirable complication. We address this issue by deÃ¯Â¬Âning an appropriate statistical model to Ã¯Â¬Ât wrapped phase data, and employ it as a state model of an HMM in order to recognize sound trajectories. Using both synthetic and real data we highlight the accuracy of this model as opposed to generic HMM modeling.",
	author = "Smaragdis, P. and Boufounos, P.",
	journal = "IEEE Workshop on Applications of Signal Processing to Audio and Acoustics",
	lockkey = "Y",
	title = "{LEARNING SOURCE TRAJECTORIES USING WRAPPED-PHASE HIDDEN MARKOV MODELS}",
	year = "2005"
}

@article{Veeneman1985,
	abstract = "The flow of air through the glottis, the glottal volume-velocity, reflects the action of the vocal folds and is thus an important indicator of laryngeal function. However, it cannot be measured directly because of vocal tract filtering. We have developed an automated on-line method to determine the glottal volume-velocity waveform from normal and pathological speech based on digital inverse filtering. The method developed addresses the problems of accurate identification of vocal tract parameters and reduction of low-frequency noise. The vocal tract filter is estimated by analysis of the undriven vocal tract response during closed glottis, as identified from an electroglottographic signal. Low-frequency noise is attenuated by a high-pass filtering operation followed by a low-pass compensation. The complete inverse filtering method provides reliable glottal volume-velocity waveforms for both normal and pathological speech.",
	author = "Veeneman, D. and BeMent, S.",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "2",
	pages = "369--377",
	title = "{Automatic glottal inverse filtering from speech and electroglottographic signals}",
	volume = "33",
	year = "1985"
}

@inproceedings{KimHS1997,
	abstract = "The quality of the synthesized speech in most low bit rate speech coders, depends greatly on the performance of the spectral coding stage, in which the spectral envelope is encoded. The spectral envelope estimation vocoder (SEEVOC) is a successful spectral envelope coding method, and also plays an important role in speech coding based on the sinusoidal model. This paper investigates the properties and limitations of the SEEVOC algorithm, which requires an estimate of the coarse pitch. Our analysis of the effect of inaccurate coarse pitch gives a new insight into the spectral envelope estimator, and shows that it is important to start with a reasonably accurate coarse pitch value. Also, we optimize and generalize the properties of the SEEVOC algorithm and propose a new method to improve pitch estimation based on the sinusoidal speech model",
	author = "Kim, H. S. and Nolmes, H. and Zhang, W.",
	booktitle = "{Proc. IEEE Speech and Image Technologies for Computing and Telecommunications}",
	doi = "10.1109/TENCON.1997.648271",
	keywords = "coarse pitch estimation; low bit rate speech coders; parameter estimation; refined pitch estimation; SEEVOC algorithm; sinusoidal speech model; spectral analysis; spectral coding; spectral envelope coding; spectral envelope estimation vocoder; speech coding; speech intelligibility; speech synthesis; synthesized speech quality; vocoders",
	lockkey = "Y",
	pages = "575--578",
	title = "{Investigation on the spectral envelope estimator ({SEEVOC}) and refined pitch estimation based on the sinusoidal speech model}",
	volume = "2",
	year = "1997"
}

@inproceedings{Lee1999,
	abstract = "In this paper, we discuss the estimation of a glottal excitation source using the glottal inverse filtering (GIF) analysis method. The WRLS-VFF-VT algorithm, which sequentially estimates the filter coefficients, estimation error, the variable forgetting factor, the pitch period, and the instant at which the glottis closes, can be applied to GIF analysis. For the estimation of the pitch period and the glottal opening/closed instants, we can use the VFF signal. The performance of this method is compared with other methods such as the two-pass and two-channel methods",
	author = "Lee, K. and Park, K.",
	booktitle = "{TENCON 99. Proceedings of the IEEE Region 10 Conference}",
	comment = "aie ...",
	doi = "10.1109/TENCON.1999.818497",
	keywords = "WRLS-VFF-VT algorithm; estimation error; filter coefficients; glottal excitation source; glottal inverse filtering; glottal opening/closed instants; pitch period; sequential estimation; speech analysis; variable forgetting factor; filtering theory; inverse problems; least squares approximations; sequential estimation; speech processing",
	lockkey = "Y",
	pages = "646--649 vol.1",
	title = "{Glottal inverse filtering (GIF) using closed phase WRLS-VFF-VT algorithm}",
	volume = "1",
	year = "1999"
}

@article{Rothenberg1973,
	abstract = "A method is described for deriving the volume velocity waveform at the glottis during voiced speech by inverse-filtering the volume velocity waveform at the mouth. Unlike the previously used technique of inverse-filtering radiated acoustic pressure, this method provides a signal that is accurate down to zero frequency, not susceptible to low-frequency noise, and easily calibrated in amplitude by a constant air flow. The primary limitation is the need for a transducer that will measure volume velocity at the mouth with adequate fidelity. In this work, volume velocity was recorded from a specially designed circumferentially vented wire screen pneumotachograph mask which provided a time resolution of 1/2 msec, without serious speech distortion. Inverse-filtered volume velocity was recorded with two adult male subjects for voicing in the modal register. Typical results are shown which indicate the way in which the glottal waveform varied with changes of fundamental frequency, subglottal pressure, 
and a dimension of voice quality related to the degree of compression of the vocal folds. Also considered are the effects of glottal-supraglottal acoustic interaction, and the effect on the glottal waveform of air displaced by the movements of the vocal folds.",
	author = "Rothenberg, M.",
	doi = "10.1121/1.1913513",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "6",
	pages = "1632--1645",
	publisher = "ASA",
	title = "{A new inverse-filtering technique for deriving the glottal air flow waveform during voicing}",
	url = "http://link.aip.org/link/?JAS/53/1632/1",
	volume = "53",
	year = "1973"
}

@inproceedings{Lobo2001,
	abstract = "This paper discusses a method for estimating glottal flow derivative model parameters using wavelet-smoothed excitation. The excitation is first estimated using the weighted recursive least squares with variable forgetting factor algorithm. The raw excitation is then smoothed by applying a discrete wavelet transform (DWT) using biorthogonal quadrature filters, and a thresholding operation carried out on the DWT amplitude coefficients, followed by an inverse DWT. The pitch period and the instant of glottal closure (IGC) are estimated from the wavelet-smoothed excitation. A six-parameter glottal flow derivative model consisting of three amplitude and three timing parameters is aligned with the IGC and optimized by minimum square error fitting to the speech waveform. The optimization is done by the method of simulated annealing. The. model is then used to reestimate the vocal-tract filter parameters in an ARX procedure followed by further stages of voice source-vocal tract estimation. The results 
of analysis of speech utterances from the BK TIMIT database are presented",
	author = "Lobo, A. P.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2001.941051",
	isbn = "0-7803-7041-4",
	lockkey = "Y",
	pages = "861--864",
	title = "{Glottal flow derivative modeling with the wavelet smoothed excitation}",
	volume = "2",
	year = "2001"
}

@article{PaulDB1981,
	abstract = "This paper describes a low bit-rate vocoder designed for improved speech reproduction quality and robustness. The vocoder is designed around a new algorithm, the spectral envelope estimator, which forms the nucleus of the spectral analyzer. In addition to estimating the speech spectrum, the spectral analyzer also allows determination of a continuous estimate of the background noise spectrum, which is used for noise suppression. A maximum-likelihood pitch estimator, which shares the signal processing of the spectral envelope estimator, has been integrated into the vocoder to yield accurate pitch estimates of noisy speech. This system is capable of good quality speech reproduction at bit rates down to 2.4 kbits/s.",
	author = "Paul, D. B.",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "4",
	pages = "786--794",
	title = "{The spectral envelope estimation vocoder}",
	volume = "29",
	year = "1981"
}

@article{Angulo2007,
	abstract = "For sensory diÃ¯Â¬Âerence tests, one way, but not the only way, of dealing with the problem of overdispersion is to use a beta-binomial analysis. Commonly, binomial statistical analyses are used for these methods and they assume that the sensitivity of the judges is uni- form. However, judge sensitivity varies and this adds a problematical extra variance to the distribution. This is termed overdispersion and renders simple binomial analysis prone to Type I error. The distribution of sensitivity of the judges is described by a beta-distribu- tion. The analysis, combining beta and binomial distributions, gives an index, gamma. This ranges from zero, for no overdispersion, to unity, for total overdispersion. A compact beta-distribution clustered around the mean of the binomial distribution, would add little extra variance and elicit minimum distortion of the binomial distribution, yielding a zero or near zero gamma value. A more scattered or even bimodal beta-distribution would have a substantial 
eÃ¯Â¬Âect and yield a signiÃ¯Â¬Âcant gamma value. One question that has been posed is whether some test methods are more prone to overdispersion than others. Yet, a consideration of the reasons for overdispersion would suggest that signiÃ¯Â¬Âcant gamma values were more a result of obtaining a heterogenous sample of sensitive and insensitive judges by chance. To conÃ¯Â¬Ârm this, {\{\{\{\^O}}}}less sensitiveÃÂ and {\{\{\{\^O}}}}more sensitiveÃÂ samples of judges performed 2-AFC and 3-AFC tests with resulting zero gamma values, indicating no overdispersion. However, when the less and more sensitive groups were combined, signiÃ¯Â¬Âcant gamma values were obtained, indicating the presence of overdispersion. However, in a further experiment using 2-AFC tests, when the {\{\{\{\^O}}}}less sensitiveÃÂ group had its sensitivity increased by a {\{\{\{\^O}}}}warm-upÃÂ procedure, combination with the {\{\{\{\^O}}}}more sensitiveÃÂ group did not result in overdispersion.",
	author = "{Ofelia Angulo}, Hye-Seong Lee Michael O'Mahony",
	journal = "Food Quality and Preference",
	lockkey = "Y",
	title = "{Sensory diÃ¯Â¬Âerence tests: Overdispersion and warm-up}",
	year = "2007"
}

@article{Angulo2005,
	abstract = "After experimenting with questionnaires, Odesky had recommendations for eliminating {\{\{\{\^O}}}}No PreferenceÃÂ responses in a paired preference test. He concluded that, judges who had chosen the {\{\{\{\^O}}}}No PreferenceÃÂ option would, if forced to choose, express preferences in the same pattern as those who had actually expressed a preference. Using questionnaire, food and personal product stimuli, this conclusion was found to be commonly violated. OdeskyÃÂs recommendation, to ignore or distribute {\{\{\{\^O}}}}No PreferenceÃÂ responses in the same proportion as expressed preferences was sometimes seen to distort data, sometimes not, depending on relative response fre- quencies and extent of violation of his conclusion regarding forced preferences. When the number of {\{\{\{\^O}}}}No PreferenceÃÂ responses is not insigniÃ¯Â¬Âcantly small, to eliminate them, runs the risk of distortion of the overall pattern of preferences.",
	author = "{Ofelia Angulo}, Michael O'Mahony",
	journal = "Food Quality and Preference",
	lockkey = "Y",
	title = "{The paired preference test and the No Preference option: was Odesky correct ?}",
	year = "2005"
}

@article{Lehto2007,
	abstract = "Inverse filtering (IF) is a common method used to estimate the source of voiced speech, the glottal flow. This investigation aims to compare two IF methods: one manual and the other semiautomatic. Glottal flows were estimated from speech pressure waveforms of six female and seven male subjects producing sustained vole /a/ in breathy, normal, and pressed phonation. The closing phase characteristics of the glottal pulse were parameterized using two time-based parameters: the closing quotient (C1Q) and the normalized amplitude quotient (NAQ). The information given by these two parameters indicates a strong correlation between the two IF methods. The results are encouraging in showing that the parameterization of the voice source in different speech sounds can be performed independently of the technique used for inverse filtering.",
	author = "Lehto, L. and Airas, M. and Bjorkner, E. and Sundberg, J. and Alku, P.",
	journal = "Journal of Voice",
	lockkey = "Y",
	number = "2",
	pages = "138--50",
	title = "{Comparison of two inverse filtering methods in parameterization of the glottal closing phase characteristics in different phonation types.}",
	volume = "21",
	year = "2007"
}

@inproceedings{Perez2009,
	abstract = "We present here a new method for the simultaneous estimation of the derivative glottal waveform and the vocal tract filter. The algorithm is pitch-synchronous and uses overlapping frames of several glottal cycles to increase the robustness and quality of the estimation. Two parametric models for the glottal waveform are used: the KLGLOTT88 during the convex optimization iteration, and the LF model for the final parametrization. We use a synthetic corpus using real data published in several studies to evaluate the performance. A second corpus has been specially recorded for this work, consisting of isolated vowels uttered with different voice qualities. The algorithm has been found to perform well with most of the voice qualities present in the synthetic data-set in terms of glottal waveform matching. The performance is also good with the real vowel data-set in terms of resynthesis quality.",
	author = "Perez, J. and Bonafonte, A.",
	booktitle = "{Proc. Interspeech}",
	keywords = "speech synthesis; speech analysis; speech processing; glottal modeling",
	lockkey = "Y",
	pages = "68--71",
	title = "{Towards Robust Glottal Source Modeling}",
	year = "2009"
}

@article{Alfaro-Rodriguez2007,
	abstract = "Paired preference tests were performed using plain salted and lemon Ã¯Â¬Âavored potato chips. In some cases, identical chips were tested to determine the eÃ¯Â¬Âects of the experimental situation per se (placebo condition). In other cases, diÃ¯Â¬Âerent chips were tested and this allowed measurement of preference, accompanied by the eÃ¯Â¬Âects of the experimental situation (test condition). Comparison between the two, allowed a measure of preference. A total of 1100 consumers were tested in a variety of experimental conditions. In one condition, a single pair of identical chips was tested while in a diÃ¯Â¬Âerent condition, two pairs of chips, one identical, one diÃ¯Â¬Âerent, were tested; this allowed both related samples and independent samples designs. All possible combinations of the two orders of pairs (same vs diÃ¯Â¬Âerent) and the four orders of tasting within the pairs were tested. Whether the placebo condition was tested Ã¯Â¬Ârst or second appeared to have little eÃ¯Â¬Âect. Chi-
squared was used to determine whether the preference results were signiÃ¯Â¬Âcantly diÃ¯Â¬Âerent from a {\lq}no preference{\rq} situation and d 0 was used to give a measure of the degree of preference for one product or another. Within-subjects and between-subjects analyses gave the same results. The placebo condition allowed the detection in the test condition of signiÃ¯Â¬Âcant preferences as well as the presence of two equally balanced preference groups. The placebo condition also had the potential to be used as a screening tool.",
	author = "Alfaro-Rodriguez, H. and Angulo, O. and O{\rq}Mahony, M.",
	journal = "Food Quality and Preference",
	keywords = "Paired preference tests; Placebo measurement; Chi-squared; Response bias; d 0; Thurstonian modeling; False preferences",
	lockkey = "Y",
	title = "{Be your own placebo: A double paired preference test approach for establishing expected frequencies}",
	year = "2007"
}

@article{Fant1988,
	author = "Fant, G. and Lin, Q.",
	journal = "STL-QPSR",
	lockkey = "Y",
	number = "2-3",
	pages = "1--21",
	title = "{Frequency domain interpretation and derivation of glottal flow parameters}",
	volume = "29",
	year = "1988"
}

@inproceedings{Doval1997,
	abstract = "This paper deals with the spectral representation of the glottal flow. The LF and the KLGLOTT88 models of the glottal flow are studied. We compute analytically the spectrum of the LF-model. Then, formulas are given for computing spectral tilt and amplitudes of the first harmonics as functions of the LF-model parameters. We consider the spectrum of the KLGLOTT88 model. It is shown that this model can be modeled in the spectral domain by an all-pole third-order linear filter. Moreover, the anticausal impulse response of this filter is a good approximation of the glottal flow model. Parameter estimation seems easier in the spectral domain. Therefore our results can be used for modification of the (hidden) glottal flow characteristic of natural speech signals, by processing directly the spectrum, without needing time-domain parameter estimation",
	author = "Doval, B. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1997.596183",
	keywords = "all-pole third-order linear filter; anticausal impulse response; correlation methods; filtering theory; first harmonics; glottal flow; glottal flow model; glottal waveform models; harmonic analysis; hidden glottal flow characteristic; KLGLOTT88 models; LF model parameters; natural speech signals; parameter estimation; spectral amplitudes; spectral analysis; spectral correlates; spectral domain; spectral representation; spectral tilt; spectrum processing; speech processing; transient response",
	lockkey = "Y",
	pages = "1295--1298",
	title = "{Spectral correlates of glottal waveform models: an analytic study}",
	volume = "2",
	year = "1997"
}

@inproceedings{Doval1997a,
	abstract = "A spectral approach is proposed for voice source parameters representation and estimation. Pa- rameter estimation is based on decomposition of the periodic and the aperiodic components of the speech signal, and on spectral modelling of the pe- riodic component. The paper focusses on param- eters estimation for the periodic component of the glottal ow. A new anticausal all-pole model of the glottal ow is derived. Glottal ow is seen as an anticausal 2-pole lter followed by a spectral tilt lter. The anticausal lter has complex poles, instead of the real poles that are usually assumed. Time-domain and frequency domain parameters are linked by analytic formulas. Two spectral do- main algorithms are proposed for estimation of open quotient. The rst one is based on mea- surement of the rst harmonics, and the second one is based on spectral modelling. Experimental results demonstrate the accuracy of the estima- tion procedures.",
	author = "Doval, B. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Diard, B.",
	booktitle = "{Proc. Eurospeech}",
	lockkey = "Y",
	pages = "533--536",
	title = "{Spectral Methods For Voice Source Parameters Estimation}",
	year = "1997"
}

@inproceedings{Sturmel2006a,
	abstract = "A new method for estimation of the voice speed quotient (Sq ) from acoustic signals is presented. The method is based on source Ã¯Â¬Âlter decomposition us- ing a new signal representation, the Zeros of Z Trans- form representation. A source dominated spectrum is obtained using the ZZT decomposition, and then the glottal for- mant frequency is estimated. The spectral theory of the voice source shows that the glottal formant frequency depends on the fundamental frequency (F0 ), the voice open quotient (Oq ) and Sq . Using an electroglottographic (EGG) reference for esti- mation of F0 and Oq ; Sq can be obtained from the glottal formant frequency. The estimation algorithm has been implemented and then tested on a database of male and female speech containing EGG and acoustic signals. Three speakers produced 71 vowels under various con- ditions of vocal effort, tenseness and fundamental frequency. In most of the case, speed quotient es- timation gives accurate values, mainly situated be- tween 1.5 
and 4. However, in some situations (high F0 , low Ã¯Â¬Ârst vocalic formant, high Oq ) the measure- ments fail and some post-processing would be nec- essary. Moreover, it seems that this decomposition method could also be used for Oq estimation, con- sidering typical values of Sq and the perceptual just noticeable differences on Oq (about 15 \%).",
	author = "Sturmel, N. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Doval, B.",
	booktitle = "{Proc. Advances in Quantitative Laryngology (AQL)}",
	lockkey = "Y",
	title = "{A spectral method for estimation of the voice speed quotient and evaluation using electroglottography}",
	year = "2006"
}

@phdthesis{HansonH1995,
	address = "USA",
	author = "Hanson, Helen M.",
	lockkey = "Y",
	school = "Harvard University",
	title = "{Glottal characteristics of female speakers}",
	year = "1995"
}

@article{JacksonLB1989,
	abstract = "A noncausal autoregressive moving average (ARMA) source-filter model of voiced speech is proposed. Although the human speech-production mechanism is obviously causal, a noncausal model allows the simple source-filter approach to incorporate different parameters for the open-glottis and closed glottis portions of the pitch period (without explicit determination of the open- and closed-glottis regions). The noncausal impulse response is obtained by standard cepstral deconvolution. Separate ARMA models are then found for the causal and anticausal portions of the impulse response. Initial experiments show that very close approximations to the speech waveform and spectrum are produced by two twelfth-order ARMA models",
	author = "Jackson, L. B.",
	doi = "10.1109/29.35403",
	issn = "0096-3518",
	journal = "Acoustics, Speech and Signal Processing, IEEE Trans. on",
	keywords = "ARMA models; LPC; cepstral deconvolution; closed glottis; human speech-production mechanism; linear predictive coding; noncausal autoregressive moving average; noncausal impulse response; open-glottis; pitch period; source-filter model; speech spectrum; speech waveform; twelfth-order ARMA models; voiced speech; encoding; filtering and prediction theory; speech analysis and processing",
	lockkey = "Y",
	number = "10",
	pages = "1606--1608",
	title = "{Noncausal ARMA modeling of voiced speech}",
	volume = "37",
	year = "1989"
}

@article{PJBJackson2001,
	abstract = "Almost all speech contains simultaneous contribu- tions from more than one acoustic source within the speaker{\rq}s vocal tract. In this paper, we propose a method---the pitch-scaled har- monic filter (PSHF)---which aims to separate the voiced and tur- bulence-noise components of the speech signal during phonation, based on a maximum likelihood approach. The PSHF outputs peri- odic and aperiodic components that are estimates of the respective contributions of the different types of acoustic source. It produces four reconstructed time series signals by decomposing the original speech signal, first, according to amplitude, and then according to power of the Fourier coefficients. Thus, one pair of periodic and aperiodic signals is optimized for subsequent time-series analysis, and another pair for spectral analysis. The performance of the PSHF algorithm was tested on synthetic signals, using three forms of disturbance (jitter, shimmer and additive noise), and the results were used to predict the 
performance on real speech. Processing recorded speech examples elicited latent features from the signals, demonstrating the PSHF{\rq}s potential for analysis of mixed-source speech.",
	author = "Jackson, Philip J. B. and Shadle, Christine H.",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "Periodic--aperiodic decomposition; speech modi- fication; speech preprocessing",
	lockkey = "Y",
	title = "{Pitch-Scaled Estimation of Simultaneous Voiced and Turbulence-Noise Components in Speech}",
	year = "2001"
}

@article{LombardE1911,
	author = "Lombard, Etienne",
	journal = "Ann. Maladies Oreille, Larynx, Nez, Pharynx",
	lockkey = "Y",
	number = "2",
	pages = "101--119",
	title = "{The sign of the elevation of the voice}",
	volume = "37",
	year = "1911"
}

@inproceedings{AtalBS1982,
	abstract = "The excitation for LPC speech synthesis usually consists of two separate signals - a delta-function pulse once every pitch period for voiced speech and white noise for unvoiced speech. This manner of representing excitation requires that speech segments be classified accurately into voiced and unvoiced categories and the pitch period of voiced segments be known. It is now well recognized that such a rigid idealization of the vocal excitation is often responsible for the unnatural quality associated with synthesized speech. This paper describes a new approach to the excitation problem that does not require a priori knowledge of either the voiced-unvoiced decision or the pitch period. All classes of sounds are generated by exciting the LPC filter with a sequence of pulses; the amplitudes and locations of the pulses are determined using a non-iterative analysis-by-synthesis procedure. This procedure minimizes a perceptual-distance metric representing subjectively-important differences between the 
waveforms of the original and the synthetic speech signals. The distance metric takes account of the finite-frequency resolution as well as the differential sensitivity of the human ear to errors in the formant and inter-formant regions of the speech spectrum.",
	author = "Atal, B. S. and Remde, J. R.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	pages = "614--617",
	title = "{A new model of {LPC} excitation for producing natural-sounding speech at low bit rates}",
	year = "1982"
}

@inproceedings{AlessandroC1995,
	abstract = "This paper presents a new method for decomposition of the speech signal into a deterministic and a stochastic component. The method is based on iterative signal reconstruction. The method involves: (1) separation of speech into an approximate excitation and filter components using linear predictive (LP) analysis; (2) identification of frequency regions of noise and deterministic components of excitation using cepstrum; (3) reconstruction of the two excitation components of the residual using an iterative algorithm; (4) and finally, the deterministic and stochastic components of the excitation are then obtained by combining the reconstructed frames of data using an overlap-add procedure. The deterministic and stochastic components are then passed through the time varying all-pole filter to obtain the components of the speech signal. The algorithm is able to decompose varying mixtures of stochastic and deterministic signals, like the noise bursts produced at the glottal closure and the 
deterministic glottal pulses. This new algorithm is a powerful tool for analysis of relevant features of the source component of speech signals",
	author = "D'Alessandro, C. and Yegnanarayana, B. and Darsinos, V.",
	booktitle = "{Acoustics, Speech, and Signal Processing, 1995. ICASSP-95., 1995 International Conference on}",
	doi = "10.1109/ICASSP.1995.479805",
	issn = "1520-6149",
	keywords = "cepstrum; deterministic component; deterministic glottal pulses; deterministic signals; excitation component; filter component; frequency regions identification; glottal closure; iterative algorithm; iterative signal reconstruction; linear predictive analysis; noise bursts; overlap-add procedure; reconstructed frames; speech features analysis; speech signals decomposition; stochastic component; stochastic signals; time varying all-pole filter; all-pass filters; cepstral analysis; filtering theory; iterative methods; prediction theory; signal reconstruction; speech processing; stochastic processes; time-varying filters",
	lockkey = "Y",
	month = "may",
	pages = "760--763 vol.1",
	title = "{Decomposition of speech signals into deterministic and stochastic components}",
	volume = "1",
	year = "1995"
}

@article{ZhouG2001,
	abstract = "Studies have shown that variability introduced by stress or emotion can severely reduce speech recognition accuracy. Techniques for detecting or assessing the presence of stress could help improve the robustness of speech recognition systems. Although some acoustic variables derived from linear speech production theory have been investigated as indicators of stress, they are not always consistent. Three new features derived from the nonlinear Teager (1980) energy operator (TEO) are investigated for stress classification. It is believed that the TEO based features are better able to reflect the nonlinear airflow structure of speech production under adverse stressful conditions. The features proposed include TEO-decomposed FM variation (TEO-FM-Var), normalized TEO autocorrelation envelope area (TEO-Auto-Env), and critical band based TEO autocorrelation envelope area (TEO-CB-Auto-Env). The proposed features are evaluated for the task of stress classification using simulated and actual stressed 
speech and it is shown that the TEO-CB-Auto-Env feature outperforms traditional pitch and mel-frequency cepstrum coefficients (MFCC) substantially. Performance for TEO based features are maintained in both text-dependent and text-independent models, while performance of traditional features degrades in text-independent models. Overall neutral versus stress classification rates are also shown to be more consistent across different stress styles",
	author = "Zhou, G. and Hansen, J.H.L. and Kaiser, J.F.",
	doi = "10.1109/89.905995",
	issn = "1063-6676",
	journal = "Speech and Audio Processing, IEEE Trans. on",
	keywords = "TEO autocorrelation envelope area; TEO-decomposed FM variation; acoustic variables; actual stressed speech; critical band; emotion; linear speech production theory; mel-frequency cepstrum coefficients; nonlinear Teager energy operator; nonlinear airflow structure; nonlinear feature based speech classification; normalized TEO autocorrelation envelope area; simulated stressed speech; speech production; speech recognition systems; stress classification rates; text-dependent models; text-independent models; cepstral analysis; correlation methods; mathematical operators; signal classification; speech recognition",
	lockkey = "Y",
	month = "mar",
	number = "3",
	pages = "201--216",
	title = "{Nonlinear feature based classification of speech under stress}",
	volume = "9",
	year = "2001"
}

@book{FantG1970,
	author = "Fant, Gunnar",
	lockkey = "Y",
	publisher = "Mouton, The Hague",
	title = "{Acoustic theory of speech production}",
	year = "1970"
}

@misc{SHawkins2008,
	annote = "tutorial",
	author = "Hawkins, Sarah",
	lockkey = "Y",
	title = "{ACOUSTIC THEORY OF SPEECH PRODUCTION SUPPLEMENT TO AND EXTENSION OF PAPER 3 LECTURES}",
	year = "2008"
}

@inproceedings{SchnellK2010,
	author = "Schnell, Karl",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{A combined time-varying and time-invariant prediction algorithm based on lattice filters for speech analysis and synthesis}",
	year = "2010"
}

@article{GrayAH1974,
	abstract = {The purpose of this paper is to introduce a spectral-flatness measure into the study of linear prediction analysis of speech. A spectral-flatness measure is introduced to give a quantitative measure of "whiteness," of a spectrum. It is shown that maximizing the spectral flatness of an inverse filter output or linear predictor error is equivalent to the autocorrelation method of linear prediction. Theoretical properties of the flatness measure are derived, and compared with experimental results. It is shown that possible ill-conditioning of the analysis problem is directly related to the spectral-flatness measure and that prewhitening by a simple first-order linear predictor to increase spectral flatness can greatly reduce the amount of ill-conditioning.},
	author = "Gray, A. Jr. and Markel, J.",
	doi = "10.1109/TASSP.1974.1162572",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "N",
	number = "3",
	pages = "207--217",
	title = "{A spectral-flatness measure for studying the autocorrelation method of linear prediction of speech analysis}",
	volume = "22",
	year = "1974"
}

@inproceedings{MoisikSR2008,
	abstract = "The aryepiglottic folds are shown to play a central role in the formation of sounds exhibiting laryngeal constriction (Esling 1996, 1999a, 1999b, 2002, 2005; Esling \& Clayards 1999; Esling, Carlson, \& Harris 2002; Edmondson \& Esling 2005; Esling \& Harris 2005; Esling, Fraser, \& Harris 2005; Esling, Zeroual, \& Crevier-Buchman 2007; Edmondson, Padayodi, Hassan, \& Esling 2007). The aryepiglottic sphincter mechanism functions both as an articulator, and as a sound source when the folds are set into a trilling motion. The properties of this trilling function are not widely documented; a handful of accounts describe the trilling of the aryepiglottic folds to occur at double the frequency of the vocal folds (Sakakibara et al. 2004a, 2004b). In the present research, high-speed video of voiced aryepiglottic trilling was analyzed to extract vital information about the trilling process that was used to construct a biomechanical model. This biomechanical model is integrated into a 3D computer model 
of the larynx, with the ultimate goal of visually synthesizing the laryngeal movements of sounds that feature laryngeal constriction. The model features a biomechanical simulation of the vocal folds inspired by Titze{\rq}s (1973, 1974) mathematical formulation, and the output of this simulation serves as input to the aryepiglottic one.",
	author = "Esling, J. H. and Moisik, S. R. and Crevier-Buchman, L.",
	booktitle = "{Proc. International Conference on Voice Physiology and Biomechanics (ICVPB)}",
	lockkey = "Y",
	pages = "90--112",
	title = "{A Biomechanical Model of Aryepiglottic Trilling}",
	year = "2008"
}

@article{MakhoulJ1975,
	abstract = "This paper gives an exposition of linear prediction in the analysis of discrete signals. The signal is modeled as a linear combination of its past values and present and past values of a hypothetical input to a system whose output is the given signal. In the frequency domain, this is equivalent to modeling the signal spectrum by a pole-zero spectrum. The major part of the paper is devoted to all-pole models. The model parameters are obtained by a least squares analysis in the time domain. Two methods result, depending on whether the signal is assumed to be stationary or nonstationary. The same results are then derived in the frequency domain. The resulting spectral matching formulation allows for the modeling of selected portions of a spectrum, for arbitrary spectral shaping in the frequency domain, and for the modeling of continuous as well as discrete spectra. This also leads to a discussion of the advantages and disadvantages of the least squares error criterion. A spectral interpretation is 
given to the normalized minimum prediction error. Applications of the normalized error are given, including the determination of an ``optimal'' number of poles. The use of linear prediction in data compression is reviewed. For purposes of transmission, particular attention is given to the quantization and encoding of the reflection (or partial correlation) coefficients. Finally, a brief introduction to pole-zero modeling is given.",
	author = "Makhoul, J.",
	issn = "0018-9219",
	journal = "Proceedings of the IEEE",
	lockkey = "Y",
	number = "4",
	pages = "561--580",
	title = "{Linear prediction: A tutorial review}",
	volume = "63",
	year = "1975"
}

@inproceedings{SchroederM1985,
	abstract = "We describe in this paper a code-excited linear predictive coder in which the optimum innovation sequence is selected from a code book of stored sequences to optimize a given fidelity criterion. Each sample of the innovation sequence is filtered sequentially through two time-varying linear recursive filters, one with a long-delay (related to pitch period) predictor in the feedback loop and the other with a short-delay predictor (related to spectral envelope) in the feedback loop. We code speech, sampled at 8 kHz, in blocks of 5-msec duration. Each block consisting of 40 samples is produced from one of 1024 possible innovation sequences. The bit rate for the innovation sequence is thus 1/4 bit per sample. We compare in this paper several different random and deterministic code books for their effectiveness in providing the optimum innovation sequence in each block. Our results indicate that a random code book has a slight speech quality advantage at low bit rates. Examples of speech produced by 
the above method will be played at the conference.",
	author = "Schroeder, M. and Atal, B.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	pages = "937--940",
	title = "{Code-excited linear prediction ({CELP}): High-quality speech at very low bit rates}",
	year = "1985"
}

@article{Roebel2007a,
	abstract = "In this work, we investigate spectral envelope estimation for harmonic signals. We address the issue of model order selection and propose to make use of the fact that the spectral envelope is sampled by means of the harmonic structure of the signal in order to derive upper bounds for the estimator order. An experimental study is performed using synthetic test signals with various fundamental frequencies and different model structures to evaluate the performance of the envelope models. Experimental results confirm the relation between optimal model order and fundamental frequency.",
	author = "Roebel, A. and Villavicencio, F. and Rodet, X.",
	doi = "10.1016/j.patrec.2006.11.021",
	issn = "0167-8655",
	journal = "Pattern Recognition Letters",
	keywords = "Speech synthesis",
	lockkey = "Y",
	number = "11",
	pages = "1343--1350",
	title = "{On cepstral and all-pole based spectral envelope modeling with unknown model order}",
	url = "http://www.sciencedirect.com/science/article/B6V15-4NC38M7-4/2/48d020326f0427a9cceca1c8ee82d321",
	volume = "28",
	year = "2007"
}

@article{AkaikeH1974,
	abstract = "The history of the development of statistical hypothesis testing in time series analysis is reviewed briefly and it is pointed out that the hypothesis testing procedure is not adequately defined as the procedure for statistical model identification. The classical maximum likelihood estimation procedure is reviewed and a new estimate minimum information theoretical criterion (AIC) estimate (MAICE) which is designed for the purpose of statistical identification is introduced. When there are several competing models the MAICE is defined by the model and the maximum likelihood estimates of the parameters which give the minimum of AIC defined by AIC = (-2)log-(maximum likelihood) + 2(number of independently adjusted parameters within the model). MAICE provides a versatile procedure for statistical model identification which is free from the ambiguities inherent in the application of conventional hypothesis testing procedure. The practical utility of MAICE in time series analysis is demonstrated with 
some numerical examples.",
	author = "Akaike, H.",
	issn = "0018-9286",
	journal = "Automatic Control, IEEE Trans. on",
	keywords = "Parameter identification; Time series; maximum-likelihood (ML) estimation",
	lockkey = "Y",
	month = "dec",
	number = "6",
	pages = "716--723",
	title = "{A new look at the statistical model identification}",
	volume = "19",
	year = "1974"
}

@article{SteiglitzK1977,
	abstract = "Kopec, Oppenheim, and Tribolet have described a homomorphic technique for producing, from a speech signal, a minimum-phase estimate of the vocal-tract impulse response. Once such an estimate has been obtained, the problem of modeling the vocal tract with a pole-zero model is a classical one in nonlinear estimation theory. It is shown in this paper that Shanks' method, Kalman's method, and the iterative prefiltering method are all different linearizations of the same nonlinear problem, and the iterative prefiltering method is proposed as an approach to estimating the poles and zeros of the vocal-tract transfer function simultaneously. A simulation is described which shows the advantage of estimating poles and zeros simultaneously rather than sequentially as in Shanks' method. A preliminary example of application to real speech is also given.",
	author = "Steiglitz, K.",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "3",
	pages = "229--234",
	title = "{On the simultaneous estimation of poles and zeros in speech analysis}",
	volume = "25",
	year = "1977"
}

@phdthesis{VillavicencioFM2010,
	author = "Villavicencio, Fernando Marquez",
	lockkey = "Y",
	school = "UPMC-Ircam",
	title = "{High-quality voice conversion}",
	year = "2010"
}

@misc{HaesW2003,
	author = "Xavier, Wim Haes and Rodet, Xavier",
	comment = "Cepstrum coefficients are widely used as features for both speech and music. In this paper, the use of discrete cepstrum coefficients is considered, which are computed from sinusoidal peaks in the short time spectrum. These coefficients are very interesting as features for pattern recognition applications since they allow to represent spectra by points in a multidimensional vector space. A new Mel frequency warping method is proposed that allows to compute the spectral envelope on the Mel scale which, by contrast to current estimation techniques, does not rely on manually set parameters. Furthermore, the robustness and perceptual relevance of the coefficients are studied and improved.",
	lockkey = "Y",
	title = "{Discrete Cepstrum Coefficients as Perceptual Features}",
	year = "2003"
}

@inproceedings{BannoH1998,
	abstract = "An efficient representation of short-time phase characteristics of speech sounds is proposed, based on findings which suggest the perceptual importance of phase characteristics. Subjective tests indicated that the synthesized speech sounds by the proposed method are indistinguishable from the original speech sounds with a moderate data compression. The proposed representation uses lower-order coefficients of the inverse Fourier transform of the group delay of speech. It also alleviates the voiced/unvoiced decision, which is an indispensable part in conventional speech coding algorithms. These features make our method potentially very useful in many applications like speech morphing",
	author = "Banno, H. and Lu, J. and Nakamura, S. and Shikano, K. and Kawahara, H.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1998.675401",
	issn = "1520-6149",
	keywords = "auditory perception; data compression; delays; fast Fourier transforms; FFT; hearing; inverse Fourier transform; inverse problems; low-order coefficients; reproduction quality; segmental SNR measure; short-time phase characteristics; short-time phase representation; signal representation; speech coding; speech coding algorithms; speech intelligibility; speech morphing; speech sounds; speech synthesis; subjective tests; synthesized speech sounds; time-domain analysis; time domain smoothed group delay; voiced/unvoiced decision",
	lockkey = "Y",
	pages = "861--864",
	title = "{Efficient representation of short-time phase based on group delay}",
	volume = "2",
	year = "1998"
}

@inproceedings{KawaharaH1997,
	abstract = "A simple new procedure called STRAIGHT (speech transformation and representation using adaptive interpolation of weighted spectrum) has been developed. STRAIGHT uses pitch-adaptive spectral analysis combined with a surface reconstruction method in the time-frequency region, and an excitation source design based on phase manipulation. It preserves the bilinear surface in the time-frequency region and allows for over 600\% manipulation of such speech parameters as pitch, vocal tract length, and speaking rate, without further degradation due to the parameter manipulation",
	author = "Kawahara, H.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1997.596185",
	keywords = "adaptive interpolation; adaptive signal processing; excitation source design; interpolation; parameter estimation; parameter manipulation; phase manipulation; pitch; pitch adaptive spectral analysis; signal reconstruction; signal representation; speaking rate; spectral analysis; speech coding; speech parameters; speech processing; speech quality; speech representation; speech transformation; STRAIGHT; surface reconstruction method; time-frequency analysis; time-frequency region; vocal tract length; vocoder; vocoders; weighted spectrum",
	lockkey = "Y",
	pages = "1303--1306",
	title = "{Speech representation and transformation using adaptive interpolation of weighted spectrum: vocoder revisited}",
	volume = "2",
	year = "1997"
}

@article{Lipshitz1982,
		title={On the Audibility of Midrange Phase Distortion in Audio Systems},
		author={Lipshitz, S. P. and Pocock, M. and Vanderkooy, J.},
		journal={J. Audio Eng. Soc},
		volume={30},
		number={9},
		pages={580--595},
		year={1982},
		}
		
@ARTICLE { DegottexG2011msp,
    AUTHOR = { G. Degottex and A. Roebel and X. Rodet },
    TITLE = { Phase minimization for glottal model estimation },
    JOURNAL = { IEEE Trans. on Acoustics, Speech and Language Processing },
    PUBLISHER = { IEEE },
    YEAR = { 2011 },
    VOLUME = { 19 },
    NUMBER = { 5 },
    PAGES = { 1080-1090 },
    MONTH = { July },
    KEYWORDS = { Glottal model , glottal closure instants (GCIs) , glottal shape , joint estimation , phase minimization , voice analysis },
    ABSTRACT = { In glottal source analysis, the phase minimization criterion has already been proposed to detect excitation instants. As shown in this article, this criterion can also be used to estimate the shape parameter of a glottal model (ex. Liljencrants-Fant model) and not only its time position. Additionally, we show that the shape parameter can be estimated independently of the glottal model position. The reliability of the proposed methods is evaluated with synthetic signals and compared to that of the IAIF and minimum/maximum-phase decomposition methods. The results of the methods are evaluated according to the influence of the fundamental frequency and noise. The estimation of a glottal model is useful for the separation of the glottal source and the vocal-tract filter and therefore can be applied in voice transformation, synthesis and also in clinical context or for the study of the voice production. },
    DOI = { 10.1109/TASL.2010.2076806 },
    LOCKKEY = { N },
}
		
@article{BannoH2002,
	author = "Banno, H. and Takeda, K. and Itakura, F.",
	journal = "Acoustical Science and Technology",
	lockkey = "Y",
	number = "1",
	pages = "1--9",
	title = "{The effect of group delay spectrum on timbre}",
	volume = "23",
	year = "2002"
}

@inproceedings{BonadaJ2008a,
	abstract = "In this paper we propose a method to estimate and transform harmonic components in wide-band conditions, out of a single period of the analyzed signal. This method allows estimating harmonic parameters with higher temporal resolution than typical Short Time Fourier Transform (STFT) based methods. We also discuss transformations and synthesis strategies in such context, focusing on the human voice.",
	author = "Bonada, J.",
	booktitle = "{Proc. Digital Audio Effects (DAFx)}",
	lockkey = "Y",
	title = "{Wide-band harmonic sinusoidal modeling}",
	year = "2008"
}

@phdthesis{BonadaJ2008,
	abstract = {<html><head><meta name="qrichtext" content="1" /></head><body style="font-size:8pt;font-family:Sans"> Singing voice is one of the most challenging musical instruments to model and imitate. Along several decades much research has been carried out to understand the mechanisms involved in singing voice production. In addition, from the very beginning of the sound synthesis techniques, singing has been one of the main targets to imitate and synthesize, and a large number of synthesizers have been created with that aim. The goal of this thesis is to build a singing voice synthesizer capable of reproducing the voice of a given singer, both in terms of expression and timbre, sounding natural and realistic, and whose inputs would be just the score and the lyrics of a song. This is a very difficult goal, and in this dissertation we discuss the key aspects of our proposed approach and identify the open issues that still need to be tackled. This dissertation substantially contributes to the field of 
singing voice synthesis: a) it critically discusses spectral processing techniques in the context of singing voice modeling, and provides significant improvements to the current state of the art; b) it applies the proposed techniques to other application contexts such as real-time voice transformations, museum installations or video games; c) it develops the concept of synthesis based on performance sampling as a way to model the sonic space produced by a performer with an instrument, focusing on the specific case of the singing voice; d) it proposes and implements a complete framework for singing voice synthesis; e) it explores the sonic space of the singing voice and proposes a procedure to model it; f) it discusses the issues involved in the creation of the synthesizer{\{\{\{\^a}}}}ÃÂÃÂs database and provide tools to automate its generation; g) it performs a qualitative evaluation of the synthesis results, comparing those to the state of the art and to real singer performance; h) it implements all the 
research results into an optimized software application for singing voice analysis, modeling, transformation and synthesis, including tools for database creation; i) a significant part of this research has been incorporated to a commercial singing voice software by Yamaha Corp. </body></html>},
	address = "Spain",
	author = "Bonada, Jordi",
	keywords = "Voice Processing; Voice Synthesis; Voice Transformation",
	lockkey = "Y",
	school = "Universitat Pompeu Fabra",
	title = "{Voice Processing and Synthesis by Performance Sampling and Spectral Models}",
	year = "2008"
}

@inproceedings{GalasT1990,
	author = "Galas, T. and Rodet, X.",
	booktitle = "{Proc. Computer Music ({ICMC})}",
	keywords = "discrete cepstrum",
	lockkey = "Y",
	title = "{An improved cepstral method for deconvolution of source-filter systems with discrete spectra: Application to musical sound signals}",
	year = "1990"
}

@inproceedings{GalasT1991,
	author = "Galas, T. and Rodet, X.",
	booktitle = "{Applications of Signal Processing to Audio and Acoustics, 1991. Final Program and Paper Summaries., 1991 IEEE ASSP Workshop on}",
	lockkey = "Y",
	month = "20-23",
	pages = "0\_71--0\_72",
	title = "{Generalized Discrete Cepstral Analysis for Deconvolution of Source-Filter System with Discrete Spectra}",
	year = "1991"
}

@article{CoxMG1971,
	acknowledgement = ack-nhfb,
	author = "Cox, M. G.",
	bibdate = "Fri Sep 29 08:51:55 MDT 2000",
	bibsource = "http://www3.oup.co.uk/computer\_journal/hdb/Volume\_14/Issue\_03/",
	classcodes = "C4130 (Interpolation and function approximation)",
	coden = "CMPJA6",
	corpsource = "Nat. Phys. Lab., Teddington, UK",
	issn = "0010-4620",
	journal = j-COMP-J,
	keywords = "analogue computers; approximating convex functions; approximation; convergence of numerical methods; design of diode function generators; equivalent linear; errors; first degree splines; free; function; knots; maximum error; minimax approximations; nonlinear programming problems; numerical construction; possessing quadratic convergence; programming problems; splines (mathematics); strictly convex functions",
	lockkey = "Y",
	month = aug,
	number = "3",
	pages = "272--275",
	title = "{An algorithm for approximating convex functions by means of first degree splines}",
	treatment = "T Theoretical or Mathematical",
	url = "http://www3.oup.co.uk/computer_journal/hdb/Volume_14/Issue_03/140272.sgm.abs.html; http://www3.oup.co.uk/computer_journal/hdb/Volume_14/Issue_03/tiff/272.tif; http://www3.oup.co.uk/computer_journal/hdb/Volume_14/Issue_03/tiff/273.tif; http://www3.oup.co.uk/computer_journal/hdb/Volume_14/Issue_03/tiff/274.tif; http://www3.oup.co.uk/computer_journal/hdb/Volume_14/Issue_03/tiff/275.tif",
	volume = "14",
	year = "1971"
}

@inproceedings{CappeO1995,
	abstract = "This paper presents an improved method for the estimation of a continuous frequency-envelope when the value of this envelope is speciÃ¯Â¬Âed only at discrete frequencies. It is based on the Galas/Rodet approach which consists of Ã¯Â¬Âtting a cepstral amplitude envelope to the speciÃ¯Â¬Âed frequency points by minimizing a frequency-domain least-squares criterion. This paper introduces a regularization tech- nique which increases the robustness of the estimation procedure. Used in combination with a warped frequency-scale, the proposed method is shown to provide an efÃ¯Â¬Âcient model for the frequency envelope of speech signals.",
	author = "{O. Capp{\'e}}, J. Laroche E. Moulines",
	booktitle = "{IEEE ASSP Workshop on applications of signal processing to audio and acoustic (WASPAA)}",
	lockkey = "Y",
	title = "{Regularized Estimation of Cepstrum Envelope from Discrete Frequency Points}",
	year = "1995"
}

@article{AnanthapadmanabhaTV1979,
	abstract = "In voiced speech analysis epochal information is useful in accurate estimation of pitch periods and the frequency response of the vocal tract system. Ideally, linear prediction (LP) residual should give impulses at epochs. However, there are often ambiguities in the direct use of LP residual since samples of either polarity occur around epochs. Further, since the digital inverse filter does not compensate the phase response of the vocal tract system exactly, there is an uncertainty in the estimated epoch position. In this paper we present an interpretation of LP residual by considering the effect of the following factors: 1) the shape of glottal pulses, 2) inaccurate estimation of formants and bandwidths, 3) phase angles of formants at the instants of excitation, and 4) zeros in the vocal tract system. A method for the unambiguous identification of epochs from LP residual is then presented. The accuracy of the method is tested by comparing the results with the epochs obtained from the estimated 
glottal pulse shapes for several vowel segments. The method is used to identify the closed glottis interval for the estimation of the true frequency response of the vocal tract system.",
	author = "Ananthapadmanabha, T. and Yegnanarayana, B.",
	doi = "10.1109/TASSP.1979.1163267",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "4",
	pages = "309--319",
	title = "{Epoch extraction from linear prediction residual for identification of closed glottis interval}",
	volume = "27",
	year = "1979"
}

@article{MooreE2008,
	abstract = "Automatic glottal waveform estimation remains a challenging problem in speech analysis. Developing criteria for the objective assess- ment of the quality of glottal waveform estimates would facilitate the design of more robust estimation algorithms. The aim of this paper is to investigate the performance of potential glottal waveform quality measures (GQM{\rq}s) and to determine whether a combination of these GQM{\rq}s is able to consistently provide an accurate assessment of glottal waveform estimate quality across several speakers and pho- nemes. We develop an experimental setup that produces disjoint sets of high and low-quality glottal waveform estimates from real speech and use this data to objectively assess the performance of 12 glottal waveform quality measures on a sustained vowel speech dataset spanning 16 male speakers and 3 phonemes. In addition, we present a rank-based method (RB-GQA) that allows arbitrary GQM subsets to be eÃ¯Â¬Âectively combined. Using this method, we perform an 
exhaustive search on the GQM subset space to determine the best-perform- ing GQM combinations for diÃ¯Â¬Âerent groups of speakers and phonemes. While it was found that the optimal GQM combinations are speaker and phoneme dependent, optimization across all utterances (speaker--phoneme pairs) resulted in a combination of 4 GQM{\rq}s (ratio of Ã¯Â¬Ârst harmonic to maximum harmonic over 0--3.7 kHz, group delay variance, phase-plane cycles/period, and phase-plane mean sub-cycle length) that performed very well on almost every utterance in the dataset and nearly matched the performance of the GQM subsets obtained via phoneme-dependent optimization.",
	author = "Moore, E. and Torres, J.",
	journal = "Speech Communication",
	lockkey = "Y",
	number = "1",
	pages = "56--66",
	title = "{A performance assessment of objective measures for evaluating the quality of glottal waveform estimates}",
	volume = "50",
	year = "2008"
}

@article{ColemanTF1993,
	abstract = "We propose a new trust region approach for minimizing a nonlinear function subject to simple bounds. Unlike most existing methods, our proposed method does not require that a quadratic programming subproblem, with inequality constraints, be solved in each iteration. Instead, a solution to a trust region subproblem is defined by minimizing a quadratic function subject only to an ellipsoidal constraint. The iterates generated are strictly feasible. Our proposed method reduces to a standard trust region approach for the unconstrained problem when there are no upper or lower bounds on the variables. Global and local quadratic convergence is established. Preliminary numerical experiments are reported indicating the practical viability of this approach.",
	author = "Coleman, T. F. and Li, Yuying",
	journal = "SIAM J. Control and Optimization",
	lockkey = "Y",
	number = "2",
	pages = "418--445",
	title = "{An Interior Trust Region Approach for Nonlinear Minimization Subject to Bounds}",
	volume = "6",
	year = "1993"
}

@inproceedings{HedelinP1988,
	abstract = "General methods are discussed for estimating a phase model in the context of all-pole analysis of speech. An optimal estimator is presented for the case in which the phase model is a strict all-pass filter. It is shown that the solution to this estimation problem is very close to that obtained by established methods of linear prediction. As a complement, discrete Fourier transform methods for the phase modeling are briefly discussed and evaluated. Experience with the algorithms is presented, including results for applications to glottal-inverse filtering and speech coding",
	author = "Hedelin, P.",
	booktitle = "{Acoustics, Speech, and Signal Processing, 1988. ICASSP-88., 1988 International Conference on}",
	doi = "10.1109/ICASSP.1988.196585",
	issn = "1520-6149",
	keywords = "all-pass filter; all-pole analysis; discrete Fourier transform methods; glottal-inverse filtering; optimal estimator; phase compensation; speech analysis; speech coding; encoding; filtering and prediction theory; speech analysis and processing",
	lockkey = "Y",
	month = "11-14",
	pages = "339--342 vol.1",
	title = "{Phase compensation in all-pole speech analysis}",
	year = "1988"
}

@article{AhmadiS1998,
	abstract = "A phase modeling algorithm for sinusoidal analysis-synthesis of speech is presented, where short-time sinusoidal phases are approximated using a combination of linear prediction, spectral sampling, delay compensation, and phase correction techniques. The algorithm is different to phase compensation methods proposed for source-system LPC in that it has been tailored to sinusoidal representation of speech. Performance analysis on a large speech data base reveals an improvement in temporal and spectral signal matching, as well as in the subjective quality of reconstructed speech. The method can be applied to enhance phase matching in low bit rate sinusoidal coders, where underlying sine wave amplitudes are extracted from an all-pole model. Preliminary subjective results are presented for a 2.4 kb/s sinusoidal coder",
	author = "Ahmadi, S. and Spanias, A.S.",
	doi = "10.1109/89.709675",
	issn = "1063-6676",
	journal = "Speech and Audio Processing, IEEE Trans. on",
	keywords = "2.4 kbit/s; all-pole model; delay compensation; linear prediction; low bit rate sinusoidal coders; performance analysis; phase correction techniques; phase matching; phase model; phase modeling algorithm; reconstructed speech; short-time sinusoidal phases; sine wave amplitudes; sinusoidal analysis-synthesis; sinusoidal representation; sinusoidal transform coding; spectral sampling; spectral signal matching; subjective quality; temporal signal matching; delays; linear predictive coding; spectral analysis; speech coding; transform coding",
	lockkey = "Y",
	month = "sep",
	number = "5",
	pages = "495--501",
	title = "{A new phase model for sinusoidal transform coding of speech}",
	volume = "6",
	year = "1998"
}

@inproceedings{FunakiK1996,
	author = "{K. Funaki}, Y. Miyanaga K. Tochinai",
	booktitle = "{Proc. 3rd Joint Meeting Between ASA. and ASJ.}",
	lockkey = "Y",
	pages = "1267--1271",
	title = "{A time-varying ARMAX speech analysis method based on glottal source model}",
	year = "1996"
}

@article{HawksJW1995,
	abstract = "Thespecification vowel of formantbandwidths .Ã¢ÂÂ¢peech for synthesis been haÃ¢ÂÂ¢ inconsistent thepast,perhaps in due to thedifficulty measuring of ]brmant bandwidths naturalspeech thepossible in and perceptual insignificanceof formantbandwidths the intelligibility synthetic on of speech. Here, regres- sionequations presented theestimation formantbandwidth.Ã¢ÂÂ¢ are for of based on measurements naturalspeech from whichis based onlyonformamcenter frequencyand independent otherformantvalues.Currentusage,as well of as comparison anotherwell-known with estimationalgorithm sugge.;tsthat the new procedureshouldbe quite acceptable some typesof speech for synthesis.",
	author = "Hawks, J. W. and Miller, J. D.",
	doi = "10.1121/1.412986",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "2",
	pages = "1343--1344",
	publisher = "ASA",
	title = "{A formant bandwidth estimation procedure for vowel synthesis}",
	url = "http://link.aip.org/link/?JAS/97/1343/1",
	volume = "97",
	year = "1995"
}

@misc{Straka,
	author = "Straka",
	lockkey = "Y",
	note = "formant vowels"
}

@inproceedings{AlkuP1994,
	abstract = "A new inverse filtering technique for the estimation of the glottal excitation is presented in this study. The method is based on the application of a new algorithm, called Discrete All-pole Modeling (DAP), used in the estimation of the vocal tract transfer function. The paper presents results that were obtained from natural and synthetic vowels of different phonation types and fundamental frequencies. It was found that estimated glottal waveforms comprised less formant ripple when the inverse filtering analysis was performed with the DAP-technique instead of conventional linear prediction. Glottal waveforms computed from natural female voices were also characterized by longer glottal closed phases when the DAP-technique was used.",
	author = "Alku, P. and Vilkman, E.",
	booktitle = "{Proc. International Conference on Spoken Language Processing (ICSLP)}",
	lockkey = "Y",
	pages = "1619--1622",
	title = "{Estimation of the Glottal Pulseform Based on Discrete All-Pole Modeling}",
	year = "1994"
}

@article{AlkuP1992,
	abstract = "A new glottal wave analysis method, Pitch Synchronous Iterative Adaptive Inverse Filtering (PSIAIF) is presented. The algorithm is based on a previously developed method, Iterative Adaptive Inverse Filtering (IAIF). In the IAIF-method the glottal contribution to the speech spectrum is first estimated with an iterative structure. The vocal tract transfer function is modeled after eliminating the average glottal contribution. The glottal excitation is obtained by cancelling the effects of the vocal tract and lip radiation by inverse filtering. In the new PSIAIF-method the glottal pulseform is computed by applying the IAIF-algorithm twice to the same signal. The first IAIF-analysis gives as a result a glottal excitation that spans over several pitch periods. This pulseform is used in order to determine positions and lengths of frames for the pitch synchronous analysis. The final result is obtained by analysing the original speech signal with the IAIF-algorithm one fundamental period at a time. The 
PSIAIF-algorithm was applied in glottal wave analysis using both synthetic and natural vowels. The results show that the method is able to give a fairly accurate estimate for the glottal flow excluding the analysis of vowels with a low first formant that are produced with a pressed phonation type.",
	address = "Amsterdam, The Netherlands, The Netherlands",
	author = "Alku, P.",
	doi = "10.1016/0167-6393(92)90005-R",
	issn = "0167-6393",
	journal = "Speech Communication",
	lockkey = "Y",
	number = "2-3",
	pages = "109--118",
	publisher = "Elsevier Science Publishers B. V.",
	title = "{Glottal wave analysis with Pitch Synchronous Iterative Adaptive Inverse Filtering}",
	volume = "11",
	year = "1992"
}

@article{SundbergJ1997,
	abstract = "The normalized amplitude quotient (NAQ), defined as the ratio between the peak-to-peak amplitude of the flow pulse and the negative peak amplitude of the differentiated flow glottogram and normalized with respect to period time, has been shown to be related to glottal adduction. Glottal adduction, in turn, affects mode of phonation and hence perceived phonatory pressedness. The relationship between NAQ and perceived phonatory pressedness was analyzed in a material collected from a professional female singer and singing teacher who sang a triad pattern in breathy, flow, neutral, and pressed phonation in three different loudness conditions (soft, middle, loud). In addition, she also sang the same triad pattern in four different styles of singing, classical, pop, jazz, and blues, in the same three loudness conditions. A panel of experts rated the degree of perceived phonatory press along visual analogue scales. Comparing the obtained mean rated pressedness ratings with the mean NAQ values for the 
various triads showed that about 73\% of the variation in perceived pressedness could be accounted for by variations of NAQ.",
	author = "{Johan Sundberg}, Margareta Thal{\'e}n Paavo Alku Erkki Vilkman",
	doi = "10.1016/j.jvoice.2003.05.006",
	journal = "The Journal of voice",
	keywords = "Phonation mode; Flow glottogram; Singing styles; Perceived pressedness; Normalized amplitude quotient NAQ",
	lockkey = "Y",
	number = "1",
	pages = "56--62",
	title = "{Estimating perceived phonatory pressedness in singing from flow glottograms}",
	volume = "18",
	year = "1997"
}

@article{SundbergJ2002,
	abstract = "The normalized amplitude quotient (NAQ), defined as the ratio between the peak- to-peak amplitude of the flow pulse and the negative peak amplitude of the differentiated flow glottogram and normalized with respect to period time, has been shown to be related to glottal adduction. Glottal adduction, in turn, affects mode of phonation and hence perceived phonatory pressedness. The relationship between NAQ and perceived phonatory pressedness was analyzed in a material collected from a professional female singer and singing teacher who sang a triad pattern in breathy, flow, neutral and pressed phonation in three different loudness conditions (soft, middle, loud). In addition, she also sang the same triad pattern in four different styles of singing, classical, pop, jazz and blues, in the same three loudness conditions. A panel of nine experts rated the degree of perceived phonatory press along visual analogue scales. Comparing the obtained mean rated pressedness ratings with the mean NAQ values for 
the various triads showed that about 73\% of the variation in perceived pressedness could be accounted for by variations of NAQ.",
	author = "Sundberg, J. and Thalen, M. and Alku, P. and Vilkman, Erkki",
	journal = "TMH-QPSR",
	lockkey = "Y",
	number = "1",
	pages = "89--96",
	title = "{Estimating perceived phonatory pressedness in singing from flow glottograms}",
	volume = "43",
	year = "2002"
}

@inproceedings{HenrichN2001a,
	abstract = "The effects of voice open quotient and glottal waveform asymmetry are studied in the spectral domain. The hypothesis that the amplitude difference of the Ã¯Â¬Ârst and second harmon- ics of the inverse-Ã¯Â¬Âltered voice signal (H1*-H2*) is a reliable spectral correlate of the open quotient is tested. Theoretical ar- guments and experiments are reported. In the theoretical part, analytical formulas are derived for the spectrum of several mod- els (LF, R++, KLGLOTT88). Then it is shown that H1*-H2* is generally dependent on both open quotient and asymmetry. Domains for open quotient, asymmetry and H1*-H2* varia- tions are given. In the experimental part, examples of voice and singing signals are analyzed. It is shown that a signiÃ¯Â¬Âcant part of the spectral measurements obtained are out of the scope of the models studied.",
	author = "Henrich, N. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Doval, B.",
	booktitle = "{Proc. Eurospeech}",
	lockkey = "Y",
	pages = "47--50",
	title = "{Spectral correlates of voice open quotient and glottal flow asymmetry: theory, limits and experimental data}",
	year = "2001"
}

@article{SteiglitzK1965,
	abstract = "An iterative technique is proposed to identify a linear system from samples of its input and output in the presence of noise by minimizing the mean-square error between system and model outputs. The model chosen has a transfer function which is a ratio of polynomials in z-1. Although the regression equations for the optimal set of coefficients are highly nonlinear and intractable, it is shown that the problem can be reduced to the repeated solution of a related linear problem. Computer simulation of a number of typical discrete systems is used to demonstrate the considerable improvement over the Kalman estimate which can be obtained in a few iterations. The procedure is found to be effective at signal-to-noise ratios less than unity, and with as few as 200 samples of the input and output records.",
	author = "Steiglitz, K. and McBride, L.",
	issn = "0018-9286",
	journal = "Automatic Control, IEEE Trans. on",
	keywords = "Linear systems; System identification",
	lockkey = "Y",
	month = "oct",
	number = "4",
	pages = "461--464",
	title = "{A technique for the identification of linear systems}",
	volume = "10",
	year = "1965"
}

@article{LichtenbergerW1961,
	abstract = "A technique for measuring the impulse response of linear processes while they are on line is described. Such an identification of process dynamics is necessary in process-adaptive control systems. A testing signal and correlating filter are employed after the manner of Turin. Such a procedure requires no multiplier, and the output of the filter is the impulse response as a continuous function of real time. To reduce accompanying output noise, the method of adding coherently the results of a number of tests made in succession is proposed. This idea is applied to the measurement of a member of an ensemble of slowly varying impulse responses. Optimum design of both the correlating filter and the necessary test signal is determined on the basis of minimum mean-square error of the resulting estimate. The optimization of the number of tests to be included in a measurement is described. The general results are applied to the case of a single, slowly time-varying process. In addition to optimum design, 
normalized curves showing the optimum number of tests for a particular mode of variation are included. A second application is made to the problem of measuring a member of an ensemble of fixed processes. The results of a digital computer simulation of this case are given.",
	author = "Lichtenberger, W.",
	issn = "0096-199X",
	journal = "Automatic Control, IRE Trans. on",
	lockkey = "Y",
	month = "may",
	number = "2",
	pages = "183--199",
	title = "{A technique of linear system identification using correlating filters}",
	volume = "6",
	year = "1961"
}

@article{AtalBS1971,
	author = "Atal, B. S. and Hanauer, S. L.",
	doi = "10.1121/1.1912679",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "2B",
	pages = "637--655",
	publisher = "ASA",
	title = "{Speech Analysis and Synthesis by Linear Prediction of the Speech Wave}",
	url = "http://link.aip.org/link/?JAS/50/637/1",
	volume = "50",
	year = "1971"
}

@misc{Kameoka2010,
	author = "Kameoca",
	lockkey = "Y",
	year = "2010"
}

@misc{GrayRM2007,
	lockkey = "Y",
	note = "heads pictures arpanet",
	title = "{Packet speech on the Arpanet: A history of early LPC speech and its accidental impact on the Internet Protocol}",
	year = "2007"
}

@article{ChildersDG1986,
	abstract = "The electroglottogram (EGG) has been conjectured to be related to the area of contact between the vocal folds. This hypothesis has been substantiated only partially via direct and indirect observations. In this paper, a simple model of vocal fold vibratory motion is used to estimate the vocal fold contact area as a function of time. This model employs a limited number of vocal fold vibratory features extracted from ultra high-speed laryngeal films. These characteristics include the opening and closing vocal fold angles and the lag (phase difference) between the upper and lower vocal fold margins. The electroglottogram is simulated using the contact area, and the EGG waveforms are compared to measured EGGs for normal male voices producing both modal and pulse register tones. The model also predicts EGG waveforms for vocal fold vibration associated with a nodule or polyp.",
	author = "Childers, D. G. and Hicks, D. M. and Moore, G. P. and Alsaka, Y. A.",
	doi = "10.1121/1.394382",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "5",
	pages = "1309--1320",
	publisher = "ASA",
	title = "{A model for vocal fold vibratory motion, contact area, and the electroglottogram}",
	url = "http://link.aip.org/link/?JAS/80/1309/1",
	volume = "80",
	year = "1986"
}

@article{AlkuP2009,
	abstract = "Closed phase (CP) covariance analysis is a widely used glottal inverse filtering method based on the estimation of the vocal tract during the glottal CP. Since the length of the CP is typically short, the vocal tract computation with linear prediction (LP) is vulnerable to the covariance frame position. The present study proposes modification of the CP algorithm based on two issues. First, and most importantly, the computation of the vocal tract model is changed from the one used in the conventional LP into a form where a constraint is imposed on the dc gain of the inverse filter in the filter optimization. With this constraint, LP analysis is more prone to give vocal tract models that are justified by the source-filter theory; that is, they show complex conjugate roots in the formant regions rather than unrealistic resonances at low frequencies. Second, the new CP method utilizes a minimum phase inverse filter. The method was evaluated using synthetic vowels produced by physical modeling and 
natural speech. The results show that the algorithm improves the performance of the CP-type inverse filtering and its robustness with respect to the covariance frame position.",
	author = "Alku, Paavo and Magi, Carlo and Yrttiaho, Santeri and B{\"a}ckstr{\"o}m, Tom and Story, Brad",
	doi = "10.1121/1.3095801",
	journal = "Journal of the Acoustical Society of America",
	keywords = "biological organs; covariance analysis; inverse problems; physiological models; speech",
	lockkey = "Y",
	number = "5",
	pages = "3289--3305",
	publisher = "ASA",
	title = "{Closed phase covariance analysis based on constrained linear prediction for glottal inverse filtering}",
	url = "http://link.aip.org/link/?JAS/125/3289/1",
	volume = "125",
	year = "2009"
}

@article{YrttiahoS2009,
	abstract = "Aperiodicity of speech alters voice quality. The current study investigated the relationship between vowel aperiodicity and human auditory cortical N1m and sustained field (SF) responses with magnetoencephalography. Behavioral estimates of vocal roughness perception were also collected. Stimulus aperiodicity was experimentally varied by increasing vocal jitter with techniques that model the mechanisms of natural speech production. N1m and SF responses for vowels with high vocal jitter were reduced in amplitude as compared to those elicited by vowels of normal vocal periodicity. Behavioral results indicated that the ratings of vocal roughness increased up to the highest jitter values. Based on these findings, the representation of vocal jitter in the auditory cortex is suggested to be formed on the basis of reduced activity in periodicity-sensitive neural populations.",
	author = "Yrttiaho, Santeri and Alku, Paavo and May, Patrick J. C. and Tiitinen, Hannu",
	doi = "10.1121/1.3097471",
	journal = "Journal of the Acoustical Society of America",
	keywords = "magnetoencephalography; speech",
	lockkey = "Y",
	number = "5",
	pages = "3177--3185",
	publisher = "ASA",
	title = "{Representation of the vocal roughness of aperiodic speech sounds in the auditory cortex}",
	url = "http://link.aip.org/link/?JAS/125/3177/1",
	volume = "125",
	year = "2009"
}

@misc{BrookesMVoicebox,
	author = "Brookes, Mike",
	lockkey = "Y",
	month = "version of may",
	note = "http://www.ee.ic.ac.uk/hp/staff/dmb/voicebox/voicebox.html",
	title = "{Voicebox}",
	year = "2010"
}

@inproceedings{GalasT1989,
	author = "Galas, T. and Rodet, X.",
	booktitle = "{GRETSI}",
	keywords = "discrete cepstrum",
	lockkey = "Y",
	pages = "497--500",
	title = "{Une nouvelle m{\'e}thode d'estimation des spectres de puissance par un mod{\`e}le source-filtre: Application {\`a} l'analyse-synth{\`e}se de la parole}",
	year = "1989"
}

@inproceedings{HenrichN2002,
	author = "Henrich, N. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Doval, B.",
	booktitle = "{Forum Acusticum}",
	location = "Sevilla, Spain",
	lockkey = "Y",
	month = sep,
	title = "{Glottal flow models : waveforms, spectra and physical measurements}",
	year = "2002"
}

@inproceedings{iseliM2006,
	abstract = "The effects of age, gender, and vocal tract configurations on the glottal excitation signal are still only partially understood. In this paper we examine some of these effects, and show that the voice source parameters, such as fundamental frequency (Fo), open quotient (related to H*1 - H*2), and spectral tilt (related to H*1 - A*3) are not only affected by age and gender but are also intercorrelated (the asterisk superscript denotes correction for the influence of various formants). Recordings of 92 male and female speakers from three age groups (8, 15, 20-39) are analyzed. The main observations are: for low-pitched talkers H*1 - H* 2 (hence, the open quotient) is proportional to Fo, while for high-pitched talkers H*1 $H*2 is proportional to F1 (high to low vowels) for F1 lt; 700 Hz. The parameter H*1 - A*3 showed a strong dependence on F2 and F3 for all talkers and age groups: increasing F2 or F3 yielded an increase in H*1 - A*3. Spectral tilt was seen to be vowel dependent and for male 
talkers, spectral tilt changed dramatically with age. A better understanding of the dependencies of voice source parameters on age and gender will help improve voice source parameter estimation and analysis for a variety of speech processing and medical applications$",
	author = "Iseli, M. and Shue, Yen-Liang and Alwan, A.",
	booktitle = "{Acoustics, Speech and Signal Processing, 2006. ICASSP 2006 Proceedings. 2006 IEEE International Conference on}",
	doi = "10.1109/ICASSP.2006.1660039",
	issn = "1520-6149",
	keywords = "15 year; 20 to 39 year; 8 year; age-dependent analysis; female speakers; gender-dependent analysis; glottal excitation signal; low-pitched talkers; male speakers; medical applications; spectral tilt; speech processing; vocal tract configurations; voice source characteristics; voice source parameters",
	lockkey = "N",
	month = "14-19",
	pages = "I--I",
	title = "{Age-and Gender-Dependent Analysis of Voice Source Characteristics}",
	volume = "1",
	year = "2006"
}

@article{Skoglund2000,
	abstract = "This paper addresses the issue of masking of noise in voiced speech. First, we examine the audibility of cyclostationary narrow-band noise bursts added to voiced speech generated by synthetic excitation. Varying the temporal location of noise within a pitch cycle corresponds to varying its phase spectrum. Using this fact, we found that a change of phase of the noise in the high frequency region is more perceptible for a low-pitched sound than for a high-pitched sound. We then propose a pitch-dependent temporal weighting function which can be employed in quantization of pitch cycle waveforms. In a second experiment, we found that the audibility of high-frequency noise added to natural speech can be significantly reduced using this weighting function",
	author = "Skoglund, J. and Kleijn, W. B.",
	doi = "10.1109/89.848218",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "cyclostationary narrow-band noise bursts audibility; experiment; high frequency region; high-frequency noise; high-pitched sound; low-pitched sound; natural speech; noise masking; phase spectrum; pitch cycle; pitch cycle waveform quantization; pitch-dependent temporal weighting function; speech coding; synthetic excitation; temporal location; time-frequency masking; voiced speech; noise; quantisation (signal); spectral analysis; speech coding; speech intelligibility; time-frequency analysis",
	lockkey = "Y",
	number = "4",
	pages = "361--369",
	title = "{On time-frequency masking in voiced speech}",
	volume = "8",
	year = "2000"
}

@article{DudleyH1939,
	abstract = "Speech has been remade automatically from a buzzer-like tone and a hiss-like noise corresponding to the cord-tone and the breath-tone of normal speech. Control of pitch and spectrum obtained from a talker's speech are applied to make the synthetic speech copy the original speech sufficiently for good intelligibility although the currents used in such controls contain only low syllabic frequencies of the order of 10 cycles per second as contrasted with frequencies of 100 to 3000 cycles in the remade speech. The isolation of these speech-defining signals of pitch and spectrum makes it possible to reconstruct the speech to a wide variety of specifications. Striking demonstrations upon altering the pitch of the remade speech stress the contribution of the pitch to the emotional content of speech. Similarly the spectrum is shown to contribute most of the intelligibility to the speech.",
	author = "Dudley, H.",
	doi = "10.1121/1.1916020",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "2",
	pages = "169--177",
	publisher = "ASA",
	title = "{Remaking Speech}",
	url = "http://link.aip.org/link/?JAS/11/169/1",
	volume = "11",
	year = "1939"
}

@article{StevensKN1953,
	abstract = "The design and construction of an electrical analog of the human vocal tract is described. The vocal tract is viewed as an acoustic tube of varying cross-sectional area, terminated by the vocal cords at one end and by the lip opening at the other. The analog is a lumped-constant electrical transmission line consisting of thirty-five pi-sections. Each section represents a (1/2)-cm length of the vocal tract and is adjustable to simulate a range of cross-sectional areas from 0.17 to 17 cm2. The electrical line can be excited by a periodic current source representing the vocal cord output or by a random voltage representing the noise from turbulent air flow at a constriction. The electrical analog can synthesize with good quality all English vowels and some consonants. The physical characteristics of the output of the analog for each sound are shown in terms of measured formant frequencies or by conventional spectrograms. For each sound, the vocal tract dimensions that the electrical network 
simulates are shown in graphical form. Applications of the speech synthesizer to linguistic and engineering research are discussed briefly.",
	author = "Stevens, K. N. and Kasowski, S. and Fant, C. Gunnar M.",
	doi = "10.1121/1.1907169",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "4",
	pages = "734--742",
	publisher = "ASA",
	title = "{An Electrical Analog of the Vocal Tract}",
	url = "http://link.aip.org/link/?JAS/25/734/1",
	volume = "25",
	year = "1953"
}

@article{StoryBH1994,
	abstract = "A simple, low-dimensional model of the body-cover vocal-fold structure is proposed as a research tool to study both normal and pathological vocal-fold vibration. It maintains the simplicity of a two-mass model but allows for physiologically relevant adjustments and separate vibration of the body and the cover. The classic two-mass model of the vocal folds [K. Ishizaka and J. L. Flanagan, Bell Syst. Tech. J. 51, 1233--1268 (1972)] has been extended to a three-mass model in order to more realistically represent the body-cover vocal-fold structure [M. Hirano, Folia Phoniar. 26, 89--94 (1974)]. The model consists of two ``cover'' masses coupled laterally to a ``body'' mass by nonlinear springs and viscous damping elements. The body mass, which represents muscle tissue, is further coupled laterally to a rigid wall (assumed to represent the thyroid cartilage) by a nonlinear spring and a damping element. The two cover springs are intended to represent the elastic properties of the epithelium and the 
lamina propria while the body spring simulates the tension produced by contraction of the thyroarytenoid muscle. Thus contractions of the cricothyroid and thyroarytenoid muscles are incorporated in the values used for the stiffness parameters of the body and cover springs. Additionally, the two cover masses are coupled to each other through a linear spring which can represent vertical mucosal wave propagation. Simulations show reasonable similarity to observed vocal-fold motion, measured vertical phase difference, and mucosal wave velocity, as well as experimentally obtained intraglottal pressure.",
	author = "Story, Brad H. and Titze, Ingo R.",
	doi = "10.1121/1.412234",
	journal = "Journal of the Acoustical Society of America",
	keywords = "VOCAL TRACT; VOCAL CORDS; VOICES; SPEECH PRODUCTION; SIMULATION; DAMPING; ELASTICITY; EPITHELIUM; MUSCLES; MECHANICAL VIBRATIONS; SPEECH SYNTHESIZERS",
	lockkey = "Y",
	number = "2",
	pages = "1249--1260",
	publisher = "ASA",
	title = "{Voice simulation with a body-cover model of the vocal folds}",
	url = "http://link.aip.org/link/?JAS/97/1249/1",
	volume = "97",
	year = "1995"
}

@article{PelorsonX1994,
	abstract = "The two-mass model is very often presented as a simple but efficient model quite well adapted for the purpose of voiced sounds numerical simulation. It appear however that the description of the flow through the glottis is usually oversimplified. To some extent this point could explain the limits of the model. This paper proposes a more precise description of the flow through the glottis. In particular a quasi-steady moving flow separation point is introduced. A validation of the theory under unsteady-flow conditions is presented here. The importance of the revised flow model for phonation modelling is evaluated and discussed using a simple model for the vocal cords based on the well-known two-mass model.",
	author = "Pelorson, X. and Hirschberg, A. and Auregn, Y.",
	journal = "Journal de Physique",
	lockkey = "Y",
	number = "C5",
	pages = "453--456",
	title = "{Modelling of voiced sounds production using a modified two-mass model}",
	volume = "4",
	year = "1994"
}

@phdthesis{LameschS2010,
	abstract = "Cette th{\`e}se porte sur l{\rq}inÃ¯Â¬Âuence de la voyelle sur les m{\'e}canismes laryng{\'e}s (M1 et M2) en voix chant{\'e}e. Nous avons observ{\'e} que les chanteurs associent le /a/ {\`a} M1 et le /i/ {\`a} M2. Nous avons alors cherch{\'e} des corr{\'e}lats physiologiques et acoustiques en {\'e}tudiant l{\rq}inÃ¯Â¬Âuence des voyelles sur les limites phon{\'e}tographiques, sur plusieurs param{\`e}tres de source et spectraux ainsi que sur les transitions des m{\'e}canismes. La limite sup{\'e}rieure des phon{\'e}togrammes est de 10 dB plus intense pour /a/ que pour /i/ en M1, mais pas en M2. Le phon{\'e}togramme de M2 est donc d{\'e}cal{\'e}, par rapport {\`a} celui de M1, vers les faibles niveaux pour /a/ mais pas pour /i/. Ce d{\'e}calage est d{\{\^u}} en partie {\`a} la diÃ¯Â¬Â{\'e}rence de valeurs de quotient ouvert entre M1 et M2. De plus, l{\rq}amplitude du signal {\'e}lectroglottographique augmente avec l{\rq}intensit{\'e} et est plus grande pour /i/ que pour /a/, r{\'e}v{\'e}lant des 
diÃ¯Â¬Â{\'e}rences glottiques de production de voyelles {\`a} m{\{\^e}}mes hauteur et intensit{\'e}. Les liens entre les voyelles et la position verticale du larynx d{\'e}pendent de l{\rq}expertise vocale des chanteurs. L{\rq}{\'e}tude de la r{\'e}partition de l{\rq}{\'e}nergie spectrale est eÃ¯Â¬Âectu{\'e}e en calculant le rapport de l{\rq}{\'e}nergie (ER) de la bande du formant du chanteur (FB2) ou des hautes fr{\'e}quences (FB3) {\`a} l{\rq}{\'e}nergie totale. Il est possible d{\rq}obtenir un formant du chanteur aussi intense en M2 qu{\rq}en M1. ER(FB2) peut saturer {\`a} haut niveau, en fonction de la voyelle, du m{\'e}canisme et de l{\rq}expertise vocale. ER(FB3) est plus faible en M2 qu{\rq}en M1. L{\rq}intervalle fr{\'e}quentiel des sauts M1Ã¢ÂÂM2 augmente avec l{\rq}intensit{\'e} mais pas avec la hauteur. Ceci n{\rq}est pas observ{\'e} dans le sens M2Ã¢ÂÂM1. La fr{\'e}quence de d{\'e}clenchement de la transition est plus basse pour /i/ que pour /a/. This dissertation concerns the inÃ¯Â¬Âuence 
of the vowel on the laryngeal mechanisms (M1 and M2) in singing voice. We observed that singers associate /a/ with M1 and /i/ with M2. We then searched for physiological and acoustical correlates by studying the inÃ¯Â¬Âuence of vowels on the Voice Range ProÃ¯Â¬Âle (VRP) on diÃ¯Â¬Âerent glottal and spectral parameters as well as the mechanisms{\rq} transitions. The upper VRP limit is 10 dB louder for /a/ than for /i/ in M1, but not in M2. The M2 VRP is therefore at a lower level when compared to the M1 VRP for /a/, but not for /i/. This shift is partly explained by diÃ¯Â¬Âerent open quotient values for M1 and M2. In addition, the amplitude of the electroglottographic signal increases with intensity and is larger for /i/ than for /a/, revealing glottal diÃ¯Â¬Âerences in the production of vowels at the same pitch and intensity. The inÃ¯Â¬Âuence of the vowel on the vertical larynx position depends on the vocal expertise of the singers. The spectral study is done by calculating the ratio (ER) between either 
the energy of the frequency band where the singer{\rq}s formant is located (FB2) or of the band corresponding to high frequencies (FB3) and the total energy. The energy of the singer{\rq}s formant can be as high in M2 as in M1. ER(FB2) can reach a saturation level depending on the vowel, the laryngeal mechanism, the vocal expertise. ER(FB3) is lower in M2 than in M1. The frequency jump that occurs in M1Ã¢ÂÂM2 transitions increases with level, but not with pitch. These correlations were not observed for M2Ã¢ÂÂM1 transitions. The starting frequency of the jumps is lower for /i/ than for /a/.",
	author = "Lamesch, Sylvain",
	key = "voix chant{\'e}e, m{\'e}canisme laryng{\'e}, registre, voyelle, phon{\'e}togramme, source glot- tique, formant du chanteur, saut de fr{\'e}quence; singing voice, laryngeal mechanism, register, vowel, Voice Range ProÃ¯Â¬Âle, glottal source, singer{\rq}s formant, frequency jump.",
	lockkey = "Y",
	school = "UPMC-Lam",
	title = "{M{\'e}canismes laryng{\'e}s et voyelles en voix chant{\'e}e}",
	year = "2010"
}

@article{StrikH1998,
	abstract = "The automatic parametrization of the Ã¯Â¬Ârst derivative of glottal Ã¯Â¬Âow is studied. Representatives of the two types of methods used most often for parametrization were tested and compared. The chosen representatives are all based on the Liljencrants--Fant model. As numerous tests were needed for a detailed comparison of the methods, a novel evaluation procedure is used which consists of the following stages: 1 use the Liljencrants--Fant model to generate synthetic Ã¯Â¬Âow pulses; 2 estimate voice source parameters for these synthetic Ã¯Â¬Âow pulses; and 3 calculate the errors by comparing the estimated values with the input values of the parameters. This evaluation procedure revealed that in order to reduce the average error in the estimated voice source parameters, the estimation methods should be able to estimate noninteger values of these parameters. The proposed evaluation method was also used to study the inÃ¯Â¬Âuence of low-pass Ã¯Â¬Âltering on the estimated voice source 
parameters. It turned out that low-pass Ã¯Â¬Âltering causes an error in all estimated voice source parameters. On average, the smallest errors were found for a parametrization method in which a voice source model is Ã¯Â¬Âtted to the Ã¯Â¬Âow derivative, and in which the voice source model is low-pass Ã¯Â¬Âltered with the same Ã¯Â¬Âlter as the Ã¯Â¬Âow derivative. ÃÂ© 1998 Acoustical Society of America.",
	author = "Strik, Helmer",
	doi = "10.1121/1.422786",
	journal = "Journal of the Acoustical Society of America",
	keywords = "speech; speech processing",
	lockkey = "Y",
	note = "Inverse filter comes from Miller (1959); optimize parameters using dUg is better; do not consider the inverse problem, only the fitting",
	number = "5",
	pages = "2659--2669",
	publisher = "ASA",
	title = "{Automatic parametrization of differentiated glottal flow: Comparing methods by means of synthetic flow pulses}",
	url = "http://link.aip.org/link/?JAS/103/2659/1",
	volume = "103",
	year = "1998"
}

@article{GriffinDW1988,
	abstract = "A speech model, referred to as the multiband excitation model, is presented. In this model the band around each harmonic of the fundamental frequency is declared voiced or unvoiced. Estimation methods for the parameters of the model are developed and methods to synthesize speech from the model parameters are described. To illustrate a potential application of the speech model, an 8 kb/s vocoder is developed and its performance is evaluated. Both informal listening and intelligibility tests show that the vocoder has very good performance both in speech quality and intelligibility, particularly for noisy speech.",
	author = "Griffin, D. W. and Lim, J. S.",
	doi = "10.1109/29.1651",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	keywords = "8 kbits/s; estimation method; fundamental frequency; harmonic; intelligibility tests; listening tests; multiband excitation model; noisy speech; speech intelligibility; speech model; speech quality; speech synthesis; vocoder; noise; speech analysis and processing; speech synthesis; vocoders",
	lockkey = "Y",
	number = "8",
	pages = "1223--1235",
	title = "{Multiband excitation vocoder}",
	volume = "36",
	year = "1988"
}

@inproceedings{PantazisY2010aqhnm,
	author = "Pantazis, Y. and Tzedakis, G. and Rosec, O. and Stylianou, Y.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	title = "{Analysis/Synthesis of Speech based on an Adaptive Quasi-Harmonic plus Noise Model}",
	year = "2010"
}

@inproceedings{PantazisY2010ashort,
	author = "Pantazis, Y. and Tzedakis, G. and Rosec, O. and Stylianou, Y.",
	booktitle = "{Proc. ICASSP}",
	lockkey = "Y",
	pages = "4246--4249",
	title = "{Analysis/Synthesis of Speech based on an Adaptive Quasi-Harmonic plus Noise Model}",
	year = "2010"
}

@inproceedings{PantazisY2008,
	abstract = "In this paper we present the properties of a parametric speech model based on a deterministic plus noise representation of speech initially suggested by Laroche et al. [1]. Aiming at a high resolution analy- sis of speech signals for voice quality control (transformation) and assessment, we focus on the deterministic representation and we reveal the properties of the model showing that such a representa- tion is equivalent to a time-varying quasi-harmonic representation of speech. Results show that the model is appropriate in estimating ac- curately linear amplitude modulations and modeling the inharmonic- ity of speech.",
	author = "Pantazis, Y. and Rosec, O. and Stylianou, Y.",
	booktitle = "{Proc. Interspeech}",
	keywords = "Speech analysis; speech modeling; quasi- harmonic models; inharmonicity",
	lockkey = "Y",
	pages = "1044--1047",
	title = "{On the Properties of a Time-Varying Quasi-Harmonic Model of Speech}",
	year = "2008"
}

@inproceedings{RoebelA2010a,
	abstract = "This paper proposes a new method for shape invariant real- time modiÃ¯Â¬Âcation of speech signals. The method can be un- derstood as a frequency domain SOLA algorithm that is us- ing the phase vocoder algorithm for phase synchronization. Compared to time domain SOLA the new implementation provides improved time synchronization during overlap add and improved quality of the noise components of the trans- formed speech signals. The algorithm has been compared in two perceptual tests with recent implementations of PSOLA and HNM algorithms demonstrating a very satisfying per- formance. Due to the fact that the quality of transformed signals stays constant over a wide range of transformation parameters the algorithm is well suited for real-time gender and age transformations.",
	author = "Roebel, Axel",
	booktitle = "{Proc. Digital Audio Effects (DAFx)}",
	lockkey = "Y",
	pages = "1--8",
	title = "{A shape-invariant phase vocoder for speech transformation}",
	year = "2010"
}

@article{FlanaganJL1972b,
	abstract = "Talking computers are likely to become a fixture in modern society. The range of information services that can be provided by voice from computers depends largely upon how clever computers become at imitating human speech. This, in turn, depends upon the fundamental acoustic and linguistic knowledge that can be imparted to the machine. This article summarizes the principles of human speech generation, traces some historical interests in speaking machines, and indicates present capabilities of talking computers.",
	author = "Flanagan, J. L.",
	doi = "10.1121/1.1912988",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "5A",
	pages = "1375--1387",
	publisher = "ASA",
	title = "{Voices of Men and Machines}",
	url = "http://link.aip.org/link/?JAS/51/1375/1",
	volume = "51",
	year = "1972"
}

@article{PortnoffMR1976,
	abstract = "This paper discusses a digital formulation of the phase vocoder, an analysis-synthesis system providing a parametric representation of a speech waveform by its short-time Fourier transform. Such a system is of interest both for data-rate reduction and for manipulating basic speech parameters. The system is designed to be an identity system in the absence of any parameter modifications. Computational efficiency is achieved by employing the fast Fourier transform (FFT) algorithm to perform the bulk of the computation in both the analysis and synthesis procedures, thereby making the formulation attractive for implementation on a minicomputer.",
	author = "Portnoff, M.",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	lockkey = "Y",
	number = "3",
	pages = "243--248",
	title = "{Implementation of the digital phase vocoder using the fast Fourier transform}",
	volume = "24",
	year = "1976"
}

@inproceedings{AlessandroC2007,
	author = "d'Alessandro, Christophe d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Bozkurt, Baris and Doval, Boris and Dutoit, Thierry and Henrich, Nathalie and Tuan, Vu Ngoc and Sturmel, Nicolas",
	booktitle = "{NOLISP}",
	lockkey = "Y",
	title = "{Phase-based methods for voice source analysis}",
	year = "2007"
}

@inproceedings{FalekL2007,
	author = "Falek, Lila and Amar, Djeradi",
	booktitle = "{ICA}",
	lockkey = "N",
	title = "{BEHAVIOR OF THE SPECTRAL ENVELOPE OF THE VOCAL TRACT IN FRONT OF A VARIATION OF THE SOURCE PARAMETERS}",
	year = "2007"
}

@article{YuleGU1927,
	author = "Yule, G. Udny",
	journal = "Philosophical Trans. of The Royal Society",
	lockkey = "Y",
	title = "{On a Method of Investigating Periodicities in Disturbed Series, with special reference to Wolfer's Sunspot Numbers}",
	year = "1927"
}

@inproceedings{YoshimuraT2001,
	author = "Yoshimura, T. and Tokuda, K. and Masuko, T. and Kitamura, T.",
	booktitle = "{Proc. Eurospeech}",
	lockkey = "Y",
	pages = "2259--2262",
	title = "{Mixed-excitation for {HMM}-based speech synthesis}",
	year = "2001"
}

@inproceedings{FarnerS2009,
	abstract = "Natural voice transformation will reduce the need for authentic voices in many situations, ranging from vocal services via education and entertainment to artistic applications. Transformation of one voice to correspond to that of another person has been studied for decades but still suffers from limitations that we propose to overcome by an alternative approach. It consists in modifying pitch, spectral envelope, durations etc. in a global way. While it sacrifices the possibility to attain a specific target voice, the approach allows the production of new voices of a high degree of naturalness with different sex and age, modiÃ¯Â¬Âed vocal quality (soft, breathy, and whisper), or another speech style (dullness and eagerness). The transformation of sex and age has been evaluated by a listening test.",
	author = "Farner, S. and Roebel, A. and Rodet, X.",
	booktitle = "{Proc. Conference of the Audio Engineering Society (AES)}",
	lockkey = "Y",
	title = "{Natural transformation of type and nature of the voice for extending vocal repertoire in high-fidelity applications}",
	year = "2009"
}

@inproceedings{SturmelN2007,
	abstract = "A new method for voice source estimation is evaluated and compared to Linear Prediction (LP) inverse filtering methods (autocorrelation LPC, covariance LPC and IAIF [1]). The method is based on a causal/anticausal model of the voice source and the ZZT (Zeros of Z-Transform) representation [2] for causal/anticausal signal separation. A database containing synthetic speech with various voice source settings and natural speech with acoustic and electro-glottographic signals was recorded. Formal evaluation of source estimation is based on spectral distances. The results show that the ZZT causal/anticausal decomposition method outperforms LP in voice source estimation both for synthetic and natural signals. However, its computational load is much heavier (despite a very simple principle) and the method seems sensitive to noise and computation precision errors.",
	author = "Sturmel, Nicolas and d'Alessandro, Christophe d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Doval, Boris",
	booktitle = "{Interspeech}",
	lockkey = "Y",
	title = "{A comparative evaluation of the Zeros of Z Transform representation for voice source estimation}",
	year = "2007"
}

@article{BozkurtB2005,
	abstract = "We propose a new spectral representation called the zeros of z-transform (ZZT), which is an all-zero representation of the z-transform of the signal. We show that separate patterns exist in ZZT representations of speech signals for the glottal flow and the vocal tract contributions. A decomposition method for source-tract separation is presented based on ZZT. The ZZT-decomposition consists in grouping the zeros into two sets, according to their location in the z-plane. This type of decomposition leads to separating glottal flow contribution (without a return phase) from vocal tract contribution in the z domain.",
	author = "Bozkurt, B. and Doval, B. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Dutoit, T.",
	doi = "10.1109/LSP.2005.843770",
	issn = "1070-9908",
	journal = "IEEE Signal Processing Letters",
	keywords = "filtering theory; glottal flow; signal representation; source-filter separation; source separation; source-tract separation; spectral representation; speech processing; speech signal; vocal tract contribution; z domain; zeros z-transform; z-plane; Z transforms; ZZT decomposition method",
	lockkey = "Y",
	number = "4",
	pages = "344--347",
	title = "{Zeros of Z-transform representation with application to source-filter separation in speech}",
	volume = "12",
	year = "2005"
}

@article{HenrichN2004,
	abstract = "Electroglottography is a common method for providing noninvasive measurements of glottal activity. The derivative of the electroglottographic signal, however, has not attracted much attention, although it yields reliable indicators of glottal closing instants. The purpose of this paper is to provide a guide to the usefulness of this signal. The main features that are to be found in this signal are presented on the basis of an extensive analysis of a database of items sung by 18 trained singers. Glottal opening and closing instants are related to peaks in the signal; the latter can be used to measure glottal parameters such as fundamental frequency and open quotient. In some cases, peaks are doubled or imprecise, which points to special (but by no means uncommon) glottal configurations. A correlation-based algorithm for the automatic measurement of fundamental frequency and open quotient using the derivative of electroglottographic signals is proposed. It is compared to three other 
electroglottographic-based methods with regard to the measurement of open quotient in inverse-filtered derived glottal flow. It is shown that agreement with the glottal-flow measurements is much better than most threshold-based measurements in the case of sustained sounds.",
	author = "Henrich, N. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Doval, B. and Castellengo, M.",
	doi = "10.1121/1.1646401",
	journal = "Journal of the Acoustical Society of America",
	keywords = "bioacoustics; bioelectric phenomena; biological organs",
	lockkey = "Y",
	number = "3",
	pages = "1321--1332",
	publisher = "ASA",
	title = "{On the use of the derivative of electroglottographic signals for characterization of nonpathological phonation}",
	url = "http://link.aip.org/link/?JAS/115/1321/1",
	volume = "115",
	year = "2004"
}

@inproceedings{BarneyA2005,
	author = "{Barney A.}, De Stefano A. and Henrich, N",
	booktitle = "{ForumAcusticum}",
	lockkey = "Y",
	pages = "2743--2748",
	title = "{The effect of glottal opening on the acoustic response of the vocal tract}",
	year = "2005"
}

@article{StylianouY2001,
	abstract = "This paper describes the application of the harmonic plus noise model (HNM) for concatenative text-to-speech (TTS) synthesis. In the context of HNM, speech signals are represented as a time-varying harmonic component plus a modulated noise component. The decomposition of a speech signal into these two components allows for more natural-sounding modifications of the signal (e.g., by using different and better adapted schemes to modify each component). The parametric representation of speech using HNM provides a straightforward way of smoothing discontinuities of acoustic units around concatenation points. Formal listening tests have shown that HNM provides high-quality speech synthesis while outperforming other models for synthesis (e.g., TD-PSOLA) in intelligibility, naturalness, and pleasantness",
	author = "Stylianou, Y.",
	doi = "10.1109/89.890068",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "acoustic units; adapted schemes; concatenative text-to-speech synthesis; discontinuities smoothing; formal listening tests; harmonic plus noise model; high-quality speech synthesis; modulated noise component; natural-sounding signal modifications; parametric speech representation; speech intelligibility; speech naturalness; speech pleasantness; speech signal decomposition; speech signals representation; time-varying harmonic component; acoustic signal processing; harmonics; noise; signal representation; smoothing methods; speech intelligibility; speech synthesis",
	lockkey = "Y",
	number = "1",
	pages = "21--29",
	title = "{Applying the harmonic plus noise model in concatenative speech synthesis}",
	volume = "9",
	year = "2001"
}

@article{RichardG1996,
	author = "Richard, Ga{\"e}l and d'Alessandro, Christophe d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro",
	doi = "10.1016/0167-6393(96)00038-6",
	issn = "0167-6393",
	journal = "Speech Communication",
	keywords = "Speech modifications",
	lockkey = "Y",
	number = "3",
	pages = "221--244",
	title = "{Analysis/synthesis and modification of the speech aperiodic component}",
	url = "http://www.sciencedirect.com/science/article/B6V1C-3WP2CXH-F/2/7494cfe32afac8a37e5053acc3514aa6",
	volume = "19",
	year = "1996"
}

@book{Oppenheim1978,
	author = "Oppenheim, A. V. and Schafer, Ronald W.",
	lockkey = "Y",
	publisher = "Prentice-Hall, 2nd edition",
	title = "{Digital Signal Processing}",
	year = "1978"
}

@article{VerhelstW1986,
	abstract = "Traditionally, a very simple model for short-time homomorphic analysis has been used. It is shown that there is no theoretical justification for applying this model to voiced speech and that the model is of limited value for improving cepstral deconvolution procedures. Consequently, a more elaborate model is introduced in which the influence of window length is approximated and the spectral sampling inherent in voiced speech is explicitly represented. As a result, this new model shows that the vocal tract contribution to the complex cepstrum is repeated at every multiple of the pitch quefrency (np) and is multiplied by a double sinclike distortion (D(n)). It is shown that in order to achieve deconvolution with a low-time gating system, a cepstral lifter of length np/2 should be used (instead of the usual length ``less than np''). Furthermore, the lifter should compensate for the distortion D(n). Unfortunately, the accuracy of straightforward homomorphic deconvolution approximations is limited by 
aliasing distortion which results from the repeated nature of the vocal tract contribution. Nevertheless, reasonable deconvolution approximations are obtained.",
	author = "Verhelst, W. and Steenhaut, O.",
	issn = "0096-3518",
	journal = "Acoustics, Speech and Signal Processing, IEEE Trans. on",
	lockkey = "Y",
	month = "feb",
	number = "1",
	pages = "43--51",
	title = "{A new model for the short-time complex cepstrum of voiced speech}",
	volume = "34",
	year = "1986"
}

@article{ColemanTF1996,
	abstract = "We propose a new trust region approach for minimizing a nonlinear function subject to simple bounds. Unlike most existing methods, our proposed method does not require that a quadratic programming subproblem, with inequality constraints, be solved in each iteration. Instead, a solution to a trust region subproblem is defined by minimizing a quadratic function subject only to an ellipsoidal constraint. The iterates generated are strictly feasible. Our proposed method reduces to a standard trust region approach for the unconstrained problem when there are no upper or lower bounds on the variables. Global and local quadratic convergence is established. Preliminary numerical experiments are reported indicating the practical viability of this approach.",
	author = "Coleman, T.F. and Li, Yuying",
	journal = "SIAM Journal on Optimization",
	lockkey = "Y",
	number = "2",
	pages = "418--445",
	title = "{An Interior, Trust Region Approach for Nonlinear Minimization Subject to Bounds}",
	volume = "6",
	year = "1996"
}

@article{ColemanTF1994,
	abstract = "We consider a new algorithm, an interior-reflective Newton approach, for the problem of minimizing a smooth nonlinear function of many variables, subject to upper and/or lower bounds on some of the variables. This approach generatesstrictly feasible iterates by using a new affine scaling transformation and following piecewise linear paths (reflection paths). The interior-reflective approach does not require identification of an ldquoactivity setrdquo. In this paper we establish that the interior-reflective Newton approach is globally and quadratically convergent. Moreover, we develop a specific example of interior-reflective Newton methods which can be used for large-scale and sparse problems.",
	author = "Coleman, T. F. and Li, Yuying",
	journal = "Mathematical Programming",
	lockkey = "Y",
	number = "1-3",
	pages = "189--224",
	title = "{On the convergence of interior-reflective Newton methods for nonlinear minimization subject to bounds}",
	volume = "67",
	year = "1994"
}

@article{Kleijn2003,
	abstract = "The commonly used line spectral frequencies form the roots of symmetric and antisymmetric polynomials constructed from a linear predictor. We provide a new, simpler proof that the symmetric and antisymmetric polynomials can be regarded as optimal constrained predictors that correspond to predicting from the low-pass and high-pass filtered signal, respectively.",
	author = "Kleijn, W. B. and Backstrom, T. and Alku, P.",
	doi = "10.1109/LSP.2003.809035",
	issn = "1070-9908",
	journal = "IEEE Signal Processing Letters",
	keywords = "antisymmetric polynomials; high-pass filtered signal; line spectral frequencies; linear prediction; linear predictor; low-pass filtered signal; online spectral frequencies; optimal constrained predictors; speech coding; symmetric polynomials; filtering theory; high-pass filters; low-pass filters; online operation; prediction theory; spectral analysis",
	lockkey = "Y",
	month = "mar",
	number = "3",
	pages = "75--77",
	title = "{On line spectral frequencies}",
	volume = "10",
	year = "2003"
}

@inproceedings{Chen2009,
	abstract = "In this paper, a new algorithm based on the Tschirnhaus transforms is developed to reduce the computation complexity of the 10-order line spectrum pairs (LSP) frequencies. The first step of the proposed algorithm is to derive a quartic equation from the 1st derivative of the given 5-degree LSP polynomial. Then the extremes of the 5-degree LSP polynomial can be found by applying the Tschirnhaus transform to the above quartic equation. By the use of these extremes as the initial approximations, one can easily solve the roots of the 5-degree LSP polynomial via the Newton's method and get the accurate LSP frequencies. One of the main advantages of the proposed algorithm is the rapid root determination of a quartic equation without complex number operations and resulting in considerable computational saving. Compared to other methods, the proposed algorithm can determine the precise LSP frequencies with the lowest computational complexity.",
	author = "Chen, Shi-Huang and Chang, Yaotsu and Syuan, Chang Jian Yu",
	booktitle = "{Circuits and Systems, 2009. ISCAS 2009. IEEE International Symposium on}",
	doi = "10.1109/ISCAS.2009.5118267",
	keywords = "5-degree LSP polynomial; Newton method; Tschirnhaus transform; computational complexity; line spectrum pair frequencies; linear predictive coding; quartic equation; speech coding system; Newton method; computational complexity; linear codes; polynomials; speech coding; transforms",
	lockkey = "Y",
	month = "24-27",
	pages = "2333--2336",
	title = "{The computation of line spectrum pair frequencies using Tschirnhaus transform}",
	year = "2009"
}

@article{KabalP1986,
	abstract = "Line spectral frequencies provide an alternate parameterization of the analysis and synthesis filters used in linear predictive coding (LPC) of speech. In this paper, a new method of converting between the direct form predictor coefficients and line spectral frequencies is presented. The system polynomial for the analysis filter is converted to two even-order symmetric polynomial with interlacing roots on the unit circle. The line spectral frequencies are given by the positions of the roots of these two auxiliary polynomials. The response of each of these polynomials on the unit circle is expressed as a series expansion in Chebyshev polynomials. The line spectral frequencies are found using an iterative root finding algorithm which searches for real roots of a real function. The algorithm developed is simple in structure and is designed to constrain the maximum number of evaluations of the series expansions. The method is highly accurate and can be used in a form that avoids the storage of 
trigonometric tables or the computation of trigonometric functions. The reconversion of line spectral frequencies to predictor coefficients uses an efficient algorithm derived by expressing the root factors as an expansion in Chebyshev polynomials.",
	author = "Kabal, P. and Ramachandran, R.P.",
	issn = "0096-3518",
	journal = "Acoustics, Speech and Signal Processing, IEEE Trans. on",
	lockkey = "Y",
	month = "dec",
	number = "6",
	pages = "1419--1426",
	title = "{The computation of line spectral frequencies using Chebyshev polynomials}",
	volume = "34",
	year = "1986"
}

@article{GoldbergerAS1962,
	author = "Goldberger, A. S.",
	journal = "Journal of the American Statistical Association",
	lockkey = "Y",
	number = "298",
	pages = "369--375",
	title = "{Best Linear Unbiased Prediction in the Generalized Linear Regression Model}",
	volume = "57",
	year = "1962"
}

@book{Oppenheim1989,
	author = "Oppenheim, A. V. and Schafer, R. W.",
	lockkey = "Y",
	publisher = "Prentice-Hall, 3rd Edition",
	title = "{Digital Signal Processing}",
	year = "1989"
}

@article{MaC1994,
	abstract = "The detection of glottal closure instants has been a necessary step in several applications of speech processing, such as voice source analysis, speech prosody manipulation and speech synthesis. The paper presents a new algorithm for glottal closure detection that compares favorably with other methods available in terms of robustness and computational efficiency. The authors propose to use the singular value decomposition (SVD) approach to detect the instants of glottal closure from the speech signal. The proposed SVD method amounts to calculating the Frobenius norms of signal matrices and therefore is computationally efficient. Moreover, it produces well-defined and reliable peaks that indicate the instants of glottal closure. Finally, with the introduction of the total linear least squares technique, two other proposed methods are reinvestigated and unified into the SVD framework",
	author = "Ma, Changxue and Kamp, Y. and Willems, L.F.",
	doi = "10.1109/89.279274",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "Frobenius norm approach; SVD method; algorithm; computational efficiency; glottal closure detection; robustness; singular value decomposition; speech processing; speech prosody manipulation; speech signal; speech synthesis; total linear least squares technique; voice source analysis; least squares approximations; speech analysis and processing",
	lockkey = "Y",
	number = "2",
	pages = "258--265",
	title = "{A Frobenius norm approach to glottal closure detection from the speech signal}",
	volume = "2",
	year = "1994"
}

@phdthesis{BellerG2009a,
	abstract = "This thesis joins in the current searches(researches) on the feelings and the emotional reactions, on the modelling and the transformation of the speech, as well as on the musical performance. It seems that the capacity to express, to feign and to identify emotions, humors, intentions or attitudes, is fundamental in the human communication. The ease with which we understand the state of a character, from the only observation of the behavior of the actors and the sounds which they utter, shows that this source of information is essential and, sometimes, suÃ¯Â¬Âcient in our social relationships. If the emotional state presents the peculiarity to be idiosyncratic, that is private to every individual, it does not also go away of the associated reaction which shows itself by the gesture (movement, posture, face), the sound (voice, music), and which, it is observable by others. That is why paradigm of analysis - transformation - synthesis of the emotional reactions grows on into the therapeutic, 
commercial, scientiÃ¯Â¬Âc and artistic domains. This thesis joins in these last two domains and proposes several contributions. From a theoretical point of view, this thesis proposes a deÃ¯Â¬Ânition of the expressivity, a deÃ¯Â¬Ânition of the neutral expression, a new representation mode of the expressivity, as well as a set of expressive categories common to the speech and to the music. It places the expressivity among the census of the available levels of information in the performance which can be seen as a model of the artistic performance. It proposes an original model of the speech and its constituents, as well as a new hierarchical prosodic model. From an experimental point of view, this thesis supplies a protocol for the acquisition of performed expressive data. Collaterally, it makes available three corpora for the observation of the expressivity. It supplies a new statistical measure of the degree of articulation as well as several analysis results concerning the inÃ¯Â¬Âuence of the 
expressivity on the speech. From a technical point of view, it proposes a speech processing algorithm allowing the modiÃ¯Â¬Âcation of the degree of articulation. It presents an innovative database management system which is used, already, used by some other automatic speech processing applications, requiring the manipulation of corpus. It shows the establishment of a bayesian network as generative model of context dependent transformation parameters. From a technological point of view, an experimental system of high quality transfor- mation of the expressivity of a French neutral utterance, either synthetic or recorded, has been produced, as well as an on-line interface for perceptive tests. Finally and especially, from a forward-looking point of view, this thesis proposes va- rious research tracks for the future, both on the theoretical, experimental, technical, and technological aspects. Among these, the confrontation of the demonstrations of the expressivity in the speech and in the musical performance 
seems to be a promising way.",
	author = "Beller, Gr{\'e}gory",
	lockkey = "Y",
	school = "UPMC",
	title = "{Analyse et Mod{\`e}le G{\'e}n{\'e}ratif de l'Expressivit{\'e}}",
	year = "2009"
}

@article{BellerG2009,
	abstract = "Corpus based methods are increasingly used for speech technology applications and for the development of theoretical or computer models of spoken languages. These usages range from unit selection speech synthesis to statistical modeling of speech phenomena like prosody or expressivity. In all cases, these usages require a wide range of tools for corpus creation, labeling, symbolic and acoustic analysis, storage and query. However, if a variety of tools exists for each of these individual tasks, they are rarely integrated into a single platform made available to a large community of researchers. In this paper, we propose IrcamCorpusTools, an open and easily extensible platform for analysis, query and visualization of speech corpora. It is already used for unit selection speech synthesis, for prosody and expressivity studies, and to exploit various corpora of spoken French or other languages.",
	author = "Beller, Gr{\'e}gory and Veaux, Christophe and Degottex, Gilles and Obin, Nicolas and Lanchantin, Pierre and Rodet, Xavier",
	journal = "Traitement Automatique des Langues (TAL)",
	lockkey = "Y",
	number = "3",
	pages = "77--103",
	title = "{IrcamCorpusTools : Plateforme Pour Les Corpus de Parole}",
	volume = "49",
	year = "2009"
}

@article{Rayleigh1907,
	author = "Rayleigh, Lord",
	journal = "Philosophical Magazine",
	lockkey = "Y",
	title = "{On our Perception of Sound Direction}",
	volume = "13",
	year = "1907"
}

@inbook{RodetX2009,
	author = "Rodet, Xavier and Beller, Gr{\'e}gory and Bogaards, Niels and Degottex, Gilles and Farner, Snorre and Lanchantin, Pierre and Obin, Nicolas and Roebel, Axel and Veaux, Christophe and Villavicencio, Fernando",
	chapter = "Transformation et synth{\`e}se de la voix parl{\'e}e et de la voix chant{\'e}e",
	lockkey = "Y",
	publisher = "Odile Jacob",
	title = "{Parole et musique}",
	year = "2009"
}

@techreport{LindseyG1987,
	address = "U.K.",
	author = "Lindsey, G. and Breen, A. and Nevard, S.",
	comment = "[39] G. Lindsey, A. Breen, and S. Nevard, ``SPAR{\rq}s Archivable Actual- Word Databases,'' Tech. Rep. Univ. College London, London, U.K., 1987.",
	institution = "University College London",
	lockkey = "Y",
	title = "{{SPAR}'s Archivable Actual-Word Databases}",
	year = "1987"
}

@inproceedings{ZenH2007,
	abstract = "A statistical parametric speech synthesis system based on hidden Markov models (HMMs) has grown in popularity over the last few years. This system simultaneously models spectrum, excitation, and duration of speech using context-dependent HMMs and generates speech waveforms from the HMMs themselves. Since December 2002, we have publicly released an open-source software toolkit named HMM-based speech synthesis system (HTS) to provide a research and development platform for the speech synthesis community. In December 2006, HTS version 2.0 was released. This version includes a number of new features which are useful for both speech synthesis researchers and developers. This paper describes HTS version 2.0 in detail, as well as future release plans.",
	author = "Zen, H. and Nose, T. and Yamagishi, J. and Sako, S. and Masuko, T. and Black, A. and Tokuda, K.",
	booktitle = "{Proc. ISCA Workshop on Speech Synthesis (SSW), http://hts.sp.nitech.ac.jp}",
	categories = "HMM, speech synthesis, HTS",
	lockkey = "Y",
	title = "{The {HMM}-based speech synthesis system ({HTS}) version 2.0}",
	year = 2007
}

@article{GalesMJF1999,
	author = "Gales, M. J. F.",
	journal = "IEEE Trans. on Speech and Audio Processing",
	lockkey = "Y",
	number = "3",
	pages = "272--281",
	title = "{Semi-tied covariance matrices for hidden markov models}",
	volume = "7",
	year = "1999"
}

@article{TokudaK2002a,
	author = "Tokuda, K. and Masuko, T. and Myizaki, N. and Kobayashi, T.",
	journal = "IEICE Trans. on Information and Systems",
	lockkey = "Y",
	pages = "455--464",
	title = "{Multi-space probability distribution {HMM}}",
	volume = "E85-D",
	year = "2002"
}

@inproceedings{LanchantinP2008,
	author = "Lanchantin, P. and Morris, A. C. and Rodet, X. and Veaux, C.",
	booktitle = "{Proc. Language Resources and Evaluation Conference}",
	lockkey = "Y",
	pages = "2403--2407",
	title = "{Automatic Phoneme Segmentation With Relaxed Textual Constraints}",
	year = "2008"
}

@techreport{YoungSJ1994,
	author = "Young, S.J.",
	institution = "University of Cambridge",
	lockkey = "Y",
	title = "{The {HTK} hidden markov model toolkit: Design and philosophy}",
	year = "1994"
}

@article{BechetF2001,
	author = "Bechet, F.",
	journal = "Traitement Automatique des Langues",
	lockkey = "Y",
	number = "1",
	pages = "47--67",
	title = "{Liaphon: un syst{\`e}me complet de phonetisation de textes}",
	volume = "42",
	year = "2001"
}

@inproceedings{TokudaK2002,
	author = "Tokuda, K. and Zen, H. and Black, A.W.",
	booktitle = "{Proc. IEEE Workshop on Speech synthesis}",
	lockkey = "Y",
	pages = "227--230",
	title = "{An {HMM}-based speech synthesis system applied to English}",
	year = "2002"
}

@inproceedings{TokudaK1995,
	author = "Tokuda, K. and Masuko, T. and Yamada, T. and Kobayashi, T. and Imai, S.",
	booktitle = "{Proc. Eurospeech}",
	lockkey = "Y",
	pages = "757--760",
	title = "{An algorithm for speech parameter generation from continuous mixture {HMMs} with dynamic features}",
	year = "1995"
}

@article{PantazisY2010adapt,
	abstract = "In this paper, we present an iterative method for the accurate estimation of amplitude and frequency modulations (AM-FM) in time-varying multi-component quasi-periodic signals such as voiced speech. Based on a deterministic plus noise representation of speech initially suggested by Laroche et al. [1], and focusing on the deterministic representation, we reveal the properties of the model showing that such a representation is equivalent to a time-varying quasi-harmonic representation of voiced speech. Next, we show how this representation can be used for the estimation of amplitude and frequency modulations and provide the conditions under which such an estimation is valid. Finally, we suggest an adaptive algorithm for non-parametric estimation of AM-FM components in voiced speech. Based on the estimated amplitude and frequency components, a high resolution time-frequency representation is obtained. The suggested approach was evaluated on synthetic AM-FM signals, while using the estimated AM-FM 
information, speech signal reconstruction was performed, resulting in a high signal-to-reconstruction error ratio (around 30dB).",
	author = "Pantazis, Y. and Rosec, O. and Stylianou, Y.",
	doi = "10.1109/TASL.2010.2047682",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	lockkey = "Y",
	number = "2",
	pages = "290--300",
	title = "{Adaptive {AM}-{FM} Signal Decomposition With Application to Speech Analysis}",
	volume = "19",
	year = "2010"
}

@article{PantazisY2010adaptshort,
	abstract = "In this paper, we present an iterative method for the accurate estimation of amplitude and frequency modulations (AM-FM) in time-varying multi-component quasi-periodic signals such as voiced speech. Based on a deterministic plus noise representation of speech initially suggested by Laroche et al. [1], and focusing on the deterministic representation, we reveal the properties of the model showing that such a representation is equivalent to a time-varying quasi-harmonic representation of voiced speech. Next, we show how this representation can be used for the estimation of amplitude and frequency modulations and provide the conditions under which such an estimation is valid. Finally, we suggest an adaptive algorithm for non-parametric estimation of AM-FM components in voiced speech. Based on the estimated amplitude and frequency components, a high resolution time-frequency representation is obtained. The suggested approach was evaluated on synthetic AM-FM signals, while using the estimated AM-FM 
information, speech signal reconstruction was performed, resulting in a high signal-to-reconstruction error ratio (around 30dB).",
	author = "Pantazis, Y. and Rosec, O. and Stylianou, Y.",
	doi = "10.1109/TASL.2010.2047682",
	issn = "1558-7916",
	journal = "IEEE TASLP",
	lockkey = "Y",
	title = "{Adaptive {AM}-{FM} Signal Decomposition With Application to Speech Analysis}",
	year = "2010"
}

@inproceedings{HuntAJ1996,
	abstract = "One approach to the generation of natural-sounding synthesized speech waveforms is to select and concatenate units from a large speech database. Units (in the current work, phonemes) are selected to produce a natural realisation of a target phoneme sequence predicted from text which is annotated with prosodic and phonetic context information. We propose that the units in a synthesis database can be considered as a state transition network in which the state occupancy cost is the distance between a database unit and a target, and the transition cost is an estimate of the quality of concatenation of two consecutive units. This framework has many similarities to HMM-based speech recognition. A pruned Viterbi search is used to select the best units for synthesis from the database. This approach to waveform synthesis permits training from natural speech: two methods for training from speech are presented which provide weights which produce more natural speech than can be obtained by hand-tuning",
	author = "Hunt, A. J. and Black, A. W.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1996.541110",
	keywords = "concatenative speech synthesis system; database unit; large speech database; natural-sounding synthesized speech; natural speech; phoneme sequence; phonetic context information; prosodic context information; pruned Viterbi search; search problems; speech synthesis; state occupancy cost; state transition network; synthesis database; training; transition cost; Viterbi decoding; waveform synthesis",
	lockkey = "Y",
	pages = "373--376",
	title = "{Unit selection in a concatenative speech synthesis system using a large speech database}",
	volume = "1",
	year = "1996"
}

@article{VepaJ2006,
	abstract = "In unit selection-based concatenative speech synthesis, join cost (also known as concatenation cost), which measures how well two units can be joined together, is one of the main criteria for selecting appropriate units from the inventory. Usually, some form of local parameter smoothing is also needed to disguise the remaining discontinuities. This paper presents a subjective evaluation of three join cost functions and three smoothing methods. We also describe the design and performance of a listening test. The three join cost functions were taken from our previous study, where we proposed join cost functions derived from spectral distances, which have good correlations with perceptual scores obtained for a range of concatenation discontinuities. This evaluation allows us to further validate their ability to predict concatenation discontinuities. The units for synthesis stimuli are obtained from a state-of-the-art unit selection text-to-speech system: rVoice from Rhetorical Systems Ltd. In this 
paper, we report listeners' preferences for each join cost in combination with each smoothing method",
	author = "Vepa, J. and King, S.",
	doi = "10.1109/TSA.2005.858548",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	keywords = "concatenation discontinuities; join cost functions; selection-based concatenative speech synthesis; smoothing methods; subjective evaluation; text-to-speech system; smoothing methods; speech synthesis",
	lockkey = "Y",
	number = "5",
	pages = "1763--1771",
	title = "{Subjective evaluation of join cost and smoothing methods for unit selection speech synthesis}",
	volume = "14",
	year = "2006"
}

@phdthesis{DintherR2003,
	address = "The Netherlands",
	author = "{van Dinther}, Ralph",
	lockkey = "Y",
	school = "Technical University of Eindhoven",
	title = "{Perceptual aspects of voice-source parameters}",
	year = "2003"
}

@book{Markel1976,
	author = "Markel, J.D. and Gray, A.H.",
	lockkey = "Y",
	publisher = "Springer Verlag",
	title = "{Linear Prediction of Speech}",
	year = 1976
}

@article{Degottex2011c,
	abstract = "In glottal source analysis, the phase minimization criterion has already been proposed to detect excitation instants. As shown in this paper, this criterion can also be used to estimate the shape parameter of a glottal model (ex. Liljencrants-Fant model) and not only its time position. Additionally, we show that the shape parameter can be estimated independently of the glottal model position. The reliability of the proposed methods is evaluated with synthetic signals and compared to that of the IAIF and minimum/maximum-phase decomposition methods. The results of the methods are evaluated according to the influence of the fundamental frequency and noise. The estimation of a glottal model is useful for the separation of the glottal source and the vocal-tract filter and therefore can be applied in voice transformation, synthesis, and also in clinical context or for the study of the voice production.",
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	doi = "10.1109/TASL.2010.2076806",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	keywords = "glottal model estimation; glottal model position; glottal source analysis; minimisation; noise; phase estimation; phase minimization criterion; reliability; shape parameter estimation; signal synthesis; speech synthesis; synthetic signal; vocal tract filter; voice production; voice synthesis; voice transformation",
	number = "5",
	pages = "1080--1090",
	title = "{Phase Minimization for Glottal Model Estimation}",
	volume = "19",
	year = "2011"
}

@article{Degottex2010d,
	abstract = "In glottal source analysis, the phase minimization criterion has already been proposed to detect excitation instants. As shown in this article, this criterion can also be used to estimate the shape parameter of a glottal model (ex. Liljencrants-Fant model) and not only its time position. Additionally, we show that the shape parameter can be estimated independently of the glottal model position. The reliability of the proposed methods is evaluated with synthetic signals and compared to that of the IAIF and minimum/maximum-phase decomposition methods. The results of the methods are evaluated according to the influence of the fundamental frequency and noise. The estimation of a glottal model is useful for the separation of the glottal source and the vocal-tract filter and therefore can be applied in voice transformation, synthesis and also in clinical context or for the study of the voice production.",
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	doi = "10.1109/TASL.2010.2076806",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing,",
	lockkey = "Y",
	number = "5",
	pages = "1080--1090",
	title = "{Phase minimization for glottal model estimation}",
	volume = "19",
	year = "2011"
}

@misc{HezardT2010,
	author = "H{\'e}lie, T. and Hezard, T. and Rodet, X.",
	lockkey = "Y",
	title = "{PhD Subject: Syst{\`e}mes dynamiques de production de la voix inform{\'e}s par la physique et command{\'e}s par la g{\'e}om{\'e}trie pour l'analyse et la synth{\`e}se sonore}",
	year = "2010"
}

@article{CaetanoM2010,
	author = "Caetano, M. and Rodet, X.",
	journal = "Draft for IEEE",
	lockkey = "Y",
	pages = "15",
	title = "{Morphing Quasi-Harmonic Sustained Musical Instrument Sounds Guided by High-Level Descriptors}",
	year = "2010"
}

@phdthesis{BurredJJ2009,
	abstract = "The goal of source separation is to detect and extract the individual signals present in a mixture. Its application to sound signals and, in particular, to music signals, is of interest for content analysis and retrieval applications arising in the context of online music services. Other applications include unmixing and remixing for post-production, restoration of old recordings, object-based audio compression and upmixing to multichannel setups. This work addresses the task of source separation from monaural and stereo- phonic linear musical mixtures. In both cases, the problem is underdetermined, meaning that there are more sources to separate than channels in the observed mix- ture. This requires taking strong statistical assumptions and/or learning a priori information about the sources in order for a solution to be feasible. On the other hand, constraining the analysis to instrumental music signals allows exploiting spe- ciÃ¯Â¬Âc cues such as spectral and temporal smoothness, note-based 
segmentation and timbre similarity for the detection and extraction of sound events. The statistical assumptions and, if present, the a priori information, are both captured by a given source model that can greatly vary in complexity and extent of application. The approach used here is to consider source models of increasing levels of complexity, and to study both their implications on the separation algorithm, and the type of mixtures they are able to handle. The starting point is sparsity-based separation, which makes the general assump- tion that the sources can be represented in a transformed domain with few high- energy coeÃ¯Â¬Âcients. It will be shown that sparsity, and consequently separation, can both be improved by using nonuniform-resolution time--frequency representations. To that end, several types of frequency-warped Ã¯Â¬Âlter banks will be used as signal front-ends in conjunction with an unsupervised separation approach aimed at stereo signals. As a next step, more sophisticated models based 
on sinusoidal modeling and statistical training will be considered in order to improve separation and to al- low the consideration of the maximally underdetermined problem: separation from single-channel signals. An emphasis is given in this work to a detailed but com- pact approach to train models of the timbre of musical instruments. An important characteristic of the approach is that it aims at a close description of the temporal evolution of the spectral envelope. The proposed method uses a formant-preserving, dimension-reduced representation of the spectral envelope based on spectral inter- polation and Principal Component Analysis. It then describes the timbre of a given instrument as a Gaussian Process that can be interpreted either as a prototype curve in a timbral space or as a time--frequency template in the spectral domain. Such templates will be used for the grouping and separation of sinusoidal tracks from the mixture. A monaural separation method based on sinusoidal modeling and on the men- 
tioned timbre modeling approach will be presented. It exploits common-fate and good-continuation cues to extract groups of sinusoidal tracks corresponding to the individual notes. Each group is compared to each one of the timbre templates on the database using a specially-designed measure of timbre similarity, followed by a Maximum Likelihood decision. Subsequently, overlapping and missing parts of the sinusoidal tracks are retrieved by interpolating the selected timbre template. The method is later extended to stereo mixtures by using a preliminary spatial-based blind separation stage, followed by a set of reÃ¯Â¬Ânements performed by the above sinusoidal modeling and timbre matching methods and aiming at reducing interfer- ences with the undesired sources. A notable characteristic of the proposed separation methods is that they do not assume harmonicity, and are thus not based on a previous multipitch estimation stage, nor on the input of detailed pitch-related information. Instead, grouping and separation 
relies solely on 
the dynamic behavior of the amplitudes of the partials. This also allows separating highly inharmonic sounds and extracting chords played by a single instrument as individual entities. The fact that the presented approaches are supervised and based on classiÃ¯Â¬Âca- tion and similarity allows using them (or parts thereof) for other content analysis applications. In particular the use of the timbre models, and the timbre matching stages of the separation systems will be evaluated in the tasks of musical instrument classiÃ¯Â¬Âcation and detection of instruments in polyphonic mixtures.",
	author = "Burred, J. J.",
	lockkey = "Y",
	school = "Berlin University",
	title = "{From Sparse Models to Timbre Learning: New Methods for Musical Source Separation}",
	year = "2009"
}

@phdthesis{TodaT2003,
	abstract = "Text-to-Speech (TTS) is a useful technology that converts any text into a speech signal. It can be utilized for various purposes, e.g. car navigation, an- nouncements in railway stations, response services in telecommunications, and e-mail reading. Corpus-based TTS makes it possible to dramatically improve the naturalness of synthetic speech compared with the early TTS. However, no general-purpose TTS has been developed that can consistently synthesize suÃ¯Â¬Â- ciently natural speech. Furthermore, there is not yet enough Ã¯Â¬Âexibility in corpus- based TTS. This thesis addresses two problems in speech synthesis. One is how to improve the naturalness of synthetic speech in corpus-based TTS. The other is how to improve control of speaker individuality in order to achieve more Ã¯Â¬Âexible speech synthesis. To deal with the former problem, we focus on two factors: (1) an algorithm for selecting the most appropriate synthesis units from a speech corpus, and (2) an evaluation measure for selecting 
the synthesis units. Moreover, we focus on a voice conversion technique to control speaker individuality to deal with the latter problem. Since various vowel sequences appear frequently in Japanese, it is not re- alistic to prepare long units that include all possible vowel sequences to avoid vowel-to-vowel concatenation, which often produces auditory discontinuity. In order to address this problem, we propose a novel segment selection algorithm based on both phoneme and diphone units that does not avoid concatenation of vowel sequences but alleviates the resulting discontinuity. Experiments testing concatenation of vowel sequences clarify that better segments can be selected by considering concatenations not only at phoneme boundaries but also at vowel centers. Moreover, the results of perceptual experiments show that speech syn- thesized using the proposed algorithm has better naturalness than that using the conventional algorithms. A cost is established as a measure for selecting the optimum waveform seg- 
ments from a speech corpus. In order to achieve high-quality segment selection for concatenative TTS, it is important to utilize a cost that corresponds to perceptual characteristics. We Ã¯Â¬Ârst clarify the correspondence of the cost to the perceptual scores and then evaluate various functions to integrate local costs capturing the degradation of naturalness in individual segments. From the results of perceptual experiments, we Ã¯Â¬Ând a novel cost that takes into account not only the degrada- tion of naturalness over the entire synthetic speech but also the local degradation. We also clarify that the naturalness of synthetic speech can be slightly improved by utilizing this cost and investigate the eÃ¯Â¬Âect of using this cost for segment selection. We improve the voice conversion algorithm based on the Gaussian Mixture Model (GMM), which is a conventional statistical voice conversion algorithm. The GMM-based algorithm can convert speech features continuously using the correlations between source and 
target features. However, the quality of the con- verted speech is degraded because the converted spectrum is excessively smoothed by the statistical averaging operation. To overcome this problem, we propose a novel voice conversion algorithm that incorporates Dynamic Frequency Warping (DFW) technique. The experimental results reveal that the proposed algorithm can synthesize speech with a higher quality while maintaining equal conversion- accuracy for speaker individuality compared with the GMM-based algorithm.",
	address = "Japan",
	author = "Toda, T.",
	lockkey = "Y",
	school = "Nara Institute of Science and Technology",
	title = "{High-Quality and Flexible Speech Synthesis with Segment Selection and Voice Conversion}",
	year = "2003"
}

@phdthesis{DegottexG2010phd,
	abstract = "This study addresses the problem of inverting a voice production model of a given recording to retrieve a representation of the sound source which is generated at the glottis level, the glottal source, and a representation of the resonances and anti-resonances made by the cavities of the vocal-tract. This separation of the elements composing the voice gives the possibility to manipulate independently the characteristics of the voice source and the timber of the resonances. There are many applications of this subject like the ones presented in this study, namely voice transformation and speech synthesis, as well as many others such as identity conversion, expressivity synthesis, voice restoration which can be used in entertainment technologies, artistic sound installations, movies and music industry, toys and video games, telecommunication, etc. In this study, we assume that the perceived elements of the voice can be manipulated using the well known source-filter model. In the spectral domain, 
voice production is thus described as a multiplication of the spectra of its elements, the glottal source, the vocal-tract filter and the radiation. The second assumption used in this study concerns the deterministic component of the glottal source. Indeed, we assume that a glottal model can fit one period of the glottal source. Using such an analytical description, the amplitude and phase spectra of the deterministic source are linked through the shape parameter of the glottal model. Regarding the state of the art of voice transformation and speech synthesis methods, the naturalness and the control of the transformed and synthesized voices should be improved. Accordingly, we try to answer the three following questions: 1) How to estimate the parameter of a glottal model? 2) How to estimate the vocal-tract filter according to this glottal model? 3) How to transform and synthesize a voiced signal using this glottal model? Special attention is given to the first question. First, we assume that the glottal 
source and the impulse response of the vocal-tract filter are mixed-phase and minimum-phase signals respectively. Then, based on these properties, various methods are proposed which minimize the mean squared phase of the convolutive residual of an observed spectrum and its model. A last method is described where a unique shape parameter is in a quasi closed-form expression of the observed spectrum. Additionally, this study discusses the conditions a glottal model and its parametrization have to satisfy in order to ensure that the parameters are efficiently estimated using the proposed methods. These methods are also evaluated and compared to state of the art methods using synthetic and electro-glotto-graphic signals. Using one of the proposed methods, the estimation of the shape parameter is independent of the position and the amplitude of the glottal model. Moreover, it is shown that this same method outperforms all the compared methods. To answer the second and third questions addressed in this study, we 
propose an analysis/synthesis procedure which estimates the vocal-tract filter according to an observed spectrum and its estimated source. Preference tests have been carried out and their results are presented in this study to compare the proposed procedure to the existing ones. In terms of pitch transposition, it is shown that the overall quality of the voiced segments of a recording can be better transposed for important transposition factors. It is also shown that the breathiness of a voice can be properly controlled.",
	address = "France",
	author = "Degottex, Gilles",
	lockkey = "Y",
	owner = "degottex",
	school = "UPMC-Ircam",
	timestamp = "2008.01.09",
	title = "{Glottal source and vocal-tract separation}",
	year = 2010
}

@inproceedings{Villavicencio2008a,
	address = "Las Vegas",
	author = "Villavicencio, Fernando and R{\"o}bel, Axel and Rodet, Xavier",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	month = "April",
	statut-editorial = "accept{\'e} - publication en cours",
	title = "{Extending efficient spectral envelope modeling to mel-frequency based representation}",
	url = "http://articles.ircam.fr/textes/Villavicencio08a",
	year = "2008"
}

@inproceedings{Degottex2009d,
	abstract = "En transformation et synth{\`e}se de la voix, le filtre du conduit-vocal est habituellement suppos{\'e} {\{\{\{\^e}}}}tre excit{\'e} par un spectre d'amplitude plat. Nous proposons d'utiliser un mod{\`e}le de source mixte: un mod{\`e}le de Liljencrants-Fant (LF) et un bruit Gaussien. L'estimation du conduit-vocal doit donc {\{\{\{\^e}}}}tre adapt{\'e} {\`a} cette source en prenant en compte les amplitudes du mod{\`e}le LF dans les basses fr{\'e}quences et le bruit dans les hautes fr{\'e}quences. Le mod{\`e}le de production vocal r{\'e}sultant peut ensuite {\{\{\{\^e}}}}tre utilis{\'e} pour contr{\{\{\{\^o}}}}ler ind{\'e}pendamment le conduit-vocal et la source dans le cadre de la transformation de la voix et pour l'apprentissage de ses param{\`e}tres dans la synth{\`e}se vocale HMM.",
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	booktitle = "{Journ{\'e}es Jeunes Chercheurs en Audition, Acoustique musicale et Signal audio, JJCAAS}",
	file = "http://recherche.ircam.fr/equipes/analyse-synthese/degottex/uploads/Main/Degottex2009e.pdf",
	lockkey = "Y",
	month = "November",
	pdf = "Degottex2009e.pdf",
	title = "{Estimation du filtre du conduit-vocal adapt{\'e}e {\`a} un mod{\`e}le d'excitation mixte pour la transformation et la synth{\`e}se de la voix}",
	year = 2009
}

@inproceedings{HamonC1989,
	abstract = "A novel time-domain algorithm is presented for text-to-speech synthesis using diphone concatenation. The algorithm is based on the pitch-synchronous overlap-add (PSOLA) approach and is capable of good quality prosodic modifications of natural speech. The algorithm can be seen as a simplification of a previous algorithm combining the PSOLA approach and frequency-domain transformations. On the other hand, it appears as a generalization of previous time-domain methods that perform pitch synchronous cut-and-splice operations on the speech waveform. This algorithm is used in the CNET diphone synthesis multilingual system, actually supporting three languages: French, Italian, and German. The resulting speech has been tested on French and is judged of much better quality than for an LPC-based synthesizer",
	author = "Hamon, C. and Mouline, E. and Charpentier, F.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1989.266409",
	issn = "1520-6149",
	keywords = "diphone synthesis multilingual system; French; German; Italian; PSOLA; diphone concatenation; diphone synthesis system; frequency-domain transformations; natural speech; pitch synchronous cut-and-splice operations; pitch-synchronous overlap-add; speech waveform; text-to-speech synthesis; time-domain algorithm; time-domain prosodic modifications; speech synthesis",
	lockkey = "Y",
	pages = "238--241",
	title = "{A diphone synthesis system based on time-domain prosodic modifications of speech}",
	volume = "1",
	year = "1989"
}

@article{MoulinesE1990,
	abstract = "We review in a common framework several algorithms that have been proposed recently, in order to improve the voice quality of a text-to-speech synthesis based on acoustical units concatenation (Charpentier and Moulines, 1988; Moulines and Charpentier, 1988; Hamon et al., 1989). These algorithms rely on a pitch-synchronous overlap-add (PSOLA) approach for modifying the speech prosody and concatenating speech waveforms. The modifications of the speech signal are performed either in the frequency domain (FD-PSOLA), using the Fast Fourier Transform, or directly in the time domain (TD-PSOLA), depending on the length of the window used in the synthesis process. The frequency domain approach is capable of a great flexibility in modifying the spectral characteristics of the speech signal, while the time domain approach provides very efficient solutions for the real time implementation of synthesis systems. We also discuss the different kinds of distortions involved in these different algorithms.",
	author = "Moulines, E. and Charpentier, F.",
	doi = "10.1016/0167-6393(90)90021-Z",
	issn = "0167-6393",
	journal = "Speech Communication",
	keywords = "pitch-synchronous overlap-aid (PSOLA)",
	lockkey = "Y",
	note = "Neuropeech '89",
	number = "5-6",
	pages = "453--467",
	title = "{Pitch-synchronous waveform processing techniques for text-to-speech synthesis using diphones}",
	url = "https://acces-distant.upmc.fr:443/http/www.sciencedirect.com/science/article/B6V1C-48V21PK-GV/2/44631563bec26c612aa6c220164d71d1",
	volume = "9",
	year = "1990"
}

@article{HasegawaT1990,
	author = "Hasegawa, Takahi and Kido, Tohru and Takeda, Shigeki and Inoue, Naoki and Matsuzawa, Kiichiro",
	doi = "10.1121/1.400316",
	journal = "Journal of the Acoustical Society of America",
	keywords = "SOUND PRESSURE; PISTONS; SPHERES; SPHERICAL HARMONICS; BOUNDARY CONDITIONS; SOUND FIELDS",
	lockkey = "Y",
	number = "3",
	pages = "1578--1583",
	publisher = "ASA",
	title = "{Acoustic radiation force on a rigid sphere in the near field of a circular piston vibrator}",
	url = "http://link.aip.org/link/?JAS/88/1578/1",
	volume = "88",
	year = "1990"
}

@book{PierceA1981,
	author = "Pierce, A. D.",
	lockkey = "Y",
	publisher = "McGraw-Hill",
	title = "{Acoustics: An Introduction to Its Physical Principles and Applications}",
	year = "1981"
}

@phdthesis{RoubeauB1993,
	abstract = "L'ensemble de l'{\'e}tendue des fr{\'e}quences r{\'e}alisables par le vibrateur laryng{\'e} a {\'e}t{\'e} explor{\'e} chez 19 sujets des deux sexes, de niveaux d'entra{\{\^i}}nement vocal diff{\'e}rents. 1) L'analyse spectrale du signal acoustique d'une part et l'analyse {\'e}lectroglottographique (EGG) de la vibration laryng{\'e}e d'autre part, ont permis d'identifier les diff{\'e}rents m{\'e}canismes vibratoires communs {\`a} tous les individus et de compl{\'e}ter la notion de registre vocal, employ{\'e}e dans la litt{\'e}rature, par celles de registre ``<laryng{\'e}''> et de registre ``<r{\'e}sonantiel''>. 2) L'{\'e}tude de la forme d{\'e}taill{\'e}e de l'onde EGG a permis de d{\'e}finir les limites de la fiabilit{\'e} de ce type d'observation de l'activit{\'e} laryng{\'e}e. 3) La transition entre deux m{\'e}canismes vibratoires appara{\{\^i}}t comme une entit{\'e} physiologique caract{\'e}ris{\'e}e par une succession d'{\'e}v{\'e}nements affectant l'amplitude, la fr{\'e}quence et les param{\
`e}tres temporels du signal EGG. Ces {\'e}v{\'e}nements refl{\`e}tent les modifications m{\'e}caniques que subit le vibrateur laryng{\'e}, en rapport avec le contr{\{\^o}}le neuromusculaire et central de la vibration. 4) L'activit{\'e} EMG du muscle cricothyroÃÂ¯dien (CT) et de trois muscles sous-hyoÃÂ¯diens est {\'e}tudi{\'e}e sur l'ensemble de l'{\'e}tendue au cours de la r{\'e}alisation de glissandos. Le muscle CT pr{\'e}sente une activit{\'e} en {\'e}troite relation avec l'{\'e}l{\'e}vation de la fr{\'e}quence tandis que l'activit{\'e} des sous-hyoÃÂ¯diens suit le sens g{\'e}n{\'e}ral d'abaissement de celle-ci. Ces cat{\'e}gories musculaires aux activit{\'e}s oppos{\'e}es sont mobilis{\'e}es de fa\c{c}on synchrone lors de la r{\'e}alisation des fr{\'e}quences extr{\{\^e}}mes.",
	address = "France",
	author = "Roubeau, Bernard",
	lockkey = "Y",
	school = "Paris11-Orsay",
	title = "{M{\'e}canismes vibratoires laryng{\'e}s et contr{\{\^o}}le neuro-musculaire de la fr{\'e}quence fondamentale}",
	year = "1993"
}

@article{DovalB2006,
	abstract = "A unified description of the most-common glottal-flow models (KLGLOTT88, Rosenberg C, R++. LF) is proposed in the time domain, using a set of five generic glottal-flow parameters: fundamental period, maximum excitation, open quotient, asymmetry coefficient, and return-phase quotient. A unified set of time-domain equations is derived, and their analytical Laplace-transform computation leads to a set of frequency-domain equations. On the basis of this mathematical framework, the spectral properties of the glottal-flow models and their derivatives are studied. It is shown that any glottal-flow model can be described by a combination of low-pass filters, the cut-off frequencies and amplitudes of which can be expressed directly in terms of time-domain parameters. The spectral correlates of time-domain glottal-flow parameters are then explored. It is shown that the maximum excitation corresponds to a gain factor, and that it controls the mid-to-high-frequency spectral slope. A non-null return-phase 
quotient adds an additional spectral tilt in the high-frequency part of the glottal-flow spectrum. The open quotient and asymmetry coefficient are related to the low-frequency spectral peak, also called the glottal formant. The glottal-formant frequency is mainly controlled by the open quotient, and its amplitude (or bandwidth) by the asymmetry coefficient. As a direct application, it is shown that the amplitude difference between the first two harmonics, commonly assumed to be correlated to the open quotient, is also theoretically dependent on the asymmetry coefficient.",
	author = "Doval, B. and d'Alessandro, C. and Henrich, N.",
	journal = "Acta acustica united with acustica",
	keywords = "Asymmetry; Bandwidth; Cut off frequency; Formant; Frequency domain method; Glottis; High frequency; Laplace transformation; Low frequency; Low pass filter; Medium frequency; Modeling; Phonation; Spectral properties; Tilt angle; Time domain method; Vocal tract",
	lockkey = "Y",
	number = "6",
	pages = "1026--1046",
	title = "{The spectrum of glottal flow models}",
	volume = "92",
	year = "2006"
}

@article{BarneyA2007,
	abstract = "In the classical theory of vowel production it is standard to assume linear separability of the voicing source, located at the glottis, from the vocal tract downstream. In this paper we consider an effect of relaxing this assumption and investigate how the open phase of the glottal cycle may affect the acoustic response of the vocal tract. A mechanical model of the larynx and vocal tract is used to make measurements of the formant frequencies with both a static glottis and a time-varying glottal area. For the static glottis the vocal tract was excited by an external sound source. The first and second formant frequencies increased with increasing glottal width. For the widest glottis investigated the upward shift in the first formant was 13\% of the value found with a closed glottis. The direction of the shift is well-modelled by a theoretical transmission line model of the vocal tract for which the value of the glottal impedance can be varied, although the F1 values are underestimated by 
approximately 5\%. For the time-varying glottis the acoustic excitation came from the periodic interruption of a steady air-flow. The first formant frequency increased with both increasing glottal width and increasing glottal open quotient. Our findings have implications for realistic modelling of modal voice, especially where there is a permanent glottal leak, and breathy voice including pathological cases.",
	author = "Barney, A. and {de Stefano}, A. and Henrich, N.",
	journal = "Acta Acustica united with Acustica",
	lockkey = "Y",
	number = "6",
	pages = "1046--1056",
	title = "{The effect of glottal opening on the acoustic response of the vocal tract}",
	volume = "93",
	year = "2007"
}

@article{HermesD1991,
	author = "Hermes, D. J.",
	journal = "Speech Communication",
	lockkey = "Y",
	pages = "497--502",
	title = "{Synthesis of breathy vowels: Some research methods}",
	volume = "10",
	year = "1991"
}

@article{HermesD1988,
	abstract = "In order to account for the phenomenon of virtual pitch, various theories assume implicitly or explicitly that each spectral component introduces a series of subharmonics. The spectral-compression method for pitch determination can be viewed as a direct implementation of this principle. The widespread application of this principle in pitch determination is, however, impeded by numerical problems with respect to accuracy and computational efficiency. A modified algorithm is described that solves these problems. Its performance is tested for normal speech and ``telephone'' speech, i.e., speech high-pass filtered at 300 Hz. The algorithm outperforms the harmonic-sieve method for pitch determination, while its computational requirements are about the same. The algorithm is described in terms of nonlinear system theory, i.c., subharmonic summation. It is argued that the favorable performance of the subharmonic-summation algorithm stems from its corresponding more closely with current pitch-perception 
theories than does the harmonic sieve.",
	author = "Hermes, D. J.",
	doi = "10.1121/1.396427",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "1",
	pages = "257--264",
	publisher = "ASA",
	title = "{Measurement of pitch by subharmonic summation}",
	url = "http://link.aip.org/link/?JAS/83/257/1",
	volume = "83",
	year = "1988"
}

@article{HansonH1997,
	abstract = "The aim of the research reported in this paper is to formulate a set of acoustic parameters of the voicing source that reflect individual differences in the voice qualities of female speakers. Theoretical analysis and observations of experimental data suggest that a more open glottal configuration results in a glottal volume-velocity waveform with relatively greater low-frequency and weaker high-frequency components, compared to a waveform produced with a more adducted glottal configuration. The more open glottal configuration also leads to a greater source of aspiration noise and larger bandwidths of the natural frequencies of the vocal tract, particularly the first formant. These different attributes of the glottal waveform can be measured directly from the speech spectrum or waveform. A set of acoustic parameters that are likely to indicate glottal characteristics is described. These parameters are measured in the speech of a group of female speakers, and the glottal configurations of the 
speakers are hypothesized. This research contributes to the description of normal variations of voicing characteristics across speakers and to a continuing effort to improve the analysis and synthesis of female speech. It may also have applications in clinical settings.",
	author = "Hanson, H. M.",
	doi = "10.1121/1.417991",
	journal = "Journal of the Acoustical Society of America",
	keywords = "speech processing; speech synthesis",
	lockkey = "Y",
	number = "1",
	pages = "466--481",
	publisher = "ASA",
	title = "{Glottal characteristics of female speakers: Acoustic correlates}",
	url = "http://link.aip.org/link/?JAS/101/466/1",
	volume = "101",
	year = "1997"
}

@inproceedings{KawaharaH2008,
	abstract = "A simple new method for estimating temporally stable power spectra is introduced to provide a unified basis for computing an interference-free spectrum, the fundamental frequency (F0), as well as aperiodicity estimation. F0 adaptive spectral smoothing and cepstral liftering based on consistent sampling theory are employed for interference-free spectral estimation. A perturbation spectrum, calculated from temporally stable power and interference-free spectra, provides the basis for both F0 and aperiodicity estimation. The proposed approach eliminates ad-hoc parameter tuning and the heavy demand on computational power, from which STRAIGHT has suffered in the past.",
	author = "Kawahara, H. and Morise, M. and Takahashi, T. and Nisimura, R. and Irino, T. and Banno, H.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2008.4518514",
	issn = "1520-6149",
	keywords = "adaptive estimation; adaptive signal processing; adaptive spectral smoothing; aperiodicity estimation; cepstral analysis; cepstral liftering; consistent sampling theory; interference-free spectral estimation; interference (signal); periodic signal power spectral representation; perturbation spectrum; signal sampling; smoothing methods; speech processing; speech synthesis; TANDEM-STRAIGHT",
	lockkey = "Y",
	pages = "3933--3936",
	title = "{Tandem-{STRAIGHT}: A temporally stable power spectral representation for periodic signals and applications to interference-free spectrum, F0, and aperiodicity estimation}",
	year = "2008"
}

@article{SchroederM1986,
	author = "Schroeder, M. R. and Strube, H. W.",
	doi = "10.1121/1.393292",
	journal = "Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "5",
	pages = "1580--1583",
	publisher = "ASA",
	title = "{Flat-spectrum speech}",
	url = "http://link.aip.org/link/?JAS/79/1580/1",
	volume = "79",
	year = "1986"
}

@phdthesis{AirasM2008,
	abstract = "Voice quality, deÃ¯Â¬Âned by John Laver as the characteristic auditory colouring of a speaker{\rq}s voice, is a signiÃ¯Â¬Âcant feature of speech, and it is used to signal various properties such as emotions, intentions, and mood of the speaker. While voice quality measurement techniques and algorithms have been developed, much work is needed to obtain a comprehensive view of the function and analysis of human voice in the production of different voice qualities. Two major research questions are presented in this thesis: First, how can the most important laryngeal voice quality features be analyzed, and second, how do the voice quality features affect different facets of vocal expression? To answer these questions, Ã¯Â¬Âve separate studies of the analysis methodology and two studies regarding the voice quality behaviour were published. The methodology articles describe a voice source analysis software package; a comparison of multiple voice source parameters in breathy, normal, and pressed 
phonation; a method for evaluating inverse Ã¯Â¬Âltering algorithms; comparison of two inverse Ã¯Â¬Âltering algorithms; and a method for analyzing intensity regulation of speech. One analysis article studies changes in the laryngeal voice quality when different emotions are expressed in speech and another voice quality changes in expression of prominence in continuous speech. The methodology studies resulted in new tools, methods, and guidelines for voice source analysis, while the analysis studies provide information on how voice quality is used in expressive speech.",
	address = "Finland",
	author = "Airas, Matti",
	lockkey = "Y",
	school = "Helsinki University of Technology",
	title = "{Methods and studies of laryngeal voice quality analysis in speech production}",
	year = "2008"
}

@article{RoubeauB2009,
	abstract = "Summary: This study, focused on the laryngeal source level, introduces the concept of laryngeal vibratory mechanism. Human phonation is characterized by the use of four laryngeal mechanisms, labeled M0--M3, as evidenced by the elec- troglottographic (EGG) study of the transition phenomena between mechanisms with a population of men and women, trained and untrained singers. Macroscopic and local descriptions of the EGG signal are analyzed during the production of glissandos and held notes with different mechanisms. The transition from one mechanism to another of higher rank is characterized by a jump in frequency, a reduction of EGG amplitude, and a change in the shape of the derivative of the EGG (which may correspond to a reduction of the vibratory mass). These characteristics are used to identify a transition between two mechanisms, in complement with acoustic spectrographic analyses. The pitches of transitions between the two main mechanisms M1 and M2 and the range of the frequency-overlap 
region are described in detail. The notion of vocal register is revisited in the light of these concepts of laryngeal mechanism. The literature on vocal registers is re- viewed, and it is shown that the confusion often cited with respect to this notion may be related to the heterogeneity of the approaches and methods used to describe the phenomena and to the multiplicity of descriptors. Therefore, the ter- minology of the registers is organized depending on their relation to the four laryngeal vibratory mechanisms.",
	author = "Roubeau, B. and Henrich, N. and Castellengo, M.",
	journal = "Journal of Voice",
	keywords = "Laryngeal mechanism--Electroglottography--Larynx--Singing voice--Voice range--Register.",
	lockkey = "Y",
	number = "4",
	pages = "425--438",
	title = "{Laryngeal Vibratory Mechanisms: The Notion of Vocal Register Revisited}",
	volume = "23",
	year = "2009"
}

@inproceedings{OliveiraL1993,
	abstract = "The new generation of text-to-speech systems needs the ability to control the voice quality of the synthesized speech by varying the excitation source. This feature is fundamental to improve naturalness and to synthesize female or child voices. The variation of the voice quality is also important when trying to synthesize expression. The problem involves two aspects: the ability to control the source parameters of the speech synthesizer and the possibility of extracting these parameters from natural speech. This paper describes a source model based on the poly-nomial model for the glottal flow suggested by Rosenberg [9] that has an exact representation in the frequency domain, and an automated procedure to estimate its parameters from natural speech.",
	author = "Oliveira, L. C.",
	booktitle = "{Proc. Eurospeech}",
	lockkey = "Y",
	pages = "99--102",
	title = "{Estimation of Source Parameters by Frequency Analysis}",
	year = "1993"
}

@article{RodetX1984,
	abstract = "The CHANT project was originally concerned with the analysis and synthesis of the singing voice. This work led to a complex programof voice synthesis- by-rule: CHANT. This programwas enriched with a constantly expanding software environment, con- sisting of both analysis and composition programs. In time, broaderaims than the synthesis of the voice imposed themselves. These aims cen- singing tered on the search for models of the processes in- volved in the production of musical sound. Our present research encompasses the physical descrip- tion of sound phenomena (the sonic material), the articulation of these phenomena (organization), and compositional issues.",
	author = "Rodet, X. and Potard, Y. and Barriere, J.-B.",
	journal = "Computer Music Journal",
	lockkey = "Y",
	number = "3",
	pages = "15--31",
	title = "{The {CHANT} project: from synthesis of the singing voice to synthesis in general}",
	volume = "8",
	year = "1984"
}

@inproceedings{GrauS1993,
	abstract = "This paper describes a new type of speech synthesizer: a parametric-concatenation (PACO) speech synthesizer, which is suitable both for formant synthesis and concatenation synthesis. This synthesizer is based on a hybrid quasi-harmonic and random formant-waveforms model of the speech signal. The synthesizer can be controlled by acoustic parameters : formant parameters and voice source parameters expressed in frequency domain. These acoustic parameters are converted into sinusoidal and formant waveforms parameters. The keypoint of this method is that spectral amplitudes are set according to a parallel formant model (both on sinusoidal waveforms and random formant-waveforms), whereas the spectral phases are set according to a serial formant model for sinusoidal waveforms (and are randomly distributed for formant waveforms). This approach avoids the phase interference problems inherent to parallel synthesis, while keeping the advantage of formant amplitudes control. An automatic analysis-synthesis 
system is also proposed for segments coding. Our model has been successfully implemented both as a formant synthesis system and in a concatenation synthesis Text-To-Speech system.",
	author = "Grau, S. and d'Alessandro, C. d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro d'Alessandro and Richard, G.",
	booktitle = "{Proc. Eurospeech}",
	keywords = "Speech synthesis; formant and concatenation synthesis; harmonic representation; random formant waveforms",
	lockkey = "Y",
	pages = "1697--1700",
	title = "{A Speech Formant Synthesizer Based on Harmonic + Random Formant-Waveforms Representations}",
	year = "1993"
}

@inproceedings{DovalB1993,
	abstract = "A new approach is presented for the estimation and tracking of the fundamental frequency (f0) of pseudoperiodic signals. It is based on a probabilistic model of pseudoperiodic signals that makes it possible to take prior knowledge into account and to include constraints on the evolution of the signal. The resulting method can operate on a large interval of f0 values (typically from 50 to 4000 Hz) and on a great variety of sound signals (speech and music signals)",
	author = "Doval, B. and Rodet, X.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1993.319095",
	keywords = "50 Hz to 4 kHz; HMMs; fundamental frequency estimation; fundamental frequency tracking; maximum likelihood harmonic matching; music; probabilistic model; pseudoperiodic signals; speech; audio signals; hidden Markov models; maximum likelihood estimation; tracking",
	lockkey = "Y",
	pages = "221--224",
	title = "{Fundamental frequency estimation and tracking using maximum likelihood harmonic matching and HMMs}",
	volume = "1",
	year = "1993"
}

@inproceedings{LarocheJ1993,
	author = "Laroche, J. and Stylianou, Y. and Moulines, E.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.1993.319365",
	isbn = "0-7803-0946-4",
	lockkey = "Y",
	pages = "550--553",
	title = "{HNS: Speech modification based on a harmonic+noise model}",
	volume = "2",
	year = "1993"
}

@book{CrystalD1998,
	author = "Crystal, David and Varley, Rosemary",
	lockkey = "Y",
	publisher = "John Wiley and Sons ltd",
	title = "{Introduction to language pathology}",
	year = "1998"
}

@inproceedings{FantG1994,
	abstract = "This is a report on a data reduction scheme for studies of voice source characteristics in connected speech and some results from speech analysis within a segmental and prosodic frame. It is shown that essentials of glottal wave shape are included in the ratio of peak glottal volume velocity U0 to the negative peak Ee of glottal flow derivative. Default values of the complete set of LF-source parameters F0, Ee, Ra, Rk, Rg can be predicted from F0, Ee and U0/Eg. Of special importance is the relation of Ee and U0 to F0. Additional adjustments related to voice type and contextual demands are included. Simplified inverse filtering methods for extraction and direct recording of U0(t) and Ee(t) in synchrony with F0(t) are described. The dependency of source parameters on voice fundamental frequency F0, global phrase structure, loudness, stress and accents, and the influence of segmental type and supraglottal and subglottal interaction effects are briefly discussed.",
	author = "Fant, G. and Kruckenberg, A. and Liljencrants, J. and Bavegdrd, M.",
	booktitle = "{Proc. International Conference on Spoken Language Processing (ICSLP)}",
	lockkey = "Y",
	pages = "1451--1454",
	title = "{Voice Source Parameters in Continuous Speech, Transformation of {LF}-Parameters}",
	year = "1994"
}

@techreport{Agiomyrgiannakis2009c,
	author = "Agiomyrgiannakis, Y.",
	institution = "UOC?",
	lockkey = "Y",
	title = "{On Phase-aware Speech Analysis: revisiting Voice Conversion and Voice Transformation}",
	year = "2009?"
}

@article{AgusT2010,
	author = "Agus, Trevor R. and Thorpe, Simon J. and Pressnitzer, Daniel",
	journal = "Neuron",
	lockkey = "Y",
	number = "4",
	pages = "610--618",
	title = "{Rapid Formation of Robust Auditory Memories: Insights from Noise}",
	volume = "66",
	year = "2010"
}

@article{AnanthapadmanabhaTV1982,
	abstract = "An iterative numerical algorithm is presented for camputing the true glottal flow given the glottal area function and lung pressure. The effectsofglottalin- ertance and sub- and supraglottal impedance are discussed. It is sham that the effect of glottal inertance is small and that it is adequate t o consider subglot- t a l and supraglottal systems by one-formant loads only. A n equivalentcircuitfor the g l o t t i s considering the nonlinear and time-varying pressure-flw relation is derived. In addition t o the dynamic glottal resistance, there exists a hypothet- i c a l inductance in the equivalent circuit which is minly responsible fortheskew- ing of the source pulses under load. An analytical equation for the m i n p l s e shape of the true glottal f l w i s derived as the source residue. Theroleof rip- ple conponents in the true glottal f l w is discussed.",
	author = "Ananthapadmanabha, T. V. and Fant, G.",
	journal = "STL-QPSR",
	lockkey = "Y",
	number = "1",
	pages = "001--030",
	title = "{Calculation of true glottal flow and its components}",
	volume = "23",
	year = "1982"
}

@phdthesis{AshbyS2004,
	abstract = "This thesis investigates whether properties of speech to infants may be classiÃ¯Â¬Âed as hyperspeech modiÃ¯Â¬Âcations, as deÃ¯Â¬Âned by Lindblom{\rq}s H\&H Theory. Hyperspeech is deÃ¯Â¬Âned as an attempt by speakers to meet listeners{\rq} communicative and situational demands by increasing the distinctiveness of speech sounds for enhanced lexical iden- tiÃ¯Â¬Âcation. Previous research has presented infant-directed (ID) speech as an accommodative style whose acoustic features provide babies with structured input for making sense of speech and acquiring mappings between sound and meaning. Implicit in some of these claims is the notion that ID speech is better formed---i.e. it involves hyperar- ticulation as per Lindblom{\rq}s deÃ¯Â¬Ânition---compared to adult-directed speech. Yet, with most investigations focused on eÃ¯Â¬Âects of this style on infants{\rq} perceptual abilities, little quantitative information is available for the ID speech signal itself. This thesis aims to describe the 
acoustic properties of ID speech, and evaluate the systematicity of such variations with respect to other accommodative styles. By comparing ID speech with other listener-oriented styles, two questions are ad- dressed. First, do diÃ¯Â¬Âerent listener constraints elicit characteristic forms of modulation by speakers? Few studies have examined how listener constraints interact with modu- lation of the signal. Results for this investigation show that for experimental conditions representing computer-directed speech, {\lq}foreigner talk{\rq}, and Lombard speech, subjects varied systematically depending on the type of listener being addressed. In contrast, for both simulated and real ID speech conditions, speakers exercised considerable Ã¯Â¬Âex- ibility in the manipulation of selected acoustic parameters. Second, how does ID speech compare with other accommodative styles in the use of hyperspeech? I conclude that ID speech may involve production of clear speech features, but that unlike speech to an 
artiÃ¯Â¬Âcial or non-native addressee (i.e. other modalities involving conceptual and/or linguistic constraints on the part of the inter- locutor), use of such features is far less consistent across speakers.",
	address = "Irland",
	author = "Ashby, Simone",
	lockkey = "Y",
	school = "University College Dublin",
	title = "{Is Infant-directed Speech Hyperspeech? An Acoustical Analysis of Speech to Infants and Other Accommodative Speech Styles}",
	year = "2004"
}

@article{BanerjeeA2005,
	abstract = "A wide variety of distortion functions, such as squared Euclidean distance, Mahalanobis distance, Itakura-Saito distance and relative entropy, have been used for clustering. In this paper, we pro- pose and analyze parametric hard and soft clustering algorithms based on a large class of distortion functions known as Bregman divergences. The proposed algorithms unify centroid-based paramet- ric clustering approaches, such as classical kmeans, the Linde-Buzo-Gray (LBG) algorithm and information-theoretic clustering, which arise by special choices of the Bregman divergence. The algorithms maintain the simplicity and scalability of the classical kmeans algorithm, while gener- alizing the method to a large class of clustering loss functions. This is achieved by Ã¯Â¬Ârst posing the hard clustering problem in terms of minimizing the loss in Bregman information, a quantity motivated by rate distortion theory, and then deriving an iterative algorithm that monotonically de- creases this loss. In addition, 
we show that there is a bijection between regular exponential families and a large class of Bregman divergences, that we call regular Bregman divergences. This result enables the development of an alternative interpretation of an efÃ¯Â¬Âcient EM scheme for learning mix- tures of exponential family distributions, and leads to a simple soft clustering algorithm for regular Bregman divergences. Finally, we discuss the connection between rate distortion theory and Breg- man clustering and present an information theoretic analysis of Bregman clustering algorithms in terms of a trade-off between compression and loss in Bregman information.",
	author = "Banerjee, Arindam and Merugu, Srujana and Dhillon, Inderjit S. and Ghosh, Joydeep",
	journal = "Journal of Machine Learning Research",
	lockkey = "Y",
	pages = "1705--1749",
	title = "{Clustering with Bregman Divergences}",
	year = "2005"
}

@article{CampedelOudotM2001,
	abstract = "Estimation of the spectral envelope (magnitude of the transfer function) of a filter driven by a periodic signal is a long-standing problem in speech and audio processing. Recently, there has been a renewed interest in this issue in connection with the rapid developments of processing techniques based on sinusoidal modeling. In this paper, we introduce a new performance criterion for spectral envelope fitting which is based on the statistical analysis of the behavior of the empirical sinusoidal magnitude estimates. We further show that penalization is an efficient approach to control the smoothness of the estimation envelope. In low-noise situations, the proposed method can be approximated by a two-step weighted least-squares procedure which also provides an interesting insight into the limitations of the previously proposed ldquo;discrete cepstrum rdquo; approach. A systematic simulation study confirms that the proposed methods perform significantly better than existing ones for high pitched 
and noisy signals",
	author = "Campedel-Oudot, M. and Cappe, O. and Moulines, E.",
	doi = "10.1109/89.928912",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "audio processing; discrete cepstrum; estimation envelope smoothness control; filter; high pitched signals; low-noise; noisy signals; penalized likelihood approach; performance criterion; periodic signal; simulation study; sinusoidal magnitude estimates; sinusoidal modeling; spectral envelope estimation; spectral envelope fitting; speech processing; statistical analysis; transfer function estimation; voiced sounds; weighted least-squares; cepstral analysis; filtering theory; least squares approximations; parameter estimation; speech processing; transfer functions",
	lockkey = "Y",
	number = "5",
	pages = "469--481",
	title = "{Estimation of the spectral envelope of voiced sounds using a penalized likelihood approach}",
	volume = "9",
	year = "2001"
}

@article{CarlyonR2003,
	abstract = {Listeners can detect phase differences between the envelopes of sounds occupying remote frequency regions, and between the fine structures of partials that interact within a single auditory filter. They are insensitive to phase differences between partials that differ sufficiently in frequency to preclude within-channel interactions. A new model is proposed that can account for all three of these findings, and which, unlike currently popular approaches, does not discard across-channel timing information. Sensitivity is predicted quantitatively by analyzing the output of a cochlear model using a spectro-temporal decomposition inspired by responses of neurons in the auditory cortex, and by computing a distance metric between the responses to two stimuli to be discriminated. Discriminations successfully modeled include phase differences between pairs of bandpass filtered harmonic complexes, and between pairs of sinusoidally amplitude modulated tones, discrimination between amplitude and frequency 
modulation, and discrimination of transient signals differing only in their phase spectra ("Huffman sequences").},
	author = "Carlyon, Robert P. and Shamma, Shihab",
	doi = "10.1121/1.1577557",
	journal = "Journal of the Acoustical Society of America",
	keywords = "hearing; physiological models; ear",
	lockkey = "Y",
	number = "1",
	pages = "333--348",
	publisher = "ASA",
	title = "{An account of monaural phase sensitivity}",
	url = "http://link.aip.org/link/?JAS/114/333/1",
	volume = "114",
	year = "2003"
}

@mastersthesis{Degottex2006,
	abstract = "The goal of musical signal separation is two split a mono recording of music into sources where sources are considered as musical instrument voices. Because the energy of a instrument sound hold basically harmonic frequencies, after decomposing a recording into frames with a STFT, the main goal is to Ã¯Â¬Ând, for each source, and reconstruct the harmonic structure (the frequencies and amplitudes of each partials). An algorithm was already studied in a previous mini-project [2] based on an article of Mark R. Every and John E. Szymanski [3]. The approach was a constructive (bottom-to-top) one. The algorithm was designed to construct the solution step by step from raw data (mainly local peaks (the spectral lines)) to the highest level object seen in the project, a mixture of harmonic structures. This report present an approach where a probabilistic model is built to Ã¯Â¬Ât the sound as best as possible. From this point of view, the corresponding algorithm evaluates a certain number of potential 
models to extract the best one. I decided to build my own probabilistic model and a particular algorithm instead of reproducing a method of an article as I did for the mini-project. Not all hypothesis were fulÃ¯Â¬Âlled but as we will see in the results, the probabilistic solution is not so far from the complete method of Mark R. Every and John E. Szymanski and as expected, it brings me a lot of intuition about probabilistic models. Most of the process is common to both approach. And these common parts come essentially from the article of M.R. Every and J.E. Szymanski. For each step of the process, the reference [3] is used when the idea comes from their article and no reference is mentioned when I replaced their solution or no explanation was given in the article. Two tests have been achieved on recordings of two Ã¯Â¬Âutes which are convenient for the a priori of the two methods and their possible application context. And so a comparison of the two method is presented at the end of this document. In 
comparison to the report of the previous project [2], several written parts are commons with this report because a big part of the two method is identical. Since I{\rq}ve to explain the whole process of the new approach (including the common parts) and the process of the constructive method is not so imposing, I decided to keep all descriptions of the previous report in this new one and thus, this document is not dependent from the previous one. Moreover, it gives me the occasion to correct one or two things from the previous document and present all the practical works I did this year in only one document. Readers who already red the report of the mini- project should skip sections 3 and 2 except sections 2.4.1 and 3.3 which have been added and improved respectively.",
	address = "Suisse",
	author = "Degottex, Gilles",
	lockkey = "Y",
	school = "EPFL",
	title = "{Spectral filtering and Probabilistic model for Musical signal separation}",
	year = "2006"
}

@phdthesis{HuberS2009,
	abstract = "The aim of this thesis work is the transformation of timing, time duration and fundamental frequency of audio objects like single notes or a melody line of one in- strument within a polyphonic audio environment. The research is limited to harmonic audio objects which are comprised of a series of frequency partials sharing a quasi- harmonic interval relation among them. With this percussive sounds of stochastic nature without sinusoidal content are excluded while the stochastic component as intrinsic part of diÃ¯Â¬Âerent instruments is considered because of its perceptual signiÃ¯Â¬Â- cance. A priori knowledge about the pitch and timing of each note is required from a MIDI Ã¯Â¬Âle including several mono tracks. Thus no probabilistic estimation of the concurrent number of sources and the pitch and timing of note events is considered and to be expected errors are omitted. In contrary to well-known Ã¯Â¬Âelds of research like source separation or audio de- composition into single mono tracks, the 
research work as well as the application implemented for this thesis estimates the harmonic partials, the transient part of each note onset and the stochastic residual belonging to one audio object without iteratively subtracting the estimation results from the input stream. Before synthesis musically meaningful transformations like time-scaling or pitch- shifting along with their corresponding scaling factor, the shifting of audio objects in time or the substitution of audio objects by other instrument types are considered. The re-synthesized audio output will be examined by subjective listening and objective evaluation tests against a reference output where the same transformation got applied to the corresponding audio object of the monophonic track before mixing all tracks together.",
	address = "Spain",
	author = "Huber, Stefan",
	lockkey = "Y",
	school = "Universitat Pompeu Fabra",
	title = "{Harmonic Audio Object Processing in Frequency Domain}",
	year = "2009"
}

@phdthesis{LuYouyi2009,
	abstract = "When exposed to noise, speakers modify the way they speak, possibly in an effort to maintain intelligible communication. These modifications are collectively referred to as the Lombard effect. The work described in this thesis compares speech production changes induced by noise with various spectral and temporal characteristics, and explores the perceptual consequence of these changes. The thesis consists of a series of experimental studies, which involve the analysis of speech corpora collected under different noise conditions, with and without a communicative task. Intelligibility is also measured and predicted using a computer model. The first part of this thesis studies the acoustic and phonetic consequences of N-talker ``babble'' noise on sentence production for a range of values of N from 1 (competing talker) to ``infinity'' (speech-shaped noise). The effect of noise on speech production increased with N and noise level, both of which act to increase the energetic masking effect of the 
noise. In a background of stationary noise, noise-induced speech was always more intelligible than speech produced in quiet, and the gain in intelligibility increased with N and noise level, suggesting that talkers modify their productions to ameliorate energetic masking at the ears of the listener. The effect of low- and high-pass filtered noise on speech production was also examined to address the issue of whether speakers can compensate for energetic masking by actively shifting their spectral energy to regions least affected by the noise. Weak evidence was found that speakers are able to modify their speech production to take advantage of those spectral regions clear of noise. The possible reasons were discussed. To evaluate the origin of the increased intelligibility of Lombard speech, the fundamental frequency and spectral tilt of speech produced in quiet were artificially manipulated to match those of speech produced in speech-shaped noise. A perceptual evaluation showed that spectral flattening made 
a larger contribution to Lombard speech intelligibility, but failed to find an influence of an increase in fundamental frequency. A computational modelling study indicated that durational changes also play a significant role in increasing intelligibility. These findings suggest that speech modifications which reallocate energy in time and frequency to introduce more ``glimpses'' of clean speech in the presence of noise are able to contribute speech intelligibility. An analysis of the effect of noise on speech production requires material recorded while undertaking realistic tasks. The effect of a communication factor was explored using conversational speech collected in the presence of maskers with differing degrees of energetic and informational masking potential. The size of speech production changes was found to scale with the energetic masking potential of background noise, extending the findings with read to a communicative task. In addition, relative to the non-communicative task, speakers exploited 
temporal planning to reduce the amount of overlap with a modulated background noise, an effect which was stronger when the noise contained intelligible speech. In conclusion, the strategies used by talkers to promote successful speech communication under various noise conditions reported in this thesis could enable spoken output applications such as dialogue systems to adapt to communicational environment. In addition, the finding from this thesis that speech intelligibility can be improved by spectrum flattening encourages speech enhancement technology since such an approach is feasible to be implemented in real-time.",
	address = "UK",
	author = "Lu, Youyi",
	lockkey = "Y",
	school = "The University of Sheffield",
	title = "{Production and Perceptual Analysis of Lombard Effect}",
	year = "2009"
}

@article{HenrichN2006,
	author = "Henrich, N.",
	journal = "Logopedics Phoniatrics Vocology",
	lockkey = "Y",
	pages = "3--14",
	title = "{Mirroring the voice from Garcia to the present day: some insights into singing voice registers}",
	volume = "31",
	year = "2006"
}

@inproceedings{HenrichN2003,
	author = "Henrich, N. and Roubeau, B. and Castellengo, M.",
	booktitle = "{Proc. of the Stockholm Music Acoustics Conference}",
	lockkey = "Y",
	title = "{On The Use Of Electroglottography For Characterisation Of The Laryngeal Mechanisms}",
	year = "2003"
}

@article{KernerI1966,
	acmid = "365527",
	address = "New York, NY, USA",
	author = "Kerner, Immo O.",
	doi = "10.1145/365278.365527",
	issn = "0001-0782",
	issue = "4",
	journal = "ACM Communication",
	lockkey = "Y",
	pages = "273--273",
	publisher = "ACM",
	title = "{Algorithm 283: Simultaneous displacement of polynomial roots if real and simple}",
	url = "https://acces-distant.upmc.fr:443/http/doi.acm.org/10.1145/365278.365527",
	volume = "9",
	year = "1966"
}

@article{RothweilerJ1999b,
	abstract = "This work describes a new version of the decimation-in-degree (DID) transformation used by Wu and Chen (see ibid., vol.5, p.105-15, 1997) as part of their procedure for computing line spectrum pair (LSP) coefficients. This new version eliminates all nontrivial multiplications, requires fewer total operations (additions and multiplications), and is performed in place-eliminating a memory buffer",
	author = "Rothweiler, J.",
	doi = "10.1109/89.784111",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "LPC; LSP coefficients; LSP frequencies computation; additions; decimation-in-degree transformation; line spectrum pair coefficients; multiplications; polynomial reduction; linear predictive coding; polynomials; spectral analysis",
	lockkey = "Y",
	number = "5",
	pages = "592--594",
	title = "{On polynomial reduction in the computation of LSP frequencies}",
	volume = "7",
	year = "1999"
}

@article{WuChung1997,
	abstract = "A novel two-level method is proposed for rapidly and accurately computing the line spectrum pair (LSP) frequencies. An efficient decimation-in-degree (DID) algorithm is also proposed in the first level, which can transform any symmetric or antisymmetric polynomial with real coefficients into the other polynomials with lower degrees and without any transcendental functions. The DID algorithm not only can avoid prior storage or large calculation of transcendental functions but can also be easily applied toward those fast root-finding methods. In the second level, if the transformed polynomial is of degree 4 or less, employing closed-form formulas is the fastest procedure of quite high accuracy. If it is of a higher degree, a modified Newton-Raphson method with cubic convergence is applied. Additionally, the process of the modified Newton-Raphson method can be accelerated by adopting a deflation scheme along with Descartes rule of signs and the interlacing property of LSP frequencies for selecting 
the better initial values. Besides this, Horner's method is extended to efficiently calculate the values of a polynomial and its first and second derivatives. A few conventional numerical methods are also implemented to make a comparison with the two-level method. Experimental results indicate that the two-level method is the fastest one. Furthermore, this method is more advantageous under the requirement of a high level of accuracy",
	author = "Wu, Chung Hsien and Chen, Jau-Hung",
	doi = "10.1109/89.554772",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "Descartes rule of signs; Horner's method; LSP frequencies; accuracy; antisymmetric polynomial; closed-form formulas; cubic convergence; decimation-in-degree algorithm; deflation scheme; experimental results; fast root-finding methods; first derivatives; interlacing property; line spectrum pair; modified Newton-Raphson method; numerical methods; real coefficients; second derivatives; speech processing; symmetric polynomial; two-level method; Newton-Raphson method; convergence of numerical methods; polynomials; spectral analysis; speech processing",
	lockkey = "Y",
	number = "2",
	pages = "106--115",
	title = "{A novel two-level method for the computation of the LSP frequencies using a decimation-in-degree algorithm}",
	volume = "5",
	year = "1997"
}

@inproceedings{RothweilerJ1999a,
	abstract = "Published techniques for computing line spectral frequencies (LSFs) generally avoid rootfinding methods because of concerns about convergence and complexity. However, this paper shows that stable predictor polynomials have properties that make rootfinding an attractive approach. It is well known that the problem of finding the LSFs for an N'th order predictor polynomial can be reduced to the problem of finding the roots of a pair of polynomials of order N/2 with real roots. The author extends this result by showing that these polynomials have the following properties: 1. It is possible to select starting points for a Newton's rootfinding method such that the iteration will converge monotonically to the largest root. 2. The Newton iteration can be modified to speed up the process while still maintaining good convergence properties. In this paper, the author presents the rootfinding procedures with proofs of their good convergence properties. Finally, he presents experimental results showing that 
this procedure performs well on speech signals, and that it can be implemented on fixed-point DSPs",
	author = "Rothweiler, J.",
	booktitle = "{Acoustics, Speech, and Signal Processing, 1999. ICASSP '99. Proceedings., 1999 IEEE International Conference on}",
	doi = "10.1109/ICASSP.1999.759753",
	keywords = "LSF; Newton iteration; convergence properties; fixed-point DSP; line spectral frequencies; rootfinding algorithm; speech signals; stable predictor polynomials; Newton method; convergence of numerical methods; polynomials; spectral analysis; speech processing",
	lockkey = "Y",
	pages = "661--664",
	title = "{A rootfinding algorithm for line spectral frequencies}",
	volume = "2",
	year = "1999"
}

@inproceedings{SemenovV2006,
	abstract = "A problem of calculation of line spectral frequencies (LSF) is considered. The investigation of mutual LSF location on adjacent quasi-stationary frames is performed. It was found that in majority of cases LSF inter-frame ordering property takes place. On this basis a new approach to LSF calculation is proposed. The LSF localization is mainly reduced to verification of inter-frame ordering property. The computational expenses are reduced in 3.4 times in comparison with widely used Kabal's method. Besides, the maximum number of operations is lower than the minimum expenses of accelerated Kabal's method. The method was implemented on fixed-point DSP and showed stable performance",
	author = "Semenov, V.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2006.1660843",
	issn = "1520-6149",
	keywords = "fixed-point DSP; inter-frame ordering property; line spectral frequencies; quasi-stationary frames; speech signal; speech processing",
	lockkey = "Y",
	title = "{A Novel Approach to Calculation of Line Spectral Frequencies Based on Inter-Frame Ordering Property}",
	volume = "3",
	year = "2006"
}

@article{ZengZhonggang2004,
	abstract = "MultRoot is a collection of Matlab modules for accurate computation of polynomial roots, especially roots with non-trivial multiplicities. As a blackbox-type software, Mul- tRoot requires the polynomial coeÃ¯Â¬Âcients as the only input, and outputs the computed roots, multiplicities, backward error, estimated forward error, as well as the pejorative condition number. The most signiÃ¯Â¬Âcant features of MultRoot are the multiplicity iden- tiÃ¯Â¬Âcation capability and the remarkable accuracy on multiple roots without using the mul- tiprecision arithmetic, even if the polynomial coeÃ¯Â¬Âcients are inexact. A comprehensive test suit of polynomials that are collected from the literature is included for numerical experiments and performance comparison.",
	acmid = "980189",
	address = "New York, NY, USA",
	author = "Zeng, Zhonggang",
	doi = "10.1145/980175.980189",
	issn = "0163-5824",
	issue = "1",
	journal = "SIGSAM Bull.",
	lockkey = "Y",
	numpages = "2",
	pages = "28--29",
	publisher = "ACM",
	title = "{A Matlab package computing polynomial roots and multiplicities}",
	url = "http://doi.acm.org/10.1145/980175.980189",
	volume = "38",
	year = "2004"
}

@inproceedings{DrugmanT2008c,
	author = "Drugman, T. and Dubuisson, T. and D'Alessandro, N. and Moinet, A. and T.Dutoit",
	booktitle = "{European Signal Processing Conference (EUSIPCO)}",
	lockkey = "Y",
	title = "{Voice source parameters estimation by fitting the glottal formant and the inverse filtering open phase}",
	year = "2008"
}

@techreport{DudleyH1939b,
	author = "Dudley, H. W.",
	institution = "Bell Telephone Laboratories",
	lockkey = "Y",
	title = "{Signal Transmission}",
	year = "1939"
}

@techreport{GriffinD1987,
	author = "Griffin, D. W.",
	institution = "Massachusetts Institute of Technology",
	lockkey = "Y",
	number = "RLE Technical Report No. 524",
	title = "{Multi-Band Excitation Vocoder}",
	year = "1987"
}

@techreport{ITU-T-P.800,
	author = "ITU-T-P.800",
	institution = "TELECOMMUNICATION STANDARDIZATION SECTOR OF ITU",
	lockkey = "Y",
	title = "{METHODS FOR SUBJECTIVE DETERMINATION OF TRANSMISSION QUALITY}",
	year = "1996"
}

@article{JensenJ2009,
	abstract = "For music information retrieval tasks, a nearest neighbor classifier using the Kullback-Leibler divergence between Gaussian mixture models of songs' melfrequency cepstral coefficients is commonly used to match songs by timbre. In this paper, we analyze this distance measure analytically and experimentally by the use of synthesized MIDI files, and we find that it is highly sensitive to different instrument realizations. Despite the lack of theoretical foundation, it handles the multipitch case quite well when all pitches originate from the same instrument, but it has some weaknesses when different instruments play simultaneously. As a proof of concept, we demonstrate that a source separation frontend can improve performance. Furthermore, we have evaluated the robustness to changes in key, sample rate, and bitrate.",
	author = "Jensen, J.H. and Christensen, M.G. and Ellis, D.P.W. and Jensen, S.H.",
	doi = "10.1109/TASL.2008.2012314",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	keywords = "Gaussian mixture models; Kullback-Leibler divergence; audio similarity measure; melfrequency cepstral coefficients; music information retrieval tasks; nearest neighbor classifier; quantitative analysis; Gaussian processes; cepstral analysis; information retrieval; music; pattern classification",
	lockkey = "Y",
	number = "4",
	pages = "693--703",
	title = "{Quantitative Analysis of a Common Audio Similarity Measure}",
	volume = "17",
	year = "2009"
}

@mastersthesis{JohanssonM1999,
	abstract = "The information about the Hilbert transform is often scattered in books about signal processing. Their authors frequently use mathe- matical formulas without explaining them thoroughly to the reader. The purpose of this report is to make a more stringent presentation of the Hilbert transform but still with the signal processing application in mind.",
	author = "Johansson, Mathias",
	lockkey = "Y",
	school = "Vaxjo University",
	title = "{The Hilbert transform}",
	year = "1999"
}

@article{PanV2002,
	abstract = "To approximate all roots (zeros) of a univariate polynomial, we develop two effective algorithms and combine them in a single recursive process. One algorithm computes a basic well isolated zero-free annulus on the complex plane, whereas another algorithm numerically splits the input polynomial of the nth degree into two factors balanced in the degrees and with the zero sets separated by the basic annulus, Recursive combination of the two algorithms leads to computation of the complete numerical factorization of a polynomial into the product of linear factors and further to the approximation of the roots. The new root-finder incorporates the earlier techniques of Sch{\"o}nhage, Neff/Reif, and Kirrinnis and our old and new techniques and yields nearly optimal (up to polylogarithmic factors) arithmetic and Boolean cost estimates for the computational complexity of both complete factorization and root-finding. The improvement over our previous record Boolean complexity estimates is by roughly the 
factor of n for complete factorization and also for the approximation of well-conditioned (well isolated) roots, whereas the same algorithm is also optimal (under both arithmetic and Boolean models of computing) for the worst case input polynomial, whose roots can be ill-conditioned, forming clusters. (The worst case complexity bounds for root-finding are supported by our previous algorithms as well.) All algorithms allow processor efficient acceleration to achieve solution in polylogarithmic parallel time.",
	acmid = "612317",
	address = "Duluth, MN, USA",
	author = "Pan, Victor Y.",
	doi = "10.1006/jsco.2002.0531",
	issn = "0747-7171",
	issue = "5",
	journal = "J. Symb. Comput.",
	lockkey = "Y",
	numpages = "33",
	pages = "701--733",
	publisher = "Academic Press, Inc.",
	title = "{Univariate polynomials: nearly optimal algorithms for numerical factorization and root-finding}",
	url = "http://portal.acm.org/citation.cfm?id=612306.612317",
	volume = "33",
	year = "2002"
}

@mastersthesis{MekwiW2001,
	abstract = "We describe iterative methods for polynomial zeroÃ¯Â¬Ânding and, speciÃ¯Â¬Âcally, the Laguerre method and how it is used in the NAG subroutine C02AFF. We also investigate a bug that has been in this subroutine for ten years. In chapter two, we give a brief survey of some zeroÃ¯Â¬Ânding methods. These include Bairstow{\rq}s method, Bernoulli{\rq}s method, GraeÃ¯Â¬Âe{\rq}s root-squaring method, MÃÅ¡ller{\rq}s method, u the Newton-Raphson method and the Jenkins-Traub and Laguerre methods. In chapter three, we look at the Laguerre method as used in C02AFF in fur- ther detail, describe the behaviour of the bug and how the problem has been solved. We also describe general tests for zeroÃ¯Â¬Ânding algorithms and results of comparisons between NAG{\rq}s C02AFF and other zeroÃ¯Â¬Ânding programs. Chap- ter 4 involves comparisons of C02AFF with other methods and a note on error bounds. Finally, we make our proposals and conclusions in chapter 5.",
	author = "Mekwi, Wankere R.",
	lockkey = "Y",
	school = "University of Oxford",
	title = "{Iterative Methods for Roots of Polynomials}",
	year = "2001"
}

@article{ShannonC1948,
	abstract = "THE recent development of various methods of modulation such as PCM and PPM which exchange bandwidth for signal-to-noise ratio has intensiÃ¯Â¬Âed the interest in a general theory of communication. A basis for such a theory is contained in the important papers of Nyquist 1 and Hartley2 on this subject. In the present paper we will extend the theory to include a number of new factors, in particular the effect of noise in the channel, and the savings possible due to the statistical structure of the original message and due to the nature of the Ã¯Â¬Ânal destination of the information.",
	author = "Shannon, C. E.",
	journal = "Bell System Technical Journal",
	lockkey = "Y",
	pages = "379--423 and 623--656",
	title = "{A mathematical theory of communication}",
	volume = "27",
	year = "1948"
}

@inproceedings{Degottex2011fpd,
	abstract = "In voice analysis, the parameters estimation of a glottal model, an analytic description of the deterministic component of the glottal source, is a challenging question to assess voice quality in clinical use or to model voice production for speech transformation and syn- thesis using a priori constraints. In this paper, we Ã¯Â¬Ârst describe the Function of Phase-Distortion (FPD) which allows to characterize the shape of the periodic pulses of the glottal source independently of other features of the glottal source. Then, using the FPD, we de- scribe two methods to estimate a shape parameter of the Liljencrants- Fant glottal model. By comparison with state of the art methods us- ing Electro-Glotto-Graphic signals, we show that the one of these method outperform the compared methods.",
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	booktitle = "{Proc. IEEE Int. Conf. on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	pages = "4608--4611",
	title = "{Function of phase-distortion for glottal model estimation}",
	year = "2011"
}

@inproceedings{Degottex2011aposter,
	abstract = "In voice analysis, the parameters estimation of a glottal model, an analytic description of the deterministic component of the glottal source, is a challenging question to assess voice quality in clinical use or to model voice production for speech transformation and syn- thesis using a priori constraints. In this paper, we Ã¯Â¬Ârst describe the Function of Phase-Distortion (FPD) which allows to characterize the shape of the periodic pulses of the glottal source independently of other features of the glottal source. Then, using the FPD, we de- scribe two methods to estimate a shape parameter of the Liljencrants- Fant glottal model. By comparison with state of the art methods us- ing Electro-Glotto-Graphic signals, we show that the one of these method outperform the compared methods.",
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	booktitle = "{ICASSP}",
	lockkey = "Y",
	title = "{Function of phase-distortion for glottal model estimation}",
	year = "2011"
}

@inproceedings{DegottexG2011pitchtrbreathmod,
	abstract = "The transformation of the voiced segments of a speech recording has many applications such as expressivity synthesis or voice conver- sion. This paper addresses the pitch transposition and the modiÃ¯Â¬Âca- tion of breathiness by means of an analytic description of the deter- ministic component of the voice source, a glottal model. Whereas this model is dedicated to voice production, most of the current methods can be applied to any pseudo-periodic signals. Using the described method, the synthesized voice is thus expected to better preserve some naturalness compared to a more generic method. Us- ing preference tests, it is shown that this method is preferred for im- portant pitch transposition (e.g. one octave) compared to two state of the art methods. Additionally, it is shown that the breathiness of two male utterances can be controlled.",
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	pages = "5128--5131",
	title = "{Pitch transposition and breathiness modification using a glottal source model and its adapted vocal-tract filter}",
	year = "2011"
}

@inproceedings{LiuniM2011,
	abstract = "Change detection within an audio stream is an important task in several domains, such as classiÃ¯Â¬Âcation and segmentation of a sound or of a music piece, as well as indexing of broad- cast news or surveillance applications. In this paper we pro- pose two novel methods for spectral change detection without any assumption about the input sound: they are both based on the evaluation of information measures applied to a time- frequency representation of the signal, and in particular to the spectrogram. The class of measures we consider, the R{\'e}nyi entropies, are obtained by extending the Shannon entropy def- inition: a biasing of the spectrogram coefÃ¯Â¬Âcients is realized through the dependence of such measures on a parameter, which allows reÃ¯Â¬Âned results compared to those obtained with standard divergences. These methods provide a low compu- tational cost and are well-suited as a support for higher level analysis, segmentation and classiÃ¯Â¬Âcation algorithms.",
	author = "{M. Liuni}, A. Roebel and Romito, M and Rodet, X.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	lockkey = "Y",
	title = "{R{\'e}nyi information measures for spectral change detection}"
}

@article{Lous1998,
	abstract = {<html><head><meta name="qrichtext" content="1" /></head><body style="font-size:8pt;font-family:Sans"> We propose a two-mass model for the vocal folds. The aerodynamic force resulting from the air flow through the glottis is distributed over both masses, as opposed to some earlier models in which the force is allocated to the upstream mass only. This allows the choice of a symmetrical vocal-fold structure, with two identical mass-spring systems. The number of mechanical parameters is thus reduced. Their choice is inspired upon analysis of the eigenmodes of the actual vocal folds. The new aerodynamic force distribution allows acoustic feedback from vocal tract and trachea to be considered; sub- and supra-glottal systems are modelled as transmission lines. The flow model includes a simple flow-separation description. Parameter values are based on physiological measurements and calculations reported in literature. However, as in any vocal-fold model it is inevitable that parameters also partly make 
up for simplifications in the model. The model predictions are shown to compare well to in-vivo experimental data from literature concerning acoustic feedback. The two-mass model is applied to study the effect of size and position of a vocal-fold prosthesis on its performance. We indicate how the model should be modified to provide order-of-magnitude estimates of the effect of flow inertia and fluid viscosity. The described improvement of the flow model is not of predictive value within the framework of the simplified mechanical model we propose. </body></html>},
	author = "Lous, N.J.C. and Hofmans, G.C.J. and Veldhuis, R.N.J. and Hirschberg, A.",
	journal = "Acta Acustica united with Acustica",
	lockkey = "Y",
	number = "16",
	pages = "1135--1150",
	title = "{A Symmetrical Two-Mass Vocal-Fold Model Coupled to Vocal Tract and Trachea, with Application to Prosthesis Design}",
	url = "http://www.ingentaconnect.com/content/dav/aaua/1998/00000084/00000006/art00019",
	volume = "84",
	year = "1998"
}

@inproceedings{DengHuiqun2007,
	abstract = "Glottal waves obtained via inverse filtering vowel sounds may contain residual vocal-tract resonances due to incomplete glottal closures. This paper investigates the effect of incomplete glottal closures on the estimates of the glottal waves via inverse filtering. It shows that such a residual resonance appears as stationary ripples superimposed on the derivatives of the original glottal wave over a whole glottal cycle. Knowing this, one can determine if there are significant resonances of vocal tracts in the obtained glottal waves. It also shows that given an incomplete glottal closure, better estimates of glottal waves can be obtained from large lip-opening vowel sounds than from other sounds. The glottal waves obtained from /scripta/ produced by male and female subjects are presented. The obtained glottal waves during rapid vocal-fold collisions exhibit transient positive derivatives, which are explained by the air squeezed by the colliding vocal folds and the air from the glottal chink.",
	author = "Deng, Huiqun and O'Shaughnessy, D.",
	booktitle = "{Proc. Interspeech}",
	lockkey = "Y",
	pages = "546--549",
	title = "{Effect of Incomplete Glottal Closures on Estimates of Glottal Waves via Inverse Filtering of Vowel Sounds}",
	year = "2007"
}

@article{PotardB2007,
	author = "Potard, B. and Laprie, Y.",
	journal = "Proc. Interspeech",
	lockkey = "Y",
	pages = "2481--2484",
	title = "{Compact Representations of the Articulatory-to-Acoustic Mapping}",
	year = "2007"
}

@article{GribonvalR2003,
	abstract = {We introduce a dictionary of elementary waveforms, called harmonic atoms, that extends the Gabor dictionary and fits well the natural harmonic structures of audio signals. By modifying the "standard" matching pursuit, we define a new pursuit along with a fast algorithm, namely, the fast harmonic matching pursuit, to approximate N-dimensional audio signals with a linear combination of M harmonic atoms. Our algorithm has a computational complexity of O(MKN), where K is the number of partials in a given harmonic atom. The decomposition method is demonstrated on musical recordings, and we describe a simple note detection algorithm that shows how one could use a harmonic matching pursuit to detect notes even in difficult situations, e.g., very different note durations, lots of reverberation, and overlapping notes.},
	author = "Gribonval, R. and Bacry, E.",
	doi = "10.1109/TSP.2002.806592",
	issn = "1053-587X",
	journal = "IEEE Trans. on Signal Processing",
	keywords = "Gabor dictionary; audio signals decomposition; computational complexity; elementary waveforms dictionary; fast algorithm; fast harmonic matching pursuit; harmonic atoms; harmonic decomposition; musical recordings; natural harmonic structures; note detection algorithm; note durations; overlapping notes; reverberation; time-frequency representation; audio signal processing; computational complexity; harmonic analysis; music; reverberation; signal detection; signal representation",
	lockkey = "Y",
	number = "1",
	pages = "101--111",
	title = "{Harmonic decomposition of audio signals with matching pursuit}",
	volume = "51",
	year = "2003"
}

@article{SzentirmaiG1977,
	abstract = "A very general computer program is described that can be used for the synthesis of passive LC, active RC, and (infinite impulse response) digital filters. Although it operates in both batch and interactive modes, this discussion deals exclusively with the interactive mode, which is somewhat more general and very easy to use. Apart from offering superior accuracy and flexibility, this program offers many firsts, including the passive realization of complex quadruplets of transmission zeros, the simultaneous realization of two transmission zero pairs, the active RC leapfrog realization, and many others.",
	author = "Szentirmai, G.",
	doi = "10.1109/PROC.1977.10748",
	issn = "0018-9219",
	journal = "Proceedings of the IEEE",
	lockkey = "Y",
	number = "10",
	pages = "1443--1458",
	title = "{FILSYN \#8212;A general purpose filter synthesis program}",
	volume = "65",
	year = "1977"
}

@inproceedings{VillavicencioF2007,
	abstract = "We present a study into all-pole spectral envelope estimation for the case of harmonic signals. We address the problem of the selection of the model order and propose to make use of the fact that the spectral envelope is sampled by means of the harmonic structure to derive a reasonable choice for an appropriate model order. The experimental investigation uses synthetic ARMA featured signals with varying fundamental frequency and differing model structure to evaluate the performance of the selected all-pole models. The experimental results confirm the relation between optimal model order and the fundamental frequency.",
	author = "Villavicencio, F. and Robel, A. and Rodet, X.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech and Signal Processing }",
	doi = "10.1109/ICASSP.2007.366613",
	issn = "1520-6149",
	keywords = "all-pole spectral envelope modelling; harmonic signals; harmonic structure; model structure; order selection; spectral envelope; synthetic ARMA featured signals; autoregressive moving average processes; harmonic analysis; spectral analysis",
	lockkey = "Y",
	pages = "49--52",
	title = "{All-Pole Spectral Envelope Modelling with Order Selection for Harmonic Signals}",
	year = "2007"
}

@article{McCreeAV2006,
	abstract = "Low-bit-rate speech coding, at rates below 4 kb/s, is needed for both communication and voice storage ap- plications. At such low rates, full encoding of the speech waveform is not possible; therefore, low-rate coders rely instead on parametric models to repre- sent only the most perceptually-relevant aspects of speech. While there are a number of different ap- proaches for this modeling, all can be related to the basic linear model of speech production, where an excitation signal drives a vocal tract Ã¯Â¬Âlter. The basic properties of the speech signal and of human speech perception can explain the princi- ples of parametric speech coding as applied in early vocoders. Current speech modeling approaches, such as mixed excitation linear prediction, sinusoidal cod- ing, and waveform interpolation, use more sophisti- cated versions of these same concepts. Modern tech- niques for encoding the model parameters, in partic- ular using the theory of vector quantization, allow the encoding of the model 
information with very few bits per speech frame. Successful standardization of low-rate coders has enabled their widespread use for both military and satellite communications, at rates from 4 kb/s all the way down to 600 b/s. However, the goal of toll- quality low-rate coding continues to provide a re- search challenge.",
	author = "McCree, A. V.",
	journal = "Springer Handbook on Speech Processing and Speech Communication",
	lockkey = "Y",
	title = "{Low-bit-rate speech coding}",
	year = "2006"
}

@inproceedings{VeldhuisRNJ1998,
	abstract = "The paper analyses how variations of the parameters of the Liljencrants-Fant (1985) model of glottal flow influence the speech spectrum, in order to determine the spectral relevance of these parameters. The effects of small parameter variations are described analytically. This analysis also gives an indication to what extent the LF parameters can be estimated reliably from the speech spectrum. The effects of larger parameter variations are discussed with the help of figures. Results are presented for a number of sets of estimated glottal-pulse parameters that were taken from the literature. The main conclusion is that the LF model, which, given the fundamental period, is a three-parameter model, actually operates as a one- or a two-parameter model",
	author = "Veldhuis, R.N.J.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech and Signal Processing }",
	doi = "10.1109/ICASSP.1998.675404",
	issn = "1520-6149",
	keywords = "LF model; LF parameters; Liljencrants-Fant model; fundamental period; glottal flow; glottal-pulse parameters; large parameter variations; one-parameter model; parameter estimation; small parameter variations; spectral relevance; speech spectrum; three-parameter model; two-parameter model; acoustic signal processing; parameter estimation; spectral analysis; speech processing",
	lockkey = "Y",
	pages = "873--876",
	title = "{The spectral relevance of glottal-pulse parameters}",
	volume = "2",
	year = "1998"
}

@article{KrishnamurthyAK1988,
	author = "Krishnamurthy, A. K. and Li, J.",
	doi = "10.1121/1.2025292",
	journal = "The Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "S1",
	pages = "S2--S2",
	publisher = "ASA",
	title = "{Voiced speech model including source-tract interaction}",
	url = "http://link.aip.org/link/?JAS/83/S2/1",
	volume = "83",
	year = "1988"
}

@article{BovesL1983,
	abstract = "The finding that synthetic speech, based on the customary linear model of acoustic speech production, often sounds somewhat machinelike, has motivated various attempts to refine the model. Our approach to the problem concentrates on variations in formant parameters due to the changing termination impedance at the glottis. Open and closed glottis intervals are determined from the electroglottogram that is digitized and recorded together with the speech signal. Linear prediction analysis of the signal segments taken from the closed glottis intervals leads to stable results for both formant frequencies and bandwidths. LP analysis of segments from the open glottis intervals leads to extremely erratic results, which can be proved to be due to pronounced spectral zeros. We will present numerical data on within-cycle formant variations in the speech of adult males obtained from cepstrally smoothed spectra.",
	author = "Boves, L. and Cranen, B.",
	doi = "10.1121/1.2020475",
	journal = "The Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "S1",
	publisher = "ASA",
	title = "{Effects of glottal termination impedance on formant frequencies and bandwidths}",
	url = "http://link.aip.org/link/?JAS/73/S5/2",
	volume = "73",
	year = "1983"
}

@inproceedings{ChildersDG1983,
	author = "Childers, D. G. and Moore, G. P. and Naik, J. M. and Larar, J. N. and Krishnamurthy, A. K.",
	booktitle = "{Proc. Care of the professional voice}",
	lockkey = "Y",
	pages = "234--244",
	title = "{Assessment of laryngeal function by simultaneous, synchronized measurement of speech, electroglottography and ultra-high speed film}",
	year = "1983"
}

@inproceedings{GottinB2009,
	abstract = "Natural signals are often characterized by a complex time-frequency behaviour. These signals exist in many different applications and systems from underwater acoustic to audio signals with sound attacks or electrical systems with partial discharges and commutation switches, for example. There is a huge number of time-frequency (TF) methods that aim to characterize these signals in terms of first phase derivative analysis (i.e instantaneous frequency law). Recently, we introduced the time frequency distribution based on complex lag arguments. This distribution is able to reduce inner interferences terms which appear when studying non-linear TF components. It also offers access to an instantaneous law representation of any phase derivative order. In this paper, we use these two properties to study highly non-stationary signals as well as transient signals.",
	author = "Gottin, B. and Orovic, I. and Ioana, C. and Stankovic, S. and Chanussot, J.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech and Signal Processing }",
	doi = "10.1109/ICASSP.2009.4960255",
	issn = "1520-6149",
	keywords = "complex lag arguments; first phase derivative analysis; generalized time-phase derivatives representation; signal characterization; time frequency distribution; signal representation; time-frequency analysis",
	lockkey = "Y",
	pages = "3001--3004",
	title = {{Signal characterization using generalized "Time-phase derivatives" representation}},
	year = "2009"
}

@inproceedings{Degottex2009a,
	abstract = "From a recorded speech signal, we propose to estimate a shape parameter of a glottal model without time position estimate. Indeed, the literature usually propose to estimate the time position first. The vocal-tract filter estimate is expressed as a minimum-phase envelope estimation after removing the glottal model and a standard lips radiation model. Since this filter is mainly biased in low frequencies by the glottal model, an estimation method of a shape parameter is proposed. The evaluation of the results of such an estimator is still difficult. Therefore, this estimator is evaluated with synthetic signals. Such an estimate is useful for voice analysis (ex. Glottal Closure Instant detection), voice transformation and synthesis.",
	author = "Degottex, G. and Roebel, A. and Rodet, X.",
	booktitle = "{Proc. Conference on Speech and Computer (SPECOM)}",
	comment = "13th International Conference on Speech and Computer,",
	conf = "13th International Conference on Speech and Computer",
	file = "http://recherche.ircam.fr/equipes/analyse-synthese/degottex/uploads/Main/Degottex2009a.pdf",
	lockkey = "Y",
	pages = "345--349",
	pdf = "Degottex2009a.pdf",
	title = "{Shape parameter estimate for a glottal model without time position}",
	year = 2009
}

@inproceedings{ZharkikhA2009a,
	author = "Zharkikh, A. A.",
	booktitle = "{Proc. Conference on Speech and Computer (SPECOM)}",
	comment = "13th International Conference on Speech and Computer,",
	conf = "13th International Conference on Speech and Computer",
	file = "http://recherche.ircam.fr/equipes/analyse-synthese/degottex/uploads/Main/Degottex2009a.pdf",
	lockkey = "Y",
	pdf = "Degottex2009a.pdf",
	title = "{Comparison of Representation Accuracy of Different Orders Gaussian Wavelets}",
	year = 2009
}

@article{BenidirM1998,
	abstract = "Nous exposons dans cet article trois repr{\'e}sentations associ{\'e}es {\`a} un polyn{\^o}me en donnant des algorithmes qui permettent de les d{\'e}terminer ainsi que les principales applications associ{\'e}es. Les deux premi{\`e}res, sont en rapport direct avec l'{\'e}tude de la stabilit{\'e} des filtres dynamiques et la troisi{\`e}me avec l'analyse temps-fr{\'e}quence des signaux {\`a} phase polyn{\^o}miale. Three representations associated with a polynomial are presented, giving algorithms that allow us to determine them as well a s the main associated applications . The first ones have a direct link with the study of the stability of linear filters and the third on e with the time-frequency analysis of polynomial phase signals .",
	author = "Benidir, M.",
	journal = "Traitement du Signal",
	lockkey = "Y",
	number = "6 Sp{\'e}cial",
	title = "{Quelques repr{\'e}sentations d'un polyn{\^o}me et leurs applications en traitement du signal}",
	volume = "15",
	year = "1998"
}

@inproceedings{PotardB2006,
	abstract = "{T}he goal of this work is to investigate audiovisual-to-articulatory inversion. {I}t is well established that acoustic-to-articulatory inversion is an underdetermined problem. {O}n the other hand, there is strong evidence that human speakers/listeners exploit the multimodality of speech, and more particularly the articulatory cues: the view of visible articulators, i.e. jaw and lips, improves speech intelligibility. {I}t is thus interesting to add constraints provided by the direct visual observation of the speaker's face. {V}isible data was obtained by stereo-vision and enable the 3{D} recovery of jaw and lip movements. {T}hese data were processed to fit the nature of parameters of {M}aeda's articulatory model. {I}nversion experiments were conducted.",
	address = "{S}ao {P}aulo/{B}razil",
	affiliation = "{PAROLE} - {INRIA} {L}orraine - {LORIA} - {INRIA} - {CNRS} : {UMR}7503 - {U}niversit{\'e} {H}enri {P}oincar{\'e} - {N}ancy {I} - {U}niversit{\'e} {N}ancy {II} - {I}nstitut {N}ational {P}olytechnique de {L}orraine",
	audience = "not specified",
	author = "Potard, B. and Laprie, Y.",
	booktitle = "{Proc. {I}nternational {S}eminar on {S}peech {P}roduction (ISSP)}",
	hal_id = "inria-00112223",
	keywords = "audiovisual; inversion",
	language = "{E}nglish",
	lockkey = "Y",
	month = "12",
	title = "{{A}dapting visual data to a linear articulatory model}",
	url = "http://hal.inria.fr/inria-00112223/PDF/audiovisualinv.pdf",
	year = "2006"
}

@techreport{VeldhuisR1997,
	author = "Veldhuis, R.",
	institution = "Unknown",
	lockkey = "Y",
	title = "{Spectral estimation and significance of glottal-pulse parameters}",
	year = "1997"
}

@techreport{TitzeIR1983,
	author = "Titze, I. R. and Thomas, B. and Cooper, D. and Scherer, R.",
	institution = "University of Iowa",
	lockkey = "Y",
	title = "{Automated extraction of glottographic waveform parameters and regression to acoustic and physiologic variables}",
	year = "1983"
}

@inproceedings{CampbellN2003,
	author = "Campbell, N. and Mokhtari, P.",
	booktitle = "{Proc. International Congress of Phonetic Sciences}",
	lockkey = "Y",
	pages = "2417--2420",
	title = "{Voice Quality: the 4th Prosodic Dimension}",
	year = "2003"
}

@article{DericheM2006,
	abstract = "In this paper, we present a novel audio coder using the discrete wavelet transform (DWT) and warped linear prediction (WLP). In contrast to conventional LP, WLP allows for the control of frequency resolution to closely match the response of the human auditory system. The structure of the system is similar to the transform coded excitation techniques used in wideband speech coding, where LP has been replaced with WLP, and the residual is analyzed by a wavelet filterbank designed to approximate the critical bands. The inherent shaping of the WLP synthesis filter, and a controlled bit allocation to the wavelet coefficients helps minimise the perceptually significant noise due to the quantization error in the residual. For monophonic signals sampled at 44.1 kHz, the coder achieves near transparent to transparent quality for a variety of speech and music signals at an average bitrate of about 64 kb/s. Tests also show that the coder (in its initial implementation) delivers superior quality to the MPEG 
layer III and comparable quality to the MPEG2-AAC codec when operating at the same bitrate",
	author = "Deriche, M. and Ning, D.",
	doi = "10.1109/TASL.2006.881701",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing,",
	keywords = "DWT; audio coding scheme; discrete wavelet transform; human auditory system; monophonic signals; quantization error; synthesis filter; transform coded excitation techniques; warped linear prediction model; wavelet filterbank; wideband speech coding; audio coding; channel bank filters; discrete wavelet transforms; speech coding; speech synthesis; transform coding",
	lockkey = "Y",
	number = "6",
	pages = "2039--2048",
	title = "{A Novel Audio Coding Scheme Using Warped Linear Prediction Model and the Discrete Wavelet Transform}",
	volume = "14",
	year = "2006"
}

@article{AllenD1985,
	abstract = "A model has been developed which is designed to preserve some of the naturalness that is usually lost in speech synthesis. A parametrized function is used to produce an approximation to the cross-sectional area through the glottis. A circuit model of the subglottal and glottal system is used with the supraglottal pressure to generate the glottal volume velocity. The tract used to obtain the supraglottal pressure is represented by its input-impedance inpulse response, which can be calculated from the area function of the tract. A convolution of the input-impedance impulse response with the volume velocity determines the supraglottal pressure. The two coupled equations for the volume velocity are solved simultaneously. The output of the model is generated by convolving the resulting glottal volume velocity with the transfer-function impulse response of the tract. This technique preserves the interaction between the glottal flow and the vocal tract, which is usually lost. Comparisons are made 
between ``complete tract loading'' and ``inductive tract loading.'' Magnitude spectra of the various pressures and the glottal volume velocity are examined in detail. Effects of varying the glottal parameters are examined for one vowel. Listening tests showed that vowels systhesized with the interaction were preferred as more natural sounding than those without the interactions.",
	author = "Allen, Donald R. and Strong, William J.",
	doi = "10.1121/1.392454",
	journal = "The Journal of the Acoustical Society of America",
	lockkey = "Y",
	number = "1",
	pages = "58--69",
	publisher = "ASA",
	title = "{A model for the synthesis of natural sounding vowels}",
	url = "http://link.aip.org/link/?JAS/78/58/1",
	volume = "78",
	year = "1985"
}

@misc{MaestriE2011,
	author = "Maestri, E. and Degottex, G.",
	howpublished = "SÃ¯Â¿Åminaire Recherche-Technologie, IRCAM",
	lockkey = "Y",
	month = "Feb.",
	title = "{L'outil {SVLN} dans un cadre de cr{\'e}ation}",
	year = "2011"
}

@phdthesis{MysoreG2010,
	address = "USA",
	author = "Mysore, Gautham",
	comment = "Statistical modeling of audio is an ongoing pursuit. There is a great deal of structure in audio and good models need to make use of this structure. Audio is non-stationary but the statistics of the spectral structure are quite consistent over segments of time. Moreover, there is a structure to the non-stationarity itself in the form of tempo- ral dynamics. Sound mixtures are commonly encountered in practice. Polyphonic music, multiple concurrent speakers, and most environmental sounds are mixtures. Moreover, most real world sound sources are actually a mixture of the source and noise. When dealing with mixtures, the structure of the individual sources becomes particularly important if we wish deal with the sources separately. In recent years, non-negative spectrogram factorization methods have become quite popular for modeling audio as they provide a rich representation of audio spectra and are amenable to high quality reconstructions. However, they disregard non- stationarity as they use a 
single dictionary to characterize the statistics of the spectral structure of an entire source. On the other hand, hidden Markov models (HMMs) cater well to non-stationarity and have been used successfully to model temporal dynamics. They can be powerful for audio analysis, as shown by their application to speech recognition. They can also be used for the reconstruction of sources but have certain limitations due to a rigid observation model. This can be an issue for high quality reconstructions. We propose a new model of single sound sources, the non-negative hidden Markov model (N-HMM), that jointly models the spectral structure and temporal dynamics of a given source. In the proposed model, rather than learning a single dictionary, we learn several small dictionaries that characterize the spectral structure of the source, catering well to non-stationarity. Moreover, we jointly learn a Markov chain that characterizes the temporal dynamics of the source. This is done with a Ã¯Â¬Âexible observation model 
that allows high quality reconstructions. We demonstrate this model on content--aware audio processing. We then propose a new model of sound mixtures, the non-negative factorial hidden Markov model (N-FHMM), that combines models of individual sources. This model incorporates the spectral structure and temporal dynamics of each individual source. We demonstrate the model on single channel source separation and show that it yields superior performance to non-negative spectrogram factorization. Although it is demonstrated on source separation, the N-FHMM is a general model of sound mixtures and can be used for various applications.",
	school = "Standford-CCRMA",
	title = "{A NON-NEGATIVE FRAMEWORK FOR JOINT MODELING OF SPECTRAL STRUCTURE AND TEMPORAL DYNAMICS IN SOUND MIXTURES}",
	year = 2010
}

@phdthesis{ErroD2008,
	address = "Spain",
	author = "Erro, Daniel",
	comment = "Within the framework of the speech technologies, voice conversion consists of transforming the voice of a speaker, called source speaker, for it to be perceived by listeners as if it had been uttered by a different specific speaker, called target speaker. Although there are many speaker-dependent voice characteristics, voice conversion focuses mainly on those that are acoustic in nature: the spectral characteristics and the fundamental frequency. Among the multiple applications of voice conversion, the most important one is to allow the synthesis systems generating speech with different voices without the need for recording large databases associated to each of them. The objective of this thesis is to provide the voice conversion systems with higher quality and versatility than they have at present. As a first step, a speech analysis, modification and synthesis system based on the harmonic plus stochastic model has been developed. The new methods for prosodic modification of speech signals and 
segment concatenation operating on the parameters of such model are the first contribution contained in this thesis. In contrast to other existing alternatives, the new methods do not require the use of reference signal points placed at a pitch-synchronous rate, so they allow a more flexible initial analysis of the signals and they succeed at solving the phase problems that derive from it. In order to prove the validity of the new model and its associated algorithms for speech synthesis, which is a previous requirement for being applied to voice conversion, they are compared to TD- PSOLA, the most popular technique in the speech synthesis world, under strong prosodic modification conditions. The results of the test show that the new model is preferred by listeners. The first limitation observed in current voice conversion systems is the fact that manipulating the speech signal for converting the source voice into the target voice implies degrading its quality. Thus, the existing spectral conversion methods 
show a trade-off between the degree of conversion achieved and the quality of the converted signals. For this reason, in this thesis, using a state-of- the-art baseline system based on statistical gaussian mixture models with linear transformations, a new method called Weighted Frequency Warping is proposed. This method combines the previous statistical approach with frequency warping, which is known to introduce very small quality degradation in the converted signals. The new voice conversion method is evaluated by means of perceptual tests in which the conversion accuracy and the quality of the converted sentences are rated by listeners using a 5-point scale. It is concluded that the new method achieves quality scores more than 0.5 points higher than the baseline system, whereas there is a small decrement in the conversion scores, lower than 0.1 points. The mean quality score is slightly higher than 3.5, which is highly remarkable. After participating in a public international evaluation campaign, it can 
be observed that such results are very good compared to those of the rest of the competitors. The versatility of current voice conversion systems is often limited by their requirements for estimating adequate transformation functions from the training data. A vast majority of them need that the training sentences uttered by the source and target speaker are exactly the same. Although some techniques for training voice conversion functions from non-parallel sentences have been proposed during the last years (some of them are also valid for multilingual contexts), the performance scores of the overall voice conversion system decay. A new iterative technique for aligning speech frames coming from sentences uttered by two different speakers is proposed here. Its main advantage is that it only takes into account acoustic features, so it does not require phonetic or linguistic extra information. The experiments confirm that the new frame alignment technique allow obtaining very similar scores to those obtained in 
ideal 
training conditions. It is also proved that when the same technique is applied in a context where the source and target languages are not the same, the decrement of the resulting scores is small. The excellent results obtained by the voice conversion system based on Weighted Frequency Warping and the proposed alignment technique in a public international evaluation, are also presented. Finally, the voice conversion system created in this thesis is applied to building a multi-speaker speech synthesis system. Experiments are carried out for evaluating the system in terms of conversion accuracy and quality.",
	school = "Universitat Polit{\`e}cnica de Catalunya",
	title = "{Intra-Lingual And Cross-Lingual Voice Conversion Using Harmonic Plus Stochastic Models}",
	year = 2008
}

@mastersthesis{PavanKummarP2004,
	address = "India",
	author = "Kumar, K. Pavan",
	comment = "This report presents an introduction to speech synthesis with a brief overview of some methods and their associated problems. The usage of sinusoidal representation of speech waveform for producing synthetic speech is discussed in detail. The sinusoidal model is based on extracting the amplitudes, frequencies, and phases of the component sine waves from the short-time Fourier transform and using them for the production of synthetic speech. The report is based on some of the works carried out on speech modification to achieve desirable characteristics in speech using pitch scaling, time-scaling, and spectral warping. Obtaining expressions like anger, emotion, joy etc., in synthetic speech is one of the major areas of concern these days. This aspect of bringing expression into speech using the sinusoidal model is presented in brief.",
	school = "IIT Bombay",
	title = "{SPEECH SYNTHESIS BASED ON SINUSOIDAL MODELING}",
	year = 2004
}

@article{KlattDH1987,
	abstract = "The automatic conversion of English text to synthetic speech is presently being performed, remarkably well, by a number of laboratory systems and commercial devices. Progress in this area has been made possible by advances in linguistic theory, acoustic-phonetic characterization of English sound patterns, perceptual psychology, mathematical modeling of speech production, structured programming, and computer hardware design. This review traces the early work on the development of speech synthesizers, discovery of minimal acoustic cues for phonetic contrasts, evolution of phonemic rule programs, incorporation of prosodic rules, and formulation of techniques for text analysis. Examples of rules are used liberally to illustrate the state of the art. Many of the examples are taken from Klattalk, a text-to-speech system developed by the author. A number of scientific problems are identified that prevent current systems from achieving the goal of completely human-sounding speech. While the emphasis is 
on rule programs that drive a formant synthesizer, alternatives such as articulatory synthesis and waveform concatenation are also reviewed. An extensive bibliography has been assembled to show both the breadth of synthesis activity and the wealth of phenomena covered by rules in the best of these programs. A recording of selected examples of the historical development of synthetic speech, enclosed as a 33 1/3-rpm record, is described in the Appendix.",
	author = "Klatt, Dennis H.",
	journal = "Journal of the Acoustical Society of America",
	number = "3",
	pages = "737--793",
	title = "{Review of text-to-speech conversion for English}",
	volume = "82",
	year = "1987"
}

@techreport{KellyJL1962,
	author = "Kelly, John L. and Lochbaum, Carol C.",
	institution = "Bell Telephone Laboratories",
	title = "{Speech Synthesis}",
	year = "1962"
}

@article{KepesiM2006,
	author = "Kepesi, M. and Weruaga, L.",
	issn = "0167-6393",
	journal = "Speech communication",
	number = "5",
	pages = "474--492",
	title = "{Adaptive Chirp-based time-frequency analysis of speech signals}",
	volume = "48",
	year = "2006"
}

@article{StylianouY2001rmlin,
	abstract = "Many current text-to-speech (TTS) systems are based on the concatenation of acoustic units of recorded speech. While this approach is believed to lead to higher intelligibility and naturalness than synthesis-by-rule, it has to cope with the issues of concatenating acoustic units that have been recorded at different times and in a different order. One important issue related to the concatenation of these acoustic units is their synchronization. In terms of signal processing this means removing linear phase mismatches between concatenated speech frames. This paper presents two novel approaches to the problem of synchronization of speech frames with an application to concatenative speech synthesis. Both methods are based on the processing of phase spectra without, however, decreasing the quality of the output speech, in contrast to previously proposed methods. The first method is based on the notion of center of gravity and the second on differentiated phase data. They are applied off-line, during 
the preparation of the speech database without, therefore, any computational burden on synthesis. The proposed methods have been tested with the harmonic plus noise model, HNM, and the TTS system of AT amp;T Labs. The resulting synthetic speech is free of linear phase mismatches",
	author = "Stylianou, Y.",
	doi = "10.1109/89.905997",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "acoustic signal processing; acoustic units concatenation; AT amp; center of gravity; concatenated speech frames; concatenative speech synthesis; differentiated phase data; harmonic plus noise model; hidden Markov models; HNM; linear phase mismatch removal; noise; output speech quality; phase spectra processing; recorded speech; signal processing; spectral analysis; speech database; speech intelligibility; speech synthesis; synchronization; text-to-speech systems; T Labs; TTS system",
	number = "3",
	pages = "232--239",
	title = "{Removing linear phase mismatches in concatenative speech synthesis}",
	volume = "9",
	year = "2001"
}

@phdthesis{AgiomyrgiannakisY2007phd,
	abstract = "It is widely accepted that Voice-over-Internet-Protocol (VoIP) will dominate wireless and wireline voice communications in the near future. Traditionally, a minimum level of Quality-of-Service is achieved by careful traÃ¯Â¬Âc monitoring and network Ã¯Â¬Âne-tuning. However, this solution is not feasible when there is no possibility of controlling/monitoring the parameters of the network. For exam- ple, when speech traÃ¯Â¬Âc is routed through Internet there are increased packet losses due to network delays and the strict end-to-end delay requirements for voice communication. Most of today{\rq}s speech codecs were not initially de- signed to cope with such conditions. One solution is to introduce channel coding at the expense of end-to-end delay. Another solution is to perform joint source/channel coding of speech by designing speech codecs which are natively robust to increased packet losses. This thesis proposes a framework for developing speech codecs which are robust to packet losses. The 
thesis addresses the problem in two levels: at the basic source/channel coding level where novel methods are proposed for introducing controlled redundancy into the bitstream, and at the signal rep- resentation/coding level where a novel speech parameterization/modelling is presented that is amenable to eÃ¯Â¬Âcient quantization using the proposed source coding methods. The speech codec is designed to facilitate high-quality Packet Loss Concealment (PLC). The speech signal is modeled with harmonically re- lated sinusoids; a representation that enables Ã¯Â¬Âne time-frequency resolution which is vital for high-quality PLC. Furthermore, each packet is encoded in- dependently of the previous packets in order to avoid a desynchronization between the encoder and the decoder upon a packet loss. This allows some redundancy to exist in the bit-stream. A number of contributions are made to well-known harmonic speech mod- els. A fast analysis/synthesis method is proposed and used in the construction of an Analysis-by-
Synthesis (AbS) pitch detector. Harmonic Codecs tend to rely on phase models for the reconstruction of the harmonic phases, introduc- ing artifacts that eÃ¯Â¬Âect the quality of the reconstructed speech signal. For a high-quality speech reconstruction, the quantization of phase is required. Unfortunately, phase quantization is not a trivial problem because phases are circular variables. A novel phase-quantization algorithm is proposed to ad- dress this problem. Harmonics phases are properly aligned and modeled with a Wrapped Gaussian Mixture Model (WGMM) capable of handling parame- ters that belong to circular spaces. The WGMM is estimated with a suitable Expectation-Maximization (EM) algorithm. Phases are then quantized by ex- tending the eÃ¯Â¬Âcient GMM-based quantization techniques for linear spaces to WGMM and circular spaces. When packet losses are increased, additional redundancy can be introduced using Multiple Description Coding (MDC). In MDC, each frame is encoded in two descriptions; receiving 
both descriptions provides a high-quality recon- struction while receiving one description provides a lower-quality reconstruc- tion. With current GMM-based MDC schemes it is possible to quantize the amplitudes of the harmonics which represent an important portion of the infor- mation of the speech signal. A novel WGMM-based MDC scheme is proposed and used for MDC of the harmonic phases. It is shown that it is possible to construct high-quality MDC codecs based on harmonic models. Furthermore, it is shown that the redundancy between the MDC descriptions can be used to ``correct'' bit errors that may have occurred during transmission. At the source coding level, a scheme for Multiple Description Transform Coding (MDTC) of multivariate Gaussians using Parseval Frame expansions and a source coding technique referred to as Conditional Vector Quantization (CVQ), are proposed. The MDTC algorithm is extended to generic sources that can be modeled with GMM. The proposed frame facilitates a compu- tationally 
eÃ¯Â¬Âcient Optimal Consistent 
Reconstruction algorithm (OCR) and Cooperative Encoding (CE). In CE, the two MDTC encoders cooperate in or- der to provide better central/side distortion tradeoÃ¯Â¬Âs. The proposed scheme provides scalability, low complexity and storage requirements, excellent perfor- mance in low redundancies and competitive performance in high redundancies. In CVQ, the focus is given in correcting the most frequent type of errors; single and double packet losses. Furthermore, CVQ Ã¯Â¬Ânds application to BandWidth Expansion (BWE), the extension of the bandwidth of narrowband speech to wideband. Concluding, two proof-of-concept harmonic codecs are constructed, a single description and a multiple description codec. Both codecs are narrowband, variable rate, similar to quality with the state-of-the-art iLBC (internet Low Bit-Rate Codec) under perfect channel conditions and better than iLBC when packet losses occur. The single description codec requires 14 kbps and it is capable of accepting 20\% packet losses with minimal 
quality degradation while the multiple description codec operates at 21 kbps while it is capable of accepting 40\% packet losses without signiÃ¯Â¬Âcant quality degradation.",
	author = "Agiomyrgiannakis, Yannis",
	school = "University of Crete",
	title = "{Sinusoidal Coding of Speech for Voice Over IP}",
	year = "2007"
}

@book{alan1975digital,
  title={Digital signal processing},
  author={Oppenheim, A. V. and Schafer, R. W.},
  year={1975},
  publisher={Prentice-Hall}
}


@article{AgiomyrgiannakisY2009a,
	abstract = "The harmonic representation of speech signals has found many applications in speech processing. This paper presents a novel statistical approach to model the behavior of harmonic phases. Phase information is decomposed into three parts: a minimum phase part, a translation term, and a residual term referred to as dispersion phase. Dispersion phases are modeled by wrapped Gaussian mixture models (WGMMs) using an expectation-maximization algorithm suitable for circular vector data. A multivariate WGMM-based phase quantizer is then proposed and constructed using novel scalar quantizers for circular random variables. The proposed phase modeling and quantization scheme is evaluated in the context of a narrowband harmonic representation of speech. Results indicate that it is possible to construct a variable-rate harmonic codec that is equivalent to iLBC at approximately 13 kbps.",
	author = "Agiomyrgiannakis, Y. and Stylianou, Y.",
	doi = "10.1109/TASL.2008.2008229",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Lang. Proc.",
	keywords = "circular vector data; dispersion phase; expectation-maximization algorithm; Gaussian processes; harmonic analysis; harmonic representation; high-rate quantization scheme; phase data; phase modeling; quantisation (signal); speech coding; speech processing; speech signal; statistical approach; variable-rate harmonic codec; wrapped Gaussian mixture model",
	number = "4",
	pages = "775--786",
	title = "{Wrapped Gaussian Mixture Models for Modeling and High-Rate Quantization of Phase Data of Speech}",
	volume = "17",
	year = "2009"
}

@inproceedings{Agiomyrgiannakis2007b,
	abstract = "Harmonic sinusoidal representations of speech have proven to be useful in many speech processing tasks. This work focuses on the phase spectra of the harmonics and provides a methodology to analyze and subsequently to model the statistics of the harmonic phases. To do so, we propose the use of a wrapped Gaussian mixture model (WGMM), a model suitable for random variables that belong to circular spaces, and provide an expectation-maximization algorithm for training. The WGMM is then used to construct a phase quantizer. The quantizer is employed in a prototype variable rate narrow-band VoIP sinusoidal codec that is equivalent to iLBC in terms of PESQ-MOS, at ~13 kbps",
	author = "Agiomyrgiannakis, Y. and Stylianou, Y.",
	booktitle = "{Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing }",
	doi = "10.1109/ICASSP.2007.367271",
	issn = "1520-6149",
	keywords = "expectation-maximisation algorithm; expectation-maximization algorithm; Gaussian processes; harmonic phases quantization; phase spectra; speech coding; speech harmonic sinusoidal representations; speech processing; stochastic modeling; wrapped Gaussian mixture models",
	pages = "1121--1124",
	title = "{Stochastic Modeling and Quantization of Harmonic Phases in Speech using Wrapped Gaussian Mixture Models}",
	volume = "4",
	year = "2007"
}

@article{MalyskaN2008,
	abstract = "Regions of nonmodal phonation, which exhibit deviations from uniform glottal-pulse periods and amplitudes, occur often in speech and convey information about linguistic content, speaker identity, and vocal health. Some aspects of these deviations are random, including small perturbations, known as jitter and shimmer, as well as more significant aperiodicities. Other aspects are deterministic, including repeating patterns of fluctuations such as diplophonia and triplophonia. These deviations are often the source of misinterpretation of the spectrum. In this paper, we introduce a general signal-processing framework for interpreting the effects of both stochastic and deterministic aspects of nonmodality on the short-time spectrum. As an example, we show that the spectrum is sensitive to even small perturbations in the timing and amplitudes of glottal pulses. In addition, we illustrate important characteristics that can arise in the spectrum, including apparent shifting of the harmonics and the 
appearance of multiple pitches. For stochastic perturbations, we arrive at a formulation of the power-spectral density as the sum of a low-pass line spectrum and a high-pass noise floor. Our findings are relevant to a number of speech-processing areas including linear-prediction analysis, sinusoidal analysis-synthesis, spectrally derived features, and the analysis of disordered voices.",
	author = "Malyska, N. and Quatieri, T.F.",
	doi = "10.1109/TASL.2007.911063",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	keywords = "glottal-pulse period; linguistic content information; low-pass line spectrum; power-spectral density; signal representation; speaker identity; spectral analysis; spectral nonmodal phonation representation; speech processing; speech signal processing; stochastic perturbation; stochastic processes; vocal health",
	number = "1",
	pages = "34--46",
	title = "{Spectral Representations of Nonmodal Phonation}",
	volume = "16",
	year = "2008"
}

@inproceedings{PantazisY2009,
	abstract = "The speech signal is usually considered as stationary during short analysis time intervals. Though this assumption may be sufficient in some applications, it is not valid for high-resolution speech analysis and in applications such as speech transformation and objective voice function assessment for detection of voice disorders. In speech, there are non stationary components, for instance time-varying amplitudes and frequencies, which may change quickly over short time intervals. In this paper, a previously suggested time-varying quasi-harmonic model is extended in order or to estimate the chirp rate for each sinusoidal component, thus successfully tracking fast variations in frequency and amplitude. The parameters of the model are estimated through linear Least Squares and the model accuracy is evaluated on synthetic chirp signals. Experiments on speech signals indicate that the new model is able to efficiently estimate the signal component chirp rates, providing means to develop more accurate 
speech models for high-quality speech transformations.",
	author = "Pantazis, Y. and Rosec, O. and Stylianou, Y.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing }",
	doi = "10.1109/ICASSP.2009.4960501",
	issn = "1520-6149",
	keywords = "chirp rate estimation; high-resolution speech analysis; least squares approximations; linear least squares; objective voice function assessment; short analysis time intervals; speech processing; speech signal; speech transformation; synthetic chirp signals; time-varying quasi-harmonic model; voice disorders. detection",
	number = "",
	pages = "3985--3988",
	title = "{Chirp rate estimation of speech based on a time-varying quasi-harmonic model}",
	volume = "",
	year = "2009"
}

@inproceedings{RoebelA2007b,
	author = "Roebel, A.",
	booktitle = "{International Conference on Signal and Image Processing}",
	title = "{Parameter Estimation for linear AM/FM sinusoids using frequency domain demodulation}",
	volume = "1",
	year = "2007"
}

@phdthesis{PantazisY2010phd,
	author = "Pantazis, Yannis",
	school = "University of Crete",
	title = "{Decomposition of AM-FM Signals with Applications in Speech Processing}",
	year = "2010"
}

@book{MarvastiF2001,
	abstract = "This hard cover print on demand book can incur an additional 1-2 working days handling time on top of the regular 2-3 working day delivery for UK standard delivery. Please note expedited shipping does not accelerate delivery times for print on demand books. We ship using Royal Mail or courier in the UK and Europe with tracking number for heavier or more valuable items. All USA orders have a shipment tracking number.Our understanding of nature is often through nonuniform observations in space or time. In space, one normally observes the important features of an object, such as edges. The less important features are interpolated. History is a collection of important events that are nonuniformly spaced in time. Historians infer between events (interpolation) and politicians and stock market analysts forecast the future from past and present events (extrapolation). The 20 chapters of Nonuniform Sampling: Theory and Practice contain contributions by leading researchers in nonuniform and Shannon 
sampling, zero crossing, and interpolation theory. Its practical applications include NMR, seismology, speech and image coding, modulation and coding, optimal content, array processing, and digital filter design. It has a tutorial outlook for practising engineers and advanced students in science, engineering, and mathematics. It is also a useful reference for scientists and engineers working in the areas of medical imaging, geophysics, astronomy, biomedical engineering, computer graphics, digital filter design, speech and video processing, and phased array radar. A special feature of the package is a CD-ROM containing C-codes, Matlab and Mathcad programs for the algorithms presented.1. Introduction; F. Marvasti. 2. An Introduction to Sampling Analysis; P.L. Butzer, et al. 3. Lagrange Interpolation and Sampling Theorems; A.I. Zayed, P.L. Butzer. 4. Random Topics in Nonuniform Sampling; F. Marvasti. 5. Iterative and Noniterative Recovery of Missing Samples for 1-{D} Band-Limited Signals; P.J.S.G. Ferreira. 6. 
Numerical and Theoretical Aspects of Nonuniform Sampling of Band-Limited Images; K. Gr{\~A} chenig, T. Strohmer. 7. The Nonuniform Discrete Fourier Transform; S. Bagchi, S.K. Mitra. 8. Reconstruction of Stationary Processes Sampled at Random Times; B. Lacaze. 9. Zero Crossings of Random Processes with Application to Estimation and Detection; J. Barnett. 10. Magnetic Resonance Image Reconstruction from Nonuniformly Sampled k-Space Data; F.T.A.W. Wajer, et al. 11. Irregular and Sparse Sampling in Exploration Seismology; A.J.W. Duijndam, et al. 12. Randomized Digital Optimal Control; W.L. de Koning, L.G. van Willigenburg. 13. Prediction of Band-Limited Signals from Past Samples and Applications to Speech Coding; D.H. Muler, Y. Wu. 14. Frames, Irregular Sampling, and a Wavelet Auditory Model; J.J. Benedetto, S. Scott. 15. Application of the Nonuniform Sampling to Motion Compensated Prediction; A. Sharif, et al. 16. Applications of Nonuniform Sampling to Nonlinear Modulation, A/D and D/A Techniques; F. Marvasti, 
M. Sandler. 17. Applications to Error Correction Codes; F. Marvasti. 18. Application of Nonuniform Sampling to Error Concealment; M. Hasan, F. Marvasti. 19. Sparse Sampling in Array Processing; S. Holm, et al. 20. Fractional Delay Filters: Design and Applications; V. V{\"a}lim{\"a}ki, T.I. Laakso. Brand NEW unread book. This item is printed on demand. Perfectly bound book in mint condition.",
	author = "Marvasti, Farokh",
	isbn = "0306464454",
	publisher = "Springer",
	title = "{Nonuniform Sampling: Theory and Practice}",
	year = "2001"
}

@article{WeruagaL2007,
	author = "Weruaga, L and Kepesi, M",
	journal = "Signal Processing",
	number = "6",
	pages = "1504--1522",
	title = "{The {F}an-{C}hirp {T}ransform for non-stationary harmonic signals}",
	url = "http://linkinghub.elsevier.com/retrieve/pii/S0165168407000114",
	volume = "87",
	year = "2007"
}

@inproceedings{ShigaY2009,
	abstract = "This study investigates a new spectral representation that is suitable for statistical parametric speech synthesis. Statisti- cal speech processing involves spectral averaging in the train- ing process; however, averaging spectra in the domain of con- ventional speech parameters over-smooths the resulting means, which degrades the quality of the speech synthesised. In the proposed representation, high-energy parts of the spectrum, such as sections of dominant formants, are represented by a group of high-density pulses in the frequency domain. These pulses{\rq} locations (i.e., frequencies) are then parameterised. The representation is theoretically capable of averaging spectra with less over-smoothing effect. The experimental results provide the optimal values of factors necessary for the encoding and decoding of the proposed representation towards the future ap- plications of speech synthesis.",
	author = "Shiga, Yoshinori",
	booktitle = "{Proc. Interspeech}",
	pages = "1771--1774",
	title = "{Pulse Density Representation of Spectrum for Statistical Speech Processing}",
	year = "2009"
}

@inproceedings{HezardT2011,
	author = "Hezard, T. and Helie, T. and Doval, B. and Causse, R. and Degottex, G.",
	booktitle = "{Proc. Pan-European Voice Conferences (PEVOC)}",
	title = "{Glottal area waveform study from high speed video-endoscopic recordings and voice production model with aeroacoustic coupling driven by a forced glottal folds model}",
	year = "2011"
}

@mastersthesis{LemmettyS1999,
	author = "Lemmetty, S.",
	school = "Helsinki University of Technology",
	title = "{Review of Speech Synthesis Technology}",
	year = "1999"
}

@phdthesis{DrugmanT2011,
	abstract = "From artiÃ¯Â¬Âcial voices in GPS to automatic systems of dictation, from voice-based identity veriÃ¯Â¬Âcation to voice pathology detection, speech processing applications are nowadays om- nipresent in our daily life. By oÃ¯Â¬Âering solutions to companies seeking for eÃ¯Â¬Âciency enhancement with simultaneous cost saving, the market of speech technology is forecast to be particularly promising in the next years. The present thesis deals with advances in glottal analysis in order to incorporate new techniques within speech processing applications. While current systems are usually based on information related to the vocal tract conÃ¯Â¬Âguration, the airÃ¯Â¬Âow passing through the vocal folds, and called glottal Ã¯Â¬Âow, is expected to exhibit a relevant complementarity. Unfortunately, glottal analysis from speech recordings requires speciÃ¯Â¬Âc complex processing operations, which explains why it has been generally avoided. The main goal of this thesis is to provide new advances in glottal 
analysis so as to pop- ularize it in speech processing. First, new techniques for glottal excitation estimation and modeling are proposed and shown to outperform other state-of-the-art approaches on large corpora of real speech. Moreover, proposed methods are integrated within various speech processing applications: speech synthesis, voice pathology detection, speaker recognition and expressive speech analysis. They are shown to lead to a substantial improvement when compared to other existing techniques. More speciÃ¯Â¬Âcally, the present thesis covers three separate but interconnected parts. In the Ã¯Â¬Ârst part, new algorithms for robust pitch tracking and for automatic determination of glottal closure instants are developed. This step is necessary as accurate glottal analysis requires to process pitch-synchronous speech frames. In the second part, a new non-parametric method based on Complex Cepstrum is proposed for glottal Ã¯Â¬Âow estimation. In addition, a way to achieve this decomposition 
asynchronously is investigated. A comprehensive comparative study of glottal Ã¯Â¬Âow estimation approaches is also given. Relying on this expertise, the usefulness of glottal information for voice pathology detection and expressive speech analysis is explored. In the third part, a new excitation modeling called Deterministic plus Stochastic Model of the residual signal is proposed. This model is applied to speech synthesis where it is shown to enhance the naturalness and quality of the delivered voice. Finally, glottal signatures derived from this model are observed to lead to an increase of identiÃ¯Â¬Âcation rates for speaker recognition purpose.",
	author = "Drugman, Thomas",
	school = "University of Mons",
	title = "{Advances in Glottal Analysis and its Applications}",
	year = "2011"
}

@inproceedings{MarpleS1997,
	abstract = "Starting with a real-valued N-point discrete-time signal, frequency-domain algorithms are provided for computing (1) the complex-valued standard N-point discrete time `analytic' signal of the same sample rate, (2) the complex-valued decimated N/2-point discrete-time `analytic' signal of half the original sample rate, and (3) the complex-valued interpolated NM-point discrete-time `analytic' signal of M times the original sample rate. Special adjustment of transform end points is shown to generate proper discrete-time `analytic' signals",
	author = "Marple, S.L. Jr.",
	booktitle = "{Signals, Systems Computers, 1997. Conference Record of the Thirty-First Asilomar Conference on}",
	doi = "10.1109/ACSSC.1997.679118",
	number = "",
	pages = "1322--1325",
	title = {{Computing the discrete-time "analytic" signal via FFT}},
	volume = "2",
	year = "1997"
}

@inproceedings{LanchantinP2011b,
	author = "Lanchantin, P. and Farner, S. and Veaux, C. and Degottex, G. and Obin, N. and Beller, G. and Villavicencio, F. and Huber, S. and Peeters, G. and Roebel, A. and Rodet, X.",
	booktitle = "{Proc. Digital Audio Effects (DAFx)}",
	location = "Paris, France",
	month = "Sep.",
	pages = "277--285",
	title = "{Vivos Voco: A Survey of Recent Research on Voice Transformations at Ircam}",
	year = "2011"
}

@inproceedings{RoebelA2012singing,
	abstract = "The present article investigates into the use of the LF glottal pulse model for singing synthesis and transformation. A recent estimator of the LF-glottal pulse shape parameter (rd) is used to analyze a small collection of professional singing examples and the results are discussed in the context of recent Ã¯Â¬Ândings relating the rd shape parameter to other speech signal parameters (intensity and vibrato). We propose a rd shape parameter model for vibrato rendering and present an algorithm that allows modifying the glottal pulse shape parameter of a given speech signal and is used to enhance the vibrato generation in a speech to singing transformation system.",
	author = "Roebel, A. and Huber, S. and Rodet, X. and Degottex, G.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech and Signal Processing }",
	title = "{Analysis and Modification of Excitation Source Characteristics for Singing Voice Synthesis}",
	year = "2012"
}

@article{JunquaJC1993,
	author = "Junqua, J.C.",
	journal = "JASA",
	number = "1",
	pages = "510--524",
	title = "{The Lombard reflex and its role on human listeners and automatic speech recognizers}",
	volume = "93",
	year = "1993"
}

@article{VanSummersW1988,
	author = "Summers, W. Van and Pisoni, D. B. and Bernacki, R. H. and Pedlow, R. I. and Stokes, M. A.",
	journal = "J. Acous. Soc. Am.",
	number = "3",
	pages = "917--928",
	title = "{Effects of noise on speech producton: Acoustical and Perceptual analyses}",
	volume = "84",
	year = "1988"
}

@inproceedings{DrugmanT2010,
	author = "Drugman, T. and Dutoit, Thierry",
	booktitle = "{Interspeech}",
	pages = "2610--2613",
	title = "{Glottal-based Analysis of the Lombard Effect}",
	year = "2010"
}

@techreport{ITURBS128412003,
	author = "Assembly, The ITU Radiocommunication",
	institution = "ITU",
	title = "{ITU-R BS.1284-1: EN-General methods for the subjective assessment of sound quality}",
	year = "2003"
}

@techreport{KabalP2003iturbs1387,
	author = "Kabal, P.",
	institution = "McGill University",
	title = "{An Examination and Interpretation of ITU-R BS.1387: Perceptual Evaluation of Audio Quality}",
	year = "2003"
}

@inproceedings{DemolM2005wsola,
	author = "Demol, M. and Verhelst, W. and Struyve, K. and Verhoeve, P.",
	booktitle = "{Proc. Conference on Speech and Computer (SPECOM)}",
	pages = "166--169",
	title = "{Efficient Non-uniform Time-scaling Of Speech With {WSOLA}}",
	year = "2005"
}

@inproceedings{HernaezI2011,
	author = "Hernaez, I. and Saratxaga, I. and Sanchez, J. and Navas, E. and Luengo, I.",
	booktitle = "{Proc. Interspeech}",
	pages = "2757--2760",
	title = "{Use of the Harmonic Phase in Speaker Recognition}",
	year = "2011"
}

@inproceedings{KawaharaH2001aper,
	author = "Kawahara, H. and Estill, J. and Fujimura, O.",
	booktitle = "{MAVEBA}",
	title = "{Aperiodicity extraction and control using mixed mode excitation and group delay manipulation for a high quality speech analysis, modification and synthesis system STRAIGHT}",
	year = "2001"
}

@techreport{DegottexG2012techHM,
	author = "Degottex, G.",
	institution = "University of Crete",
	title = "{Harmonic Models for Voice Tranformation}",
	year = "2012"
}

@inproceedings{DegottexG2012tenspd,
	author = "Degottex, G. and Godoy, E. and Stylianou, Y.",
	booktitle = "{Proc. The Listening Talker: An interdisciplinary workshop on natural and synthetic modification of speech in response to listening conditions}",
	location = "Edinburgh",
	pages = "60",
	title = "{Identifying Tenseness of Lombard Speech Using Phase Distortion}",
	year = "2012"
}

@inproceedings{CabralJP2011hmmlf,
	abstract = "A major factor which causes a deterioration in speech quality in HMM-based speech synthesis is the use of a simple delta pulse signal to generate the excitation of voiced speech. This paper sets out a new approach to using an acoustic glottal source model in HMM-based synthesisers instead of the traditional pulse signal. The goal is to improve speech quality and to better model and transform voice characteristics. We have found the new method decreases buzziness and also improves prosodic modelling. A perceptual evaluation has supported this finding by showing a 55.6\% preference for the new system, as against the baseline. This improvement, while not being as significant as we had initially expected, does encourage us to work on developing the proposed speech synthesiser further.",
	author = "Cabral, J.P. and Renals, S. and Yamagishi, J. and Richmond, K.",
	booktitle = "{IEEE International Conference on Acoustics, Speech and Signal Processing }",
	doi = "10.1109/ICASSP.2011.5947405",
	issn = "1520-6149",
	keywords = "acoustic glottal source model LF-model; delta pulse signal; hidden Markov models; HMM-based speech synthesiser; perceptual evaluation; prosodic modelling; speech quality; speech synthesis; voiced speech generation",
	month = "may",
	number = "",
	pages = "4704--4707",
	title = "{{HMM}-based speech synthesiser using the LF-model of the glottal source}",
	volume = "",
	year = "2011"
}

@phdthesis{CabralJP2010phd,
	address = "U.K.",
	author = "Cabral, Joao Paulo",
	school = "CSTR, University of Edinburgh",
	title = "{{HMM}-based speech synthesis using an Acoustic Glottal Source Model}",
	year = "2010"
}

@article{RaitioT2011hmmginv,
	abstract = "This paper describes an hidden Markov model (HMM)-based speech synthesizer that utilizes glottal inverse filtering for generating natural sounding synthetic speech. In the proposed method, speech is first decomposed into the glottal source signal and the model of the vocal tract filter through glottal inverse filtering, and thus parametrized into excitation and spectral features. The source and filter features are modeled individually in the framework of HMM and generated in the synthesis stage according to the text input. The glottal excitation is synthesized through interpolating and concatenating natural glottal flow pulses, and the excitation signal is further modified according to the spectrum of the desired voice source characteristics. Speech is synthesized by filtering the reconstructed source signal with the vocal tract filter. Experiments show that the proposed system is capable of generating natural sounding speech, and the quality is clearly better compared to two HMM-based speech 
synthesis systems based on widely used vocoder techniques.",
	author = "Raitio, T. and Suni, A. and Yamagishi, J. and Pulakka, H. and Nurminen, J. and Vainio, M. and Alku, P.",
	doi = "10.1109/TASL.2010.2045239",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	keywords = "concatenating natural glottal flow pulses; glottal excitation signal; glottal inverse filtering; glottal source signal reconstruction; hidden Markov model; hidden Markov models; HMM-based speech synthesis; interpolating natural glottal flow pulses; natural sounding synthetic speech; signal reconstruction; spectral features; speech synthesis; vocal tract filter; vocoder techniques",
	month = "jan.",
	number = "1",
	pages = "153--165",
	title = "{{HMM}-Based Speech Synthesis Utilizing Glottal Inverse Filtering}",
	volume = "19",
	year = "2011"
}

@mastersthesis{MehtaD2006mth,
	author = "Mehta, D.",
	school = "Massachusetts Institute of Technology",
	title = "{ASPIRATION NOISE DURING PHONATION: SYNTHESIS, ANALYSIS, AND PITCH-SCALE MODIFICATION}",
	year = "2003"
}

@inproceedings{ZenHeiga2004hsmm,
	author = "Zen, Heiga and Tokuda, Keiichi and Masuko, Takashi and Kobayashi, Takao and Kitamura, Tadashi",
	booktitle = "{in Proc. of ICSLP}",
	title = "{Hidden Semi-Markov Model Based Speech Synthesis}",
	year = "2004"
}

@inproceedings{DegottexG2012ahm,
	author = "Degottex, G. and Stylianou, Y.",
	booktitle = "{Proc. Interspeech}",
	organization = "ISCA",
	title = "{A Full-Band Adaptive Harmonic Representation of Speech}",
	year = "2012"
}

@inproceedings{HuberS2012mspd2ix,
	address = "Portland, USA",
	author = "{S. Huber}, A Roebel and Degottex, G.",
	booktitle = "{Proc. Interspeech}",
	month = "September",
	organization = "ISCA",
	title = "{Glottal source shape parameter estimation using phase minimization variants}",
	year = "2012"
}

@techreport{KabalP2002iturbs1387,
	author = "Kabal, P.",
	institution = "McGill University",
	title = "{An Examination and Interpretation of ITU-R BS.1387: Perceptual Evaluation of Audio Quality}",
	year = "2002"
}

@phdthesis{SerraX1989phd,
	author = "Serra, X.",
	school = "Stanford University",
	title = "{A System for Sound Analysis/Transformation/Synthesis based on a Deterministic plus Stochastic Decomposition}",
	year = "1989"
}

@book{LaverJ1980voicequality,
	author = "Laver, J.",
	publisher = "Cambridge University Press",
	title = "{THE PHONETIC DESCRIPTION OF VOICE QUALITY}",
	year = "1980"
}

@article{RiceWR1989onew,
	abstract = "We have designed a statistical test that eliminates the assumption of equal group variances from one-way analysis of variance. This test is preferable to the standard technique of trial-and-error transformation and can be shown to be an extension of the Behrens-Fisher T test to the case of three or more means. We suggest that this procedure be used in most applications where the one-way analysis of variance has traditionally been applied to biological data. ",
	author = "Rice, W. R. and Gaines, S. D.",
	journal = "PNAS",
	number = "21",
	pages = "8183--8184",
	title = "{One-way analysis of variance with unequal variances}",
	volume = "86",
	year = "1989"
}

@inproceedings{DemolM2004wsola,
	author = "Demol, M. and Verhelst, W. and Struyve, K. and Verhoeve, P.",
	booktitle = "{Proc. InSTIL/ICALL Symposium}",
	number = "7",
	title = "{Efficient Non-uniform Time-scaling Of Speech With WSOLA for CALL applications}",
	year = "2004"
}

@article{JensenJ2001spenhanc,
	abstract = "This paper presents a sinusoidal model based algorithm for enhancement of speech degraded by additive broad-band noise. In order to ensure speech-like characteristics observed in clean speech, smoothness constraints are imposed on the model parameters using a spectral envelope surface (SES) smoothing procedure. Algorithm evaluation is performed using speech signals degraded by additive white Gaussian noise. Distortion as measured by objective speech quality scores showed a 34\%-41\% reduction over a SNR range of 5-to-20 dB. Objective and subjective evaluations also show considerable improvement over traditional spectral subtraction and Wiener filtering based schemes. Finally, in a subjective AB preference test, where enhanced signals were coded with the G729 codec, the proposed scheme was preferred over the traditional enhancement schemes tested for SNRs in the range of 5 to 20 dB",
	author = "Jensen, J. and Hansen, J.H.L.",
	doi = "10.1109/89.952491",
	issn = "1063-6676",
	journal = "IEEE Trans. on Speech and Audio Processing",
	keywords = "G729 codec; SES smoothing procedure; additive broad-band noise; additive white Gaussian noise; constrained iterative sinusoidal model; objective speech quality scores; smoothness constraints; spectral envelope surface smoothing procedure; speech enhancement; subjective AB preference test; AWGN; acoustic noise; iterative methods; smoothing methods; spectral analysis; speech enhancement",
	number = "7",
	pages = "731--740",
	title = "{Speech enhancement using a constrained iterative sinusoidal model}",
	volume = "9",
	year = "2001"
}

@article{HuYi2010presharmcoch,
	abstract = "Pre-processing based noise-reduction algorithms used for cochlear implants (CIs) can sometimes introduce distortions which are carried through the vocoder stages of CI processing. While the background noise may be notably suppressed, the harmonic structure and/or spectral envelope of the signal may be distorted. The present study investigates the potential of preserving the signal{\rq}s harmonic structure in voiced segments (e.g., vowels) as a means of alleviating the negative effects of pre-processing. The hypothesis tested is that preserving the harmonic structure of the signal is crucial for subsequent vocoder processing. The implications of preserving either the main harmonic components occurring at multiples of F0 or the main harmonics along with adjacent partials are investigated. This is done by first pre-processing noisy speech with a conventional noise-reduction algorithm, regenerating the harmonics, and vocoder processing the stimuli with eight channels of stimulation in steady speech-
shaped noise. Results indicated that preserving the main low-frequency harmonics (spanning 1 or 3 kHz) alone was not beneficial. Preserving, however, the harmonic structure of the stimulus, i.e., the main harmonics along with the adjacent partials, was found to be critically important and provided substantial improvements (41 percentage points) in intelligibility.",
	author = "Hu, Y. and Loizou, P. C.",
	journal = "Journal of Acoustic Society of America",
	number = "1",
	pages = "427--434",
	title = "{On the importance of preserving the harmonics and neighboring partials prior to vocoder processing: Implications for cochlear implants}",
	volume = "127",
	year = "2010"
}

@article{DegottexG2013svln,
	abstract = "In current methods for voice transformation and speech synthesis, the vocal-tract filter is usually assumed to be excited by a flat amplitude spectrum. In this article, we present a method using a mixed source model defined as a mixture of the Liljencrants-Fant (LF) model and Gaussian noise. Using the LF model, the base approach used in this presented work is therefore close to a vocoder using exogenous input like ARX-based methods or the Glottal Spectral Separation (GSS) method. Such approaches are therefore dedicated to voice processing promising an improved naturalness compared to generic signal models. Also, using spectral division like in GSS, we show that a glottal source model can be used in a more flexible way than in ARX approach. A vocal-tract filter estimate is therefore derived to take into account the amplitude spectra of both deterministic and random components of the glottal source. The proposed mixed source model is controlled by a small set of intuitive and independent 
parameters. The relevance of this voice production model is evaluated, through listening tests, in the context of resynthesis, HMM-based speech synthesis, breathiness modification and pitch transposition.",
	author = "Degottex, G. and Lanchantin, P. and Roebel, A. and Rodet, X.",
	doi = "10.1016/j.specom.2012.08.010",
	issn = "0167-6393",
	journal = "Speech Communication",
	keywords = "Mixed source; glottal model; vocal-tract filter; voice quality; voice transformation; speech synthesis",
	number = "2",
	pages = "278--294",
	publisher = "Elsevier",
	title = "{Mixed source model and its adapted vocal tract filter estimate for voice transformation and synthesis}",
	volume = "55",
	year = "2013"
}

@article{DegottexG2013jahmair,
	author = "Degottex, G. and Stylianou, Y.",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech and Language Processing",
	number = "10",
	pages = "2085--2095",
	title = "{Analysis and Synthesis of Speech Using an Adaptive Full-Band Harmonic Model}",
	volume = "21",
	year = "2013"
}

@inproceedings{AgiomyrgiannakisY2011tvenv,
	author = "Agiomyrgiannakis, Y. and Stylianou, Y.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech and Signal Processing }",
	pages = "5400--5403",
	title = "{On the recovery of time-varying spectral envelope information from aQHM-derived spectra.}",
	year = "2011"
}

@article{HoningH2008webexp,
	author = "Honing, H. and Ladinig, O.",
	journal = "Empirical Musicology Review",
	number = "1",
	pages = "4--7",
	title = "{The Potential of the Internet for Music Perception Research: A Comment on Lab-Based Versus Web-Based Studies}",
	volume = "3",
	year = "2008"
}

@book{SmithJO2011,
	author = "Smith, J. O. III",
	isbn = "0974560731 / 9780974560731",
	publisher = "W3K Publishing",
	title = "{Spectral Audio Signal Processing}",
	year = "2011"
}

@article{GriffinD1984mstft,
	author = "Griffin, D. and Lim, Jae",
	issn = "0096-3518",
	journal = "IEEE Trans. on Acoustics, Speech and Signal Processing",
	number = "2",
	pages = "236--243",
	title = "{Signal estimation from modified short-time Fourier transform}",
	volume = "32",
	year = "1984"
}

@article{BozkurtB2007cgd,
	author = "Bozkurt, Baris and Couvreur, Laurent and Dutoit, Thierry",
	issn = "0167-6393",
	journal = "Speech Communication",
	number = "3",
	pages = "159--176",
	title = "{Chirp group delay analysis of speech signals}",
	volume = "49",
	year = "2007"
}

@article{HannaP2005noisesin,
	abstract = "We propose an original model for noise analysis, transformation, and synthesis: the CNSS model. Noisy sounds are represented with short-time sinusoids whose frequencies and phases are random variables. This spectral and statistical model represents information about the spectral density of frequencies. This perceptually relevant property is modeled by three mathematical parameters that define the distribution of the frequencies. This model also represents the spectral envelope. The mathematical parameters are defined and the analysis algorithms to extract these parameters from sounds are introduced. Then algorithms for generating sounds from the parameters of the model are presented. Applications of this model include tools for composers, psychoacoustic experiments, and pedagogy. ",
	author = "Hanna, P. and Desainte-Catherine, M.",
	journal = "EURASIP Journal on Advances in Signal Processing",
	keywords = "stochastic part of sounds; analysis and real-time synthesis of noisy sounds; spectral models; spectral density; musical transformations of sounds",
	pages = "1794--1806",
	title = "{A Statistical and Spectral Model for Representing Noisy Sounds with Short-Time Sinusoids}",
	year = "2005"
}

@article{PaliwalK2011impphaseenhance,
	author = "Paliwal, K. and Wojcicki, K. and Shannon, B.",
	journal = "Speech Communication",
	number = "4",
	pages = "465--494",
	title = "{The importance of phase in speech enhancement}",
	volume = "53",
	year = "2011"
}

@inproceedings{StarkAP2009gdd,
	author = "Stark, A.P. and Paliwal, K.K.",
	booktitle = "{Proc. Interspeech}",
	isbn = "1990-9772",
	title = "{Group-Delay-Deviation Based Spectral Analysis of Speech}",
	year = "2009"
}

@article{HartmannWM1986discrspecdens,
	author = "Hartmann, W. M. and McAdams, Stephen and Gerzso, Andrew and Boulez, Pierre",
	journal = "Journal of Acoustic Society of America",
	number = "6",
	pages = "1915--1925",
	publisher = "ASA",
	title = "{Discrimination of spectral density}",
	volume = "79",
	year = "1986"
}

@inproceedings{SaratxagaI2012perceprps,
	author = "Saratxaga, I. and Hernaez, I. and Pucher, M. and Sainz, I.",
	booktitle = "{Proc. Interspeech}",
	title = "{Perceptual {I}mportance of the {P}hase {R}elated {I}nformation in {S}peech}",
	year = "2012"
}

@article{SaratxagaI2009rpsltr,
	author = "Saratxaga, I. and Hernaez, I. and Erro, D. and Navas, E. and Sanchez, J.",
	issn = "0013-5194",
	journal = "Electronics Letters",
	number = "7",
	pages = "381--383",
	title = "{Simple representation of signal phase for harmonic speech models}",
	volume = "45",
	year = "2009"
}
@ARTICLE{Martinsigpro2006,
author = {R. Martin},
journal = {Signal Processing},
title = {Bias compensation methods for minimum statistics noise power spectral density estimation},
volume = {86},
number = {6},
pages = {1215 - 1229},
year = {2006},
}
@book{MardiaKV1999,
	abstract = "Presents new and up-dated material on both the underlying theory and the practical methodology of directional statistics, helping the reader to utilise and develop the techniques appropriate to their work. The book is divided into three parts. The first part concentrates on statistics on the circle. Topics covered include tests of uniformity, tests of good-of-fit, inference on von Mises distributions and non-parametric methods. The second part considers statistics on spheres of arbitrary dimension, and includes a detailed account of inference on the main distributions on spheres. Recent material on correlation, regression time series, robust techniques, bootstrap methods, density estimation and curve fitting is presented. The third part considers statistics on more general sample spaces, in particular rotation groups, Stiefel manifolds, Grassmann manifolds and complex projective spaces. Shape analysis is considered from the perspective of directional statistics. Written by leading authors in the 
field, this text will be invaluable not only to researchers in probability and statistics interested in the latest developments in directional statistics, but also to practitioners and researchers in many scientific fields, including astronomy, biology, computer vision, earth sciences and image analysis. ",
	author = "Mardia, K. V. and Jupp, P. E.",
	edition = "Wiley",
	isbn = "978-0471953333",
	title = "{Directional Statistics}",
	year = "1999"
}

@inproceedings{KafentzisGP2012modvoiceless,
	author = "Kafentzis, G.P. and Rosec, O. and Stylianou, Y.",
	booktitle = "{Proc. Interspeech}",
	title = "{On the Modeling of Voiceless Stop Sounds of Speech using Adaptive Quasi-Harmonic Models. In: Interspeech 2012, Portland, U.S.A, September 9-13, 2012.}",
	year = "2012"
}

@inproceedings{ErroD2011ahocoder2,
	author = "Erro, D. and Sainz, I. and Navas, E. and Hernaez, I.",
	booktitle = "{Proc. Interspeech}",
	title = "{Improved HNM-based Vocoder for Statistical Synthesizers}",
	year = "2011"
}

@inproceedings{ErroD2011ahocoder1,
	author = "Erro, D. and Sainz, I. and Navas, E. and Hernaez, I.",
	booktitle = "{Proc. IEEE Int. Conf. on Acoustics, Speech and Sig. Proc. }",
	pages = "4728--4731",
	title = "{HNM-based MFCC+F0 extractor applied to statistical speech synthesis}",
	year = "2011"
}

@inproceedings{KafentzisGP2012eaqhm,
	author = "Kafentzis, G.P. and Pantazis, Y. and Rosec, O. and Stylianou, Y.",
	booktitle = "{Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing }",
	title = "{An extension of the adaptive Quasi-Harmonic Model}",
	year = "2012"
}

@techreport{ITUTP8622000,
	author = "Assembly, The ITU Radiocommunication",
	institution = "ITU",
	title = "{ITU-T P.862: Perceptual evaluation of speech quality (PESQ): An objective method for end-to-end speech quality assessment of narrow-band telephone networks and speech codecs}",
	year = "2000"
}

@inproceedings{KafentzisGP2013timescaleahm,
	author = "Kafentzis, G. and Degottex, G. and Rosec, O. and Stylianou, Y.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech and Signal Processing }",
	title = "{Time-Scale Modifications Based on a Full-Band Adaptive Harmonic Model}",
	year = "accepted for publication, 2013"
}

@article{WangTianyu2010,
	author = "Wang, T.T. and Quatieri, T.F.",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	number = "1",
	pages = "171--186",
	title = "{High-Pitch Formant Estimation by Exploiting Temporal Change of Pitch}",
	volume = "18",
	year = "2010"
}

@proceedings{TodaT2005gv,
	author = "Toda, T. and Tokuda, K.",
	booktitle = "{Proc. Interspeech}",
	title = "{Speech Parameter Generation Algorithm Considering Global Variance for HMM-Based Speech Synthesis}",
	year = "2005"
}

@inproceedings{MowlaeeP2013phiestimforsep,
	author = "Mowlaee, P. and Saeidi, R. and Martin, R.",
	booktitle = "{Proceedings of the International Conference on Spoken Language Processing}",
	title = "{Phase Estimation for Signal Reconstruction in Single-channel Speech Separation}",
	year = "2012"
}

@INPROCEEDINGS{icassp2013,
	author = "Mowlaee, P. and Saeidi, R.", 
	title = "On Phase Importance in Parameter Estimation in Single-channel Speech Enhancement",
	booktitle = "IEEE International Conference on Acoustics, Speech and Signal Processing",
	year = "2013",
	pages = "7462-7466",
}

@inproceedings{DegottexG2013phaseimp,
	author = "Degottex, G.",
	booktitle = "{Proc. Interspeech}",
	month = "submitted",
	title = "{The importance of the phase in analysis and synthesis methods}",
	year = "2013"
}

@article{KuhlPK2011whostalking,
	author = "Kuhl, P.K.",
	journal = "Science",
	pages = "529--530",
	title = "{Who{\rq}s Talking?}",
	volume = "333",
	year = "2011"
}

@article{HagerEB2012,
	author = "Hager, E. B.",
	journal = "The New York Times",
	month = jul,
	title = "{For Children Who Cannot Speak, a True Voice via Technology}",
	year = "2012"
}

@article{USAToday2006hawkingvoice,
	author = "USAToday",
	journal = "USA Today",
	month = "june",
	number = "June 15th",
	organization = "The Associated Press",
	title = "{Stephen Hawking says pope told him not to study beginning of universe}",
	year = "2006"
}

@article{MooreBCJ1983,
	author = "Moore, Brian C. J. and Glasberg, Brian R.",
	journal = "The Journal of the Acoustical Society of America",
	number = "3",
	pages = "750--753",
	publisher = "ASA",
	title = "{Suggested formulae for calculating auditory-filter bandwidths and excitation patterns}",
	volume = "74",
	year = "1983"
}

@book{Castellengo1986,
	author = "Castellengo, M.",
	pages = "45--70",
	series = "{Le livre des techniques du son, tome 1}",
	title = "{Les sources acoustiques}",
	year = "1986"
}

@article{Belin2000,
	author = "Belin, P. and Zatorre, R.J. and Lafaille, P. and Ahad, P. and Pike, B.",
	journal = "Nature",
	pages = "309--312",
	title = "{Voice-selective areas in human auditory cortex}",
	volume = "403.6767",
	year = "2000"
}

@article{Belin2004,
	author = "Belin, P. and Fecteau, S. and Bedard, C.",
	journal = "Trends in cognitive sciences",
	pages = "129--135",
	title = "{Thinking the voice: neural correlates of voice perception}",
	volume = "8.3",
	year = "2004"
}

@article{Lattner2005,
	author = "Lattner, S. and Meyer, M.E. and Friederici, A. D.",
	journal = "Human brain mapping",
	pages = "11--20",
	title = "{Voice perception: Sex, pitch, and the right hemisphere}",
	volume = "24.1",
	year = "2005"
}

@article{Mendoza1996,
	author = "Mendoza, E. and Valencia, N. and Munoz, J. and Trujillo, H.",
	journal = "Journal of Voice",
	pages = "59--66",
	title = "{Differences in voice quality between men and women: use of the long-term average spectrum (LTAS)}",
	volume = "10.1",
	year = "1996"
}

@article{Mullennix1995,
	author = "Mullennix, J.W. and Johnson, K.A. and Topcu-Durgun, M. and Farnsworth, L.M.",
	journal = "The Journal of the Acoustical Society of America",
	pages = "3080--95",
	title = "{The perceptual representation of voice gender}",
	volume = "98",
	year = "1995"
}

@article{Schotz2006,
	author = "Schotz, Susanne",
	booktitle = "{Graduate School of Language Technology (GSLT)}",
	title = "{Perception, analysis and synthesis of speaker age}",
	volume = "47",
	year = "2006"
}

@article{Perry2001,
	author = "Perry, T.L. and Ohde, R.N. and Ashmead, D.H.",
	journal = "The Journal of the Acoustical Society of America",
	pages = "2988--98",
	title = "{The acoustic bases for gender identification from children's voices}",
	volume = "109",
	year = "2001"
}

@article{Kitamura2005,
	author = "Kitamura, T. and Honda, K. and Takemoto, H.",
	journal = "Acoustical science and technology",
	pages = "16--26",
	title = "{Individual variation of the hypopharyngeal cavities and its acoustic effects}",
	volume = "26.1",
	year = "2005"
}

@article{Evans2006,
	author = "Evans, S. and Neave, N. and Wakelin, D.",
	journal = "Biological psychology",
	pages = "160--163",
	title = "{Relationships between vocal characteristics and body size and shape in human males: an evolutionary explanation for a deep male voice}",
	volume = "72.2",
	year = "2006"
}

@article{Gardner1996,
	author = "Gardner, G. M. and Benninger, M. S.",
	journal = "Current Opinion in Otolaryngology \& Head and Neck Surgery",
	pages = "113",
	title = "{The definition and measurement of hoarseness}",
	volume = "4",
	year = "1996"
}

@article{Omori1997,
	author = "Omori, K. and Kojima, H. and Kakani, R. and Slavit, D.H. and Blaugrund, S.M.",
	journal = "Journal of Voice",
	pages = "40--47",
	title = "{Acoustic characteristics of rough voice: subharmonics}",
	volume = "11.1",
	year = "1997"
}

@article{Altenberge2006,
	author = "Altenberg, E. P. and Ferrand, C.T.",
	journal = "Journal of Voice",
	pages = "89--96",
	title = "{Fundamental frequency in monolingual English, bilingual English/Russian, and bilingual English/Cantonese young adult women}",
	volume = "20.1",
	year = "2006"
}

@article{Gallois1981,
	author = "Gallois, C. and Callan, V. J.",
	journal = "Journal of Cross-Cultural Psychology",
	pages = "347--359",
	title = "{Personality impressions elicited by accented English speech}",
	volume = "12.3",
	year = "1981"
}

@article{Sapir1927,
	author = "Sapir, E.",
	journal = "American Journal of Sociology",
	pages = "892--905",
	title = "{Speech as a personality trait}",
	year = "1927"
}

@book{Scherer1979,
	author = "Scherer, K. R.",
	edition = "Cambridge University Press",
	title = "{Personality markers in speech}",
	year = "1979"
}

@article{Keller2005,
	author = "Keller, B. Z.",
	journal = "Logopedics Phonatrics Vocology",
	pages = "72--78",
	title = "{Speech prosody, voice quality and personality}",
	volume = "30.2",
	year = "2005"
}

@inproceedings{LeGac2005,
	author = "{Le Gac}, D. and Jamin, M. and Lehka, I.",
	booktitle = "{Proc. Speech Prosody}",
	title = "{A preliminary study of prosodic patterns in two varieties of suburban youth speech in France}",
	year = "2006"
}

@article{Pittam1990,
	author = "Pittam, J. and Gallois, C. and Callan, V. J.",
	journal = "Speech Communication",
	pages = "177--187",
	title = "{The long-term spectrum and perceived emotion}",
	volume = "9.3",
	year = "1990"
}

@article{Ladd1985,
	journal = "The Journal of the Acoustical Society of America",
	pages = "435--444",
	title = "{Evidence for the independent function of intonation contour type, voice quality, and F0 range in signaling speaker affect}",
	volume = "78",
	year = "1985"
}

@inproceedings{Ehrette2002,
	author = "Ehrette, T. and Chateau, N. and d{\rq}Alessandro, C. and Maffiolo, V.",
	booktitle = "{Proc. Speech Prosody}",
	title = "{Prosodic parameters of perceived emotions in vocal server voices}",
	year = "2002"
}

@article{Hummert1999,
	author = "Hummert, M. L. and Mazloff, D. and Clark, H.",
	journal = "Journal of Nonverbal Behavior",
	pages = "111--132",
	title = "{Vocal characteristics of older adults and stereotyping}",
	volume = "23.2",
	year = "1999"
}

@article{Shipp1969,
	author = "Shipp, T. and Hollien, H.",
	journal = "Journal of Speech, Language and Hearing Research",
	pages = "703--710",
	title = "{Perception of the aging male voice}",
	volume = "12.4",
	year = "1969"
}

@article{Garnier2007,
	author = "Garnier, M. and Henrich, N. and Castellengo, M. and Sotiropoulos, D. and Dubois, D.",
	journal = "Journal of interdisciplinary music studies",
	pages = "62--91",
	title = "{Characterisation of voice quality in Western lyrical singing: From teachers' judgements to acoustic descriptions}",
	volume = "1.2",
	year = "2007"
}

@article{Henrich2008,
	author = "Henrich, N. and Bezard, P. and Expert, R. and Garnier, M. and Guerin, C. and Pillot, C. and Quattrocchi, S. and Roubeau, B. and Terk, B.",
	journal = "Journal of interdisciplinary music studies",
	pages = "71--93",
	title = "{Towards a common terminology to describe voice quality in western lyrical singing: Contribution of a multidisciplinary research group}",
	volume = "2.1-2",
	year = "2008"
}

@article{Kreiman1992,
	author = "Kreiman, J. and Gerratt, B.R. and Precoda, K. and Berke, G.S.",
	journal = "Journal of Speech, Language and Hearing Research",
	pages = "512--520",
	title = "{Individual differences in voice quality perception}",
	volume = "35.3",
	year = "1992"
}

@inproceedings{Wilting2006,
	author = "Wilting, J. and Krahmer, E. and Swerts, M.",
	booktitle = "{Proc. Interspeech}",
	title = "{Real vs. acted emotional speech}",
	year = "2006"
}

@inproceedings{Schuller2006,
	author = "Schuller, B. and Arsic, D. and Wallhoff, F. and Rigoll, G.",
	booktitle = "{Proc. Speech Prosody}",
	pages = "276--289",
	title = "{Emotion recognition in the noise applying large acoustic feature sets}",
	year = "2006"
}

@inproceedings{Hammarberg1997,
	author = "Hammarberg, B.",
	booktitle = "{Proc. Larynx'97}",
	pages = "11--19",
	title = "{Perceptual evaluation of dysphonic voices}",
	year = "1997"
}

@book{Miller1986,
	author = "Miller, R. L.",
	publisher = "New York: Schirmer",
	title = "{The Structure of singing: system and art in vocal technique}",
	year = "1986"
}

@article{EileenD2007,
	journal = "Journal of School Health",
	number = "5",
	pages = "225--231",
	title = "{Noise and Hearing Loss: A Review}",
	volume = "7",
	year = "2007"
}

@article{ZenH2012poehmm,
	author = "Zen, Heiga and Gales, M. J F and Nankaku, Y. and Tokuda, K.",
	issn = "1558-7916",
	journal = "IEEE Trans. on Audio, Speech, and Language Processing",
	number = "3",
	pages = "794--805",
	title = "{Product of Experts for Statistical Parametric Speech Synthesis}",
	volume = "20",
	year = "2012"
}

@inproceedings{LatorreJ2011contf0,
	author = "Latorre, J. and Gales, M. J F and Buchholz, S. and Knill, K. and Tamurd, M. and Ohtani, Y. and Akamine, M.",
	booktitle = "{Proc. IEEE Int. Conf. on Acoustics, Speech and Signal Processing }",
	issn = "1520-6149",
	pages = "4724--4727",
	title = "{Continuous F0 in the source-excitation generation for HMM-based TTS: Do we need voiced/unvoiced classification?}",
	year = "2011"
}

@article{GaudiosiJ2012videogames,
	author = "Gaudiosi, J.",
	journal = "Forbes",
	month = "July",
	title = "{New Reports Forecast Global Video Game Industry Will Reach \$82 Billion by 2017}",
	year = "2012"
}

@inproceedings{VerhelstW1991qual,
	abstract = "It is shown that a recently proposed technique for high-quality waveform manipulation can be formulated as a pitch-excited vocoder. This waveform vocoder produces high-quality speech over a wide range of prosodic modifications, showing that natural sounding speech can be produced using an impulse driven linear synthesis model. In a pilot experiment, waveform vocoding techniques were applied on the LPC (linear predictive coding) residue to investigate the relative importance of amplitude and phase in the synthesis of male and female voices. It was found that the amplitude information contributed more to speech quality than phase information, and that, for male voices, amplitude information alone was sufficient to make the synthetic speech quality almost indistinguishable from that of natural speech ",
	author = "Verhelst, W.",
	booktitle = "{Proc. IEEE International Conference on Acoustics, Speech and Signal Processing }",
	issn = "1520-6149",
	pages = "501--504",
	title = "{On the quality of speech produced by impulse driven linear systems}",
	year = "1991"
}

@inproceedings{DrugmanT2011phipathodetect,
	author = "Drugman, T. and Dubuisson, T. and Dutoit, T.",
	booktitle = "{IEEE Int. Conf. on Acoustics, Speech and Signal Processing }",
	issn = "1520-6149",
	pages = "4612--4615",
	title = "{Phase-based information for voice pathology detection}",
	year = "2011"
}

@article{PainterT2000percepcod,
	author = "Painter, T. and Spanias, A.",
	issn = "0018-9219",
	journal = "Proc. of the IEEE",
	number = "4",
	pages = "451--515",
	title = "{Perceptual coding of digital audio}",
	volume = "88",
	year = "2000"
}

@article{PoblothH2003msephidistortion,
	author = "Pobloth, H. and Kleijn, W. B.",
	journal = "Journal of the Acoustical Society of America",
	number = "2",
	pages = "1081--1094",
	title = "{Squared error as a measure of perceived phase distortion}",
	volume = "114",
	year = "2003"
}

@inproceedings{ZenH2010hmmadapt,
	author = "Zen, Heiga and Braunschweiler, N. and Buchholz, S. and Knill, K. and Krstulovic, S. and Latorre, J.",
	booktitle = "{Proc. 7th ISCA Speech Synthesis Workshop (SSW7)}",
	pages = "186--191",
	title = "{HMM-Based Polyglot Speech Synthesis by Speaker and Language Adaptive Training}",
	year = "2010"
}

@article{YuKai2011adapt,
	address = "Amsterdam, The Netherlands, The Netherlands",
	author = "Yu, Kai and Zen, Heiga and Mairesse, F. and Young, S.",
	issn = "0167-6393",
	journal = "Speech Commun.",
	month = jul,
	number = "6",
	pages = "914--923",
	publisher = "Elsevier Science Publishers B. V.",
	title = "{Context adaptive training with factorized decision trees for HMM-based statistical parametric speech synthesis}",
	volume = "53",
	year = "2011"
}

@inproceedings{VeauxC2012hmmresto,
	abstract = "When individuals lose the ability to produce their own speech, due to degenerative diseases such as motor neuron disease (MND) or Parkinson{\rq}s, they lose not only a functional means of communication but also a display of their individual and group identity. In order to build personalized synthetic voices, attempts have been made to capture the voice before it is lost, using a process known as voice banking. But, for some patients, the speech deterioration frequently coincides or quickly follows diagnosis. Using HMM-based speech synthesis, it is now possible to build personalized synthetic voices with minimal data recordings and even disordered speech. In this approach, the patient{\rq}s recordings are used to adapt an average voice model pre-trained on many speakers. The structure of the voice model allows some reconstruction of the voice by substituting some components from the average voice in order to compensate for the disorders found in the patient{\rq}s speech. In this paper, we compare 
different substitution strategies and introduce a context-dependent model substitution to improve the intelligibility of the synthetic speech while retaining the vocal identity of the patient. A subjective evaluation of the reconstructed voice for a patient with MND shows promising results for this strategy.",
	author = "Veaux, C. and Yamagishi, J. and King, S.",
	booktitle = "{Proc. Interspeech}",
	title = "{Using HMM-based Speech Synthesis to Reconstruct the Voice of Individuals with Degenerative Speech Disorders.}",
	year = "2012"
}

@article{ZenH2009hmmsynth,
	author = "Zen, Heiga and Tokuda, K. and Black, A W.",
	issn = "0167-6393",
	journal = "Speech Communication",
	number = "11",
	pages = "1039--1064",
	title = "{Statistical parametric speech synthesis}",
	volume = "51",
	year = "2009"
}

@article{LipshitzSP1982,
	abstract = "The current state of our knowledge regarding the audible consequences of phase nonlinearities in the audio chain is surveyed, a series of experiments is described which the authors have conducted using a flexible system of all-pass networks carefully constructed for this purpose, and some conclusions are drawn regarding the audible effects of midrange phase distortions. It is known that the inner ear possesses nonlinearity (akin to an acoustic half-wave rectifier) in its mechanical-to-electrical transduction, and this would be expected to modify the signal on the acoustic nerve in a manner which depends upon the acoustic signal waveform, and so upon the relative phase relationships of the frequency components of this signal. Some of these effects have been known for over 30 years, and are quite audible on even very simple signals. Simple experiments are outlined to enable the readers to demonstrate these effects for themselves. Having satisfied ourselves that phase distortions can be audible, 
the types of phase distortions contributed by the various links in the audio chain are surveyed, and it is concluded that only the loudspeaker contributes significant midrange phase nonlinearities. Confining the investigation to the audibility of such phase nonlinearities in the midrange, circuitry is described which enables such effects to be assessed objectivbely fo their audible consequences. The experiments conducted so far lead to a number of conclusions. 1) Even quite small midrange phase nonlinearities can be audible on suitably chosen signals. 2) Audibility is far greater on headphones than on loudspeakers. 3) Simple acoustic signals generated anechoically display clear phase audibility on headphones. 4) On normal music or speech signals phase distortion appears not to be generally audible, although it was heard with 99\% confidence on some recorded vocal material. It is clear that more work needs to be done to ascertain acceptable limits for the phase linearity of audio components-limits which might 
become more stringent as improved recording/reproduction systems become available. It is stressed that none of these experiments thus far has indicated a present requirement for phase linearity in loudspeakers for the reproduction of music and speech. ",
	author = "Lipshitz, S. P. and Pocock, M. and Vanderkooy, J.",
	journal = "J. Audio Eng. Soc",
	number = "9",
	pages = "580--595",
	title = "{On the Audibility of Midrange Phase Distortion in Audio Systems}",
	volume = "30",
	year = "1982"
}

@article{HansenV1974phasepercep,
	author = "Hansen, V. and Madsen, E. R.",
	journal = "J. Audio Eng. Soc",
	number = "1",
	pages = "10--14",
	title = "{On Aural Phase Detection: Part 1}",
	volume = "22",
	year = "1974"
}

@book{FisherNI1955circdata,
	author = "Fisher, N. I.",
	isbn = "0521568900, 9780521568906",
	month = "Oct.",
	publisher = "Cambridge University Press",
	title = "{Statistical Analysis of Circular Data}",
	year = "1995"
}

@INPROCEEDINGS{IS2012a,
	author = "P. Mowlaee and R. Saiedi and R. Martin", 
	title = "Phase estimation for signal reconstruction in single-channel speech separation", 
	booktitle = "Proceedings of the International Conference on Spoken Language Processing",
	year = "2012",
}
@INPROCEEDINGS{showandtell,
	author = {Mowlaee, P. and Watanabe, M. and Saeidi, R.},
	title = {SHOW \& TELL: PHASE-AWARE SINGLE-CHANNEL SPEECH ENHANCEMENT},
	booktitle = {14th Annual Conference of the International Speech Communication Association},
	year = {2013},
}
@INPROCEEDINGS{IS2013,
	author = "Mowlaee, P. and Watanabe, M.", 
	title = "Iterative sinusoidal-based partial phase reconstruction in single-channel source separation",
	booktitle = "IEEE International Conference on Acoustics, Speech and Signal Processing",
	year = "2013",
	pages={832-836}, 	
}

@INPROCEEDINGS{IWAENC2012,
	title = {On Phase Importance in Parameter Estimation for Single-channel Source Separation},
	author = {Mowlaee, P. and Martin, R.},
	booktitle = {The International Workshop on Acoustic Signal Enhancement (IWAENC)},
	year = {2012},
	pages={1-4}, 	
}
@ARTICLE{Lim1982, 
author={Wang, D. and Lim, J.}, 
journal={IEEE Trans. on Acoustics, Speech and Signal Processing}, 
title={The unimportance of phase in speech enhancement}, 
volume={30}, 
number={4}, 
year={1982}, 
pages={679-681}, 
}

@ARTICLE{TimoSPL,
author={Gerkmann, T. and Krawczyk, M.},
journal={IEEE Signal Processing Letters},
title={{MMSE}-Optimal Spectral Amplitude Estimation Given the {STFT}-Phase},
year={2013},
month={Feb. },
volume={20},
number={2},
pages={129 -132},
}

@ARTICLE{Paliwal_enh,
  title     = {The importance of phase in speech enhancement},
  journal   = {Speech Communication},
  author    = {Paliwal, K. K. and Wojcicki, K. K. and Shannon, B. J.},
  volume    = {53},
  number    = {4},
  year      = {2011},
  pages     = {465-494},
}

@article{varga92,
    author = {Varga, A. and Steeneken, H. J. M. and Tomlinson, M. and Jones, D.},
    citeulike-article-id = {1740162},
    journal = {Technical Report, DRA Speech Research Unit},
    title = {{The NOISEX--92 Study on the Effect of Additive Noise on Automatic Speech Recognition}},
    year = {1992}
}
	 
@article{Cooke2010,
 title = {Monaural speech separation and recognition challenge} ,
 author = {Cooke, M. and Hershey, J. R. and Rennie, S. J.},
 journal = {Elsevier Computer Speech and Language},
 volume = {24},
 number = {1},
 year = {2010},
 issn = {0885-2308},
 pages = {1-15},
 }	 
 
 @INPROCEEDINGS {ICASSP2013c,
	author = {Mowlaee, P. and Saeidi, R.},
 title = {Target Speaker Separation in a Multisource Environment Using Speaker-dependent Postfilter and Noise Estimation},
booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing}, 
	year = {2013},
    pages={7254-7258}, 	
	address = {Vancouver, Canada},
}

 @INPROCEEDINGS{NMF2008, 
author={Wilson, K. W. and Raj, B. and Smaragdis, P. and Divakaran, A.}, 
booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing}, 
title={Speech denoising using nonnegative matrix factorization with priors}, 
year={2008}, 
pages={4029-4032}, 
}
@ARTICLE{Saratxaga_IET, 
author={Saratxaga, I. and Hernaez, I. and Erro, D. and Navas, E. and Sanchez, J.}, 
journal={Electronics Letters}, 
title={Simple representation of signal phase for harmonic speech models}, 
year={2009}, 
volume={45}, 
number={7}, 
pages={381 -383}, 
}
@article{snrloss,
 author = {Ma, J. and Loizou, P. C.},
 title = {{SNR Loss}: A New Objective Measure for Predicting the Intelligibility of Noise-suppressed Speech},
 journal = {Speech Commun.},
 volume = {53},
 number = {3},
 month = mar,
 year = {2011},
 pages = {340--354},
 numpages = {15},
} 
  @ARTICLE{Ephraim1985,
  author = {Y. Ephraim and D. Malah},
  title = {Speech Enhancement using a Minimum Mean Square Error Log-Spectral Amplitude Estimator},
  journal = {IEEE Trans. on Acoust., Speech, Signal Processing},
  year = {1985},
  volume = {ASSP-33},
  pages = {443-445},
}
@ARTICLE{Ephraim1984,
  author = {Y. Ephraim and D. Malah},
  title = {Speech enhancement using a minimum-mean square error short-time spectral	amplitude estimator},
  journal = {IEEE Trans. Acoust., Speech, Signal Processing},
  year = {1984},
  volume = {32},
  pages = { 1109-1121},
  number = {6},
}
@ARTICLE{imcra2003, 
author={Cohen, I.}, 
journal={IEEE Trans. on Speech and Audio Processing},
title={Noise spectrum estimation in adverse environments: improved minima controlled recursive averaging}, 
year={2003}, 
month={sept.}, 
volume={11}, 
number={5}, 
pages={ 466 - 475}, 
}
@book{Aarabi2006PhaseBased,
    author = {Aarabi, P.},
    publisher = {World Scientific Publishing},
    title = {{Phase-Based Speech Processing}},
    year = {2006}
}
@INPROCEEDINGS{Maia2012, 
author={Maia, R. and Akamine, M. and Gales, M. J F}, 
booktitle={Acoustics, Speech and Signal Processing , 2012 IEEE International Conference on}, 
title={Complex cepstrum as phase information in statistical parametric speech synthesis}, 
year={2012}, 
month={March}, 
pages={4581-4584}, 
}
@INPROCEEDINGS{Paliwal03usefulnessof,
    author = {Paliwal, K. K. and Alsteris, L.},
    title = {Usefulness of Phase Spectrum in Human Speech Perception},
    booktitle = {Proc. Eurospeech},
    year = {2003},
    pages = {2117--2120},
}
@ARTICLE{Aarabi2006, 
author={Guangji, S. and Shanechi, M. M. and Aarabi, P.}, 
journal={IEEE Trans. on Audio, Speech, and Language Processing}, 
title={On the importance of phase in human speech recognition}, 
year={2006}, 
month={sept.}, 
volume={14}, 
number={5}, 
pages={1867 -1874}, 
}
@article{Kleinschmidt2011585,
author = "Kleinschmidt, T. and Sridharan, S. and Mason, M.",
title = "The use of phase in complex spectrum subtraction for robust speech recognition",
journal = "Computer Speech and Language ",
volume = "25",
number = "3",
pages = "585 - 600",
year = "2011",
}
@INPROCEEDINGS{Schluter2001, 
author={Schluter, R. and Ney, H.}, 
booktitle={icassp}, 
title={Using phase spectrum information for improved speech recognition performance}, 
year={2001}, 
month={}, 
volume={1}, 
pages={133-136 vol.1}, 
}

@ARTICLE{Krishnan2011,
author={Parthasarathi, S. H. and Padmanabhan, R. and Murthy, H. A.},
title={Robustness of group delay representations for noisy speech signals},
journal={International Journal of Speech Technology},
volume={14},
number={4},
year={2011},
pages={361-368},
}
@ARTICLE{ErkelensHHJ07,
  author    = {Erkelens, J. S. and Hendriks, R. C. and Heusdens, R. and Jensen, J.},
  title     = {Minimum Mean-Square Error Estimation of Discrete Fourier Coefficients With Generalized {Gamma} Priors},
  journal   = {IEEE Trans. on Audio, Speech and Language Processing},
  month={Aug}, 
  volume    = {15},
  number    = {6},
  year      = {2007},
  pages     = {1741-1752},
}

@INPROCEEDINGS{Martin2008, 
author={Breithaupt, C. and Krawczyk, M. and Martin, R.}, 
booktitle=icassp, 
title={Parameterized {MMSE} spectral magnitude estimation for the enhancement of noisy speech}, 
year={2008}, 
month={March}, 
pages={4037-4040}, 
}

@ARTICLE{Srinivasan2007, 
author={Srinivasan, S. and Samuelsson, J. and Kleijn, W. B.}, 
journal={IEEE Trans. on Audio, Speech, and Language Processing}, 
title={Codebook-Based Bayesian Speech Enhancement for Nonstationary Environments}, 
year={2007}, 
month={Feb}, 
volume={15}, 
number={2}, 
pages={441-452}, 
}

@article{Rosenkranz2012767,
title = "Integrating recursive minimum tracking and codebook-based noise estimation for improved reduction of non-stationary noise ",
journal = "Signal Processing ",
volume = "92",
number = "3",
pages = "767 - 779",
year = "2012",
note = "",
issn = "0165-1684",
author = "Rosenkranz, T. and Puder, H.",
}

@ARTICLE{Breithaupt2007, 
author={Breithaupt, C. and Gerkmann, T. and Martin, R.}, 
journal={IEEE Signal Processing Letters}, 
title={Cepstral Smoothing of Spectral Filter Gains for Speech Enhancement Without Musical Noise}, 
year={2007}, 
month={Dec}, 
volume={14}, 
number={12}, 
pages={1036-1039}, 
keywords={Fourier transforms;cepstral analysis;smoothing methods;speech enhancement;Fourier spectrum;adaptive spectral filter gain;cepstral smoothing;musical noise;noisy signal;quasistationary narrowband structure;recursive temporal smoothing;short-term spectral magnitude;speech enhancement;Cepstral analysis;cepstral smoothing;musical noise;nonstationary noise;smoothing methods;speech enhancement}, 
doi={10.1109/LSP.2007.906208}, 
ISSN={1070-9908},}

  @BOOK{Loizou07,
    author =   {Loizou, P.},
    title =    {Speech Enhancement: Theory and Practice},
    year =     {2007},
    publisher =    {CRC Press},
    address =      {Boca Raton},
  }
  
  @ARTICLE{Rabiner1980, 
author={Rabiner, L. and Allen, J. B.}, 
journal={IEEE Trans. on Acoustics, Speech and Signal Processing}, 
title={On the implementation of a short-time spectral analysis method for system identification}, 
year={1980}, 
month={Feb}, 
volume={28}, 
number={1}, 
pages={69-78}, 
}

@ARTICLE{Stylianou2001, 
author={Stylianou, Y.}, 
journal={IEEE Trans. on Speech and Audio Processing}, 
title={Removing linear phase mismatches in concatenative speech synthesis}, 
year={2001}, 
month={Mar}, 
volume={9}, 
number={3}, 
pages={232-239}, 
}

@ARTICLE{DeLeon2012, 
author={De Leon, P. L. and Pucher, M. and Yamagishi, J. and Hernaez, I. and Saratxaga, I.}, 
journal={IEEE Trans. on Audio, Speech, and Language Processing}, 
title={Evaluation of Speaker Verification Security and Detection of HMM-Based Synthetic Speech}, 
year={2012}, 
month={Oct}, 
volume={20}, 
number={8}, 
pages={2280-2290}, 
keywords={Adaptation models;Hidden Markov models;Speech;Support vector machines;Synthesizers;Training;Vectors;Security;speaker recognition;speech synthesis}, 
doi={10.1109/TASL.2012.2201472}, 
ISSN={1558-7916},}

@ARTICLE{Cooke2010,
 title = {Monaural speech separation and recognition challenge},
 author = {Cooke, M. and Hershey, J. R. and Rennie, S. J.},
 journal = {Elsevier Computer Speech and Language},
 volume = {24},
 number = {1},
 year = {2010},
 issn = {0885-2308},
 pages = {1-15},
 }

@article{Hershey201045,
author = "John R. Hershey and Steven J. Rennie and Peder A. Olsen and Trausti T. Kristjansson",
title = "Super-human multi-talker speech recognition: A graphical modeling approach ",
journal = "Computer Speech \& Language ",
volume = "24",
number = "1",
pages = "45 - 66",
year = "2010",
}
 
@ARTICLE{Loizou2011, 
author={Loizou, P. C. and Gibak, K.}, 
journal={IEEE Trans. on Audio, Speech, and Language Processing}, 
title={Reasons why Current Speech-Enhancement Algorithms do not Improve Speech Intelligibility and Suggested Solutions}, 
year={2011}, 
month={Jan}, 
volume={19}, 
number={1}, 
pages={47-56}, 
}

@ARTICLE{IS2014a,
 author={Mowlaee, P. and Saeidi, R. and Stylianou, Y.},
 journal={in Proceedings of the 15th International Conference on Spoken Language Processing},
 title = {Phase Importance in Speech Processing Applications},
 month={},
 volume={},
 number={},
 pages={1623--1627},
 year={2014},
 }
 
 @ARTICLE{IS2014b,
 author={Chacon, C. and Mowlaee, P.},
 journal={in Proceedings of the 15th International Conference on Spoken Language Processing},
 title = {Least Squares Phase Estimation of Mixed Signals},
 month={},
 volume={},
 number={},
 pages={2705--2709},
 year={2014},
 }
 
 @ARTICLE{IWAENCa,
 author={Mowlaee, P. and Saeidi, R.},
 journal={The International Workshop on Acoustic Signal Enhancement (IWAENC)},
 title = {Time-Frequency Constraint for Phase Estimation in Single-Channel Speech Enhancement},
 month={},
 volume={},
 number={},
 pages={338--342},
 year={2014},
 }
 
@inproceedings{ICASSP2014_Timo,
 author={Gerkmann, T.},
 booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing },
 title = {{MMSE}-Optimal Enhancement of Complex Speech Coefficents With Uncertain Prior Knowledge of The Clean Speech Phase},
 month={},
 volume={},
 number={},
 pages={4511-4515},
 year={2014},
 }
 @INPROCEEDINGS{TimoIWAENC,
author={Krawczyk, M. and Gerkmann, T.},
booktitle={International Workshop on Acoustic Signal Enhancement; Proceedings of IWAENC},
title={{STFT} Phase Improvement for Single Channel Speech Enhancement},
year={2012},
pages={1-4},
}

@INPROCEEDINGS{Fingscheidt2012, 
author={Fodor, B. and Fingscheidt, T.}, 
booktitle={Acoustics, Speech and Signal Processing , 2012 IEEE International Conference on}, 
title={{MMSE} speech enhancement under speech presence uncertainty assuming (generalized) gamma speech priors throughout}, 
year={2012}, 
month={March}, 
pages={4033-4036}, 
}



@ARTICLE{Mohammadiha, 
author={Mohammadiha, N. and Smaragdis, P. and Leijon, A.}, 
journal={IEEE Trans. on Audio, Speech, and Language Processing,}, 
title={Supervised and Unsupervised Speech Enhancement Using Nonnegative Matrix Factorization}, 
year={2013}, 
month={Oct}, 
volume={21}, 
number={10}, 
pages={2140-2151}, 
}

@INPROCEEDINGS{wilson, 
author={Wilson, K. W. and Raj, B. and Smaragdis, P. and Divakaran, A.}, 
booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing}, 
title={Speech denoising using nonnegative matrix factorization with priors}, 
year={2008}, 
month={March}, 
pages={4029-4032}, 
}

 @ARTICLE{IS2014Gilles,
 author={Degottex, G. and Erro, D.},
 journal={in Proceedings of the 15th International Conference on Spoken Language Processing},
 title = {A Measure of Randomness for Harmonic Model in Speech Synthesis},
 month={},
 volume={},
 number={},
 pages={},
 year={2014},
 }
 
 @INPROCEEDINGS{IS2014GillesMaria,
    AUTHOR = {Koutsogiannaki, M. and Simantiraki, O. and Degottex, G. and Stylianou, Y.},
    TITLE = {The Importance of Phase on Voice Quality Assessment},
    BOOKTITLE = {Proc. Interspeech},
    MONTH = {Sept.},
    YEAR = {2014},
}
 
 @TechReport{ituPESQ,
    author = "ITU-T",
    title = "Perceptual evalaution of speech quality (PESQ)",
    institution = "International Telecommunication Union",
    type = "Recommendation",
    number = "P.862",
    year = "2001",
    }
	
@INPROCEEDINGS{Tribolet1978, 
author={Tribolet, J. M. and Noll, P. and McDermott, B. and Crochiere, R. E.}, 
booktitle={IEEE International Conference on Acoustics, Speech, and Signal Processing}, 
title={A study of complexity and quality of speech waveform coders}, 
year={1978}, 
month={Apr}, 
volume={3}, 
pages={586-590}, 
}
@INPROCEEDINGS{Patilicassp2014,
	author = "Patil, S. P. and Gowdy, J. N.", 
	title = "Exploiting the baseband phase structure of the voiced speech for speech enhancement",
	booktitle = "IEEE International Conference on Acoustics, Speech and Signal Processing",
	year = "2014",
	pages = "6133-6137",
}
@INPROCEEDINGS{Akihiko2013,
  author    = {Sugiyama, A. and Miyahara, R.},
  title     = {Phase randomization - A new paradigm for single-channel signal enhancement},
  booktitle = {IEEE International Conference on Acoustics, Speech and Signal Processing},
  year      = {2013},
  pages     = {7487-7491},
}

@article{JASAMehmetcik,
   author = "Mehmetcik, E. and Ciloglu, T.",
   title = "Speech enhancement by maintaining phase continuity between consecutive analysis frames",
   journal = "The Journal of the Acoustical Society of America",
   year = "2012",
   volume = "132",
   number = "3", 
   pages = "1972-1972",
}

@book{Hendriks2013,
  author    = {Hendriks, R. C. and Gerkmann, T. and Jensen, J.},
  title     = {DFT-Domain Based Single-Microphone Noise Reduction for Speech Enhancement},
  publisher = {Morgan {\&} Claypool Publishers},
  series    = {Synthesis Lectures on Speech and Audio Processing},
  year      = {2013},
}


@article{Vary1985387,
author = {Vary, P.},
journal = {Signal Processing},
title = {Noise suppression by spectral magnitude estimation mechanism and theoretical limits},
volume = {8},
number = {4},
pages = {387 - 400},
year = {1985},
}

@INPROCEEDINGS{IS2013,
	author = "Mowlaee, P. and Watanabe, M.", 
	title = "Iterative Sinusoidal-based Partial Phase Reconstruction in Single-Channel Source Separation",
	booktitle = {Proc. Interspeech},
	year = "2013",
	pages={832-836}, 	
}

@ARTICLE{Alsteris2007,
  author    = {Alsteris, L. D. and Paliwal, K. K.},
  title     = {Iterative reconstruction of speech from short-time {Fourier} transform phase and magnitude spectra},
  journal   = {Computer Speech {\&} Language},
  volume    = {21},
  number    = {1},
  year      = {2007},
  pages     = {174-186},
}

@ARTICLE{Griffin1984, 
author={Griffin, D. and Lim, J.}, 
journal={IEEE Trans. on Acoustics, Speech and Signal Processing}, 
title={Signal estimation from modified short-time {Fourier} transform}, 
year={1984}, 
month={Apr}, 
volume={32}, 
number={2}, 
pages={ 236 - 243}, 
}

@ARTICLE{LotterV05,
  author    = {Lotter, T. and Vary, P.},
  title     = {Speech Enhancement by MAP Spectral Amplitude Estimation
               Using a Super-Gaussian Speech Model},
  journal   = {EURASIP J. Adv. Sig. Proc.},
  volume    = {2005},
  number    = {7},
  year      = {2005},
  pages     = {1110-1126},
}

@ARTICLE{Leroux2013, 
    author = {Le Roux, J. and Vincent, E.},
    journal={IEEE signal processing letters},
    title = {{Consistent Wiener filtering for audio source separation}},
    year = {2013},
    volume={20}, 
    number={3}, 
    pages={ 217 - 220}, 
}
@INPROCEEDINGS{leroux2010,
    title = {{Consistent Wiener filtering: generalized time-frequency masking respecting spectrogram consistency}},
    author = {Le Roux, J. and Vincent, E. and Mizuno, Y. and Kameoka, H. and Ono, N. and Sagayama, S.},
    booktitle = {{9th Int. Conf. on Latent Variable Analysis and Signal Separation (LVA/ICA)}},
    pages = {89--96},
    year = {2010},
}

@ARTICLE{Smaragdis2013, 
author={Traa, J. and Smaragdis, P.}, 
journal={Signal Processing Letters, IEEE}, 
title={A Wrapped Kalman Filter for Azimuthal Speaker Tracking}, 
year={2013}, 
month={Dec}, 
volume={20}, 
number={12}, 
pages={1257-1260}, 
}

 @INPROCEEDINGS{EUSIPCO2013Gerkmann, 
author={Krawczyk, M. and Rehr, R. and Gerkmann, T.}, 
booktitle={Signal Processing Conference (EUSIPCO), 2013 Proceedings of the 21st European}, 
title={Phase-sensitive real-time capable speech enhancement under voiced-unvoiced uncertainty}, 
year={2013}, 
month={Sept}, 
pages={1-5}, 
}

@article{Taal2014,
author = {Taal, C. H. and Hendriks, R. C. and Heusdens, R.},
journal = {Computer Speech \& Language},
title ={speech energy redistribution for intelligibility improvement in noise baed on a perceptial distortion measre},
pages = {858-872},
volume = 28,
number = 4,
year = 2014,
}

@ARTICLE{QaziDMW12,
  author    = {Obaid, R. Q. and van Dijk, B. and Moonen, M. and Wouters, J.},
  journal   = {{IEEE} Trans. Biomed. Engineering},  
  title     = {Speech Understanding Performance of Cochlear Implant Subjects Using Time-Frequency Masking-Based Noise Reduction},
  year      = {2012},
  volume    = {59},
  number    = {5},
  pages     = {1364--1373},
}

@ARTICLE{gerkmann2012unbiased, 
author={Gerkmann, T. and Hendriks, R.C.}, 
journal={IEEE Transactions on Audio, Speech, and Language Processing}, 
title={Unbiased MMSE-Based Noise Power Estimation With Low Complexity and Low Tracking Delay}, 
year={2012}, 
month={May}, 
volume={20}, 
number={4}, 
pages={1383-1393}, 
}

@ARTICLE{erkelens2007minimum,
  author    = {Erkelens, J. S. and Hendriks, R. C. and Heusdens, R. and Jensen, J.},
  title     = {Minimum Mean-Square Error Estimation of Discrete Fourier Coefficients With Generalized {Gamma} Priors},
  journal   = {IEEE Trans. on Audio, Speech and Language Processing},
  month={Aug}, 
  volume    = {15},
  number    = {6},
  year      = {2007},
  pages     = {1741-1752},
}

@article{virtanenSPM,
  title={Compositional Models for Audio Processing: Uncovering the structure of sound mixtures},
  author={Virtanen, T. and Gemmeke, J.~F. and Raj, B. and Smaragdis, P.},
  journal={Signal Processing Magazine, IEEE},
  volume={32},
  number={2},
  pages={125--144},
  year={2015},
  publisher={IEEE}
}

@article{duchietal2010,
 author = {Duchi, John and Hazan, Elad and Singer, Yoram},
 title = {Adaptive Subgradient Methods for Online Learning and Stochastic Optimization},
 journal = {J. Mach. Learn. Res.},
 issue_date = {2/1/2011},
 volume = {12},
 month = jul,
 year = {2011},
 issn = {1532-4435},
 pages = {2121--2159},
 numpages = {39},
 url = {http://dl.acm.org/citation.cfm?id=1953048.2021068},
 acmid = {2021068},
 publisher = {JMLR.org},
} 

@inproceedings{glorotRelu2011, 
    Publisher = {Journal of Machine Learning Research - Workshop and Conference Proceedings}, 
    Title = {Deep Sparse Rectifier Neural Networks}, 
    Url = {http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf}, 
    Booktitle = {Proceedings of the Fourteenth International Conference on Artificial Intelligence and Statistics (AISTATS-11)}, 
    Author = {Xavier Glorot and Antoine Bordes and Yoshua Bengio}, 
    Volume = {15}, 
    Editor = {Geoffrey J. Gordon and David B. Dunson}, 
    Year = {2011}, 
    Pages = {315-323} 
   }
@article{healyetal2013,
    abstract = {{Despite considerable effort, monaural (single-microphone) algorithms capable of increasing the intelligibility of speech in noise have remained elusive. Successful development of such an algorithm is especially important for hearing-impaired (HI) listeners, given their particular difficulty in noisy backgrounds. In the current study, an algorithm based on binary masking was developed to separate speech from noise. Unlike the ideal binary mask, which requires prior knowledge of the premixed signals, the masks used to segregate speech from noise in the current study were estimated by training the algorithm on speech not used during testing. Sentences were mixed with speech-shaped noise and with babble at various signal-to-noise ratios (SNRs). Testing using normal-hearing and HI listeners indicated that intelligibility increased following processing in all conditions. These increases were larger for HI listeners, for the modulated background, and for the least-favorable SNRs. They were also often substantial, allowing several HI listeners to improve intelligibility from scores near zero to values above 70\%.}},
    author = {Healy, Eric W. and Yoho, Sarah E. and Wang, Yuxuan and Wang, DeLiang},
    citeulike-article-id = {12904029},
    citeulike-linkout-0 = {http://dx.doi.org/10.1121/1.4820893},
    citeulike-linkout-1 = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3799726/},
    citeulike-linkout-2 = {http://view.ncbi.nlm.nih.gov/pubmed/24116438},
    citeulike-linkout-3 = {http://www.hubmed.org/display.cgi?uids=24116438},
    day = {01},
    doi = {10.1121/1.4820893},
    issn = {0001-4966},
    journal = {The Journal of the Acoustical Society of America},
    keywords = {hearingimpaired, noisesuppression, separation, speech},
    month = oct,
    number = {4},
    pages = {3029--3038},
    pmcid = {PMC3799726},
    pmid = {24116438},
    posted-at = {2014-02-19 15:23:40},
    priority = {0},
    title = {{An algorithm to improve speech recognition in noise for hearing-impaired listeners}},
    url = {http://dx.doi.org/10.1121/1.4820893},
    volume = {134},
    year = {2013}
}
@article{hintonetal2012,
  added-at = {2012-10-10T00:00:00.000+0200},
  author = {Hinton, Geoffrey E. and Srivastava, Nitish and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  biburl = {http://www.bibsonomy.org/bibtex/2852239c1ed83a86f637f80bc641333b6/dblp},
  ee = {http://arxiv.org/abs/1207.0580},
  interhash = {3e6590885191244531ef7ce34bb388d0},
  intrahash = {852239c1ed83a86f637f80bc641333b6},
  journal = {CoRR},
  keywords = {dblp},
  timestamp = {2012-10-11T12:21:47.000+0200},
  title = {Improving neural networks by preventing co-adaptation of feature detectors},
  url = {http://dblp.uni-trier.de/db/journals/corr/corr1207.html#abs-1207-0580},
  volume = {abs/1207.0580},
  year = 2012
}
@article{kimetal2009,
   author = "Kim, Gibak and Lu, Yang and Hu, Yi and Loizou, Philipos C.",
   title = "An algorithm that improves speech intelligibility in noise for normal-hearing listeners",
   journal = "The Journal of the Acoustical Society of America",
   year = "2009",
   volume = "126",
   number = "3", 
   eid = ,
   pages = "1486-1494",
   url = "http://scitation.aip.org/content/asa/journal/jasa/126/3/10.1121/1.3184603",
   doi = "http://dx.doi.org/10.1121/1.3184603" 
}
@ARTICLE{IEEEcorpus, 
author={IEEE Audio and Electroacoustics Group},
journal={Audio and Electroacoustics, IEEE Transactions on}, 
title={IEEE Recommnded Pratice for Speech Quality Measurements}, 
year={1969}, 
volume={17}, 
number={3}, 
pages={225-246}, 
keywords={Aircraft;Current measurement;Educational institutions;Fasteners;Laboratories;Measurement standards;Speech analysis;Speech recognition;Standards publication;Telephony}, 
doi={10.1109/TAU.1969.1162058}, 
ISSN={0018-9278}, 
month={Sep},}
@incollection{Wang05onideal,
    abstract = {{In his famous treatise of computational vision, Marr (1982) makes a compelling argument for separating different levels of analysis in order to understand complex information processing. In particular, the computational theory level, concerned with the goal of computation and general processing strategy, must be separated from the algorithm level, or the separation of what from how. This chapter is an attempt at a computational-theory analysis of auditory scene analysis, where the main task is to understand the character of the CASA problem.
                        My analysis results in the proposal of the ideal binary mask as a main goal of CASA. This goal is consistent with characteristics of human auditory scene analysis. The goal is also consistent with more specific objectives such as enhancing ASR and speech intelligibility. The resulting evaluation metric has the properties of simplicity and generality, and is easy to apply when the premixing target is available. The goal of the ideal binary mask has led to effective for speech separation algorithms that attempt to explicitly estimate such masks.}},
    address = {Boston},
    author = {Wang, DeLiang},
    booktitle = {Speech Separation by Humans and Machines},
    chapter = {12},
    citeulike-article-id = {4284733},
    citeulike-linkout-0 = {http://dx.doi.org/10.1007/0-387-22794-6\_12},
    citeulike-linkout-1 = {http://www.springerlink.com/content/p41103403v35338k},
    citeulike-linkout-2 = {http://link.springer.com/chapter/10.1007/0-387-22794-6\_12},
    doi = {10.1007/0-387-22794-6\_12},
    editor = {Divenyi, Pierre},
    isbn = {1-4020-8001-8},
    journal = {Speech Separation by Humans and Machines},
    keywords = {idealbinarymask, separation},
    pages = {181--197},
    posted-at = {2012-12-10 21:55:51},
    priority = {0},
    publisher = {Springer US},
    title = {{On Ideal Binary Mask As the Computational Goal of Auditory Scene Analysis}},
    url = {http://dx.doi.org/10.1007/0-387-22794-6\_12},
    year = {2005}
}
@article{yuxuwangDNNFeat2013,
  added-at = {2013-01-17T00:00:00.000+0100},
  author = {Wang, Yuxuan and Han, Kun and Wang, DeLiang},
  biburl = {http://www.bibsonomy.org/bibtex/220dd3e6e11932967beae1e16ee7e6bfc/dblp},
  ee = {http://dx.doi.org/10.1109/TASL.2012.2221459},
  interhash = {e1c5762058adc8b121bde8cdcf07817b},
  intrahash = {20dd3e6e11932967beae1e16ee7e6bfc},
  journal = {IEEE Transactions on Audio, Speech \& Language Processing},
  keywords = {dblp},
  number = 2,
  pages = {270-279},
  timestamp = {2013-01-18T11:36:01.000+0100},
  title = {Exploring Monaural Features for Classification-Based Speech Segregation.},
  url = {http://dblp.uni-trier.de/db/journals/taslp/taslp21.html#WangHW13},
  volume = 21,
  year = 2013
}
@ARTICLE{wangetal2014, 
author={Yuxuan Wang and Narayanan, A. and Deliang Wang}, 
journal={Audio, Speech, and Language Processing, IEEE/ACM Transactions on}, 
title={On Training Targets for Supervised Speech Separation}, 
year={2014}, 
volume={22}, 
number={12}, 
pages={1849-1858}, 
keywords={Fourier transforms;learning (artificial intelligence);matrix decomposition;neural nets;source separation;speech coding;speech intelligibility;time-frequency analysis;FFT-mask;Fourier transform spectral magnitude;Gammatone frequency power spectrum;IBM;IRM;ideal binary mask;ideal ratio mask;masking based targets;neural network;nonnegative matrix factorization;spectral envelope based targets;speech enhancement;speech intelligibility gains;supervised learning algorithm;supervised learning problem;supervised speech separation;target binary mask;time-frequency representation;Noise measurement;Signal to noise ratio;Speech;Speech processing;Supervised learning;Training;Deep neural networks;speech separation;supervised learning;training targets}, 
doi={10.1109/TASLP.2014.2352935}, 
ISSN={2329-9290}, 
month={Dec},}
@inproceedings{zhangandwang2014,
  author    = {Xiao{-}Lei Zhang and
               DeLiang Wang},
  title     = {Boosted deep neural networks and multi-resolution cochleagram features
               for voice activity detection},
  booktitle = {{INTERSPEECH} 2014, 15th Annual Conference of the International Speech
               Communication Association, Singapore, September 14-18, 2014},
  pages     = {1534--1538},
  year      = {2014},
  url       = {http://www.isca-speech.org/archive/interspeech_2014/i14_1534.html},
  timestamp = {Wed, 18 Feb 2015 08:38:47 +0100},
  biburl    = {http://dblp.uni-trier.de/rec/bib/conf/interspeech/ZhangW14},
  bibsource = {dblp computer science bibliography, http://dblp.org}
}

@inproceedings{sturmel2012,
TITLE = {{Phase-based informed source separation for active listening of music}},
AUTHOR = {Sturmel, Nicolas and Daudet, Laurent and Girin, Laurent},
URL = {https://hal.archives-ouvertes.fr/hal-00807001},
BOOKTITLE = {{15th International Conference on Digital Audio Effects (DAFx 2012)}},
ADDRESS = {York, United Kingdom},
PAGES = {n/c},
YEAR = {2012},
MONTH = Sep,
KEYWORDS = {Informed Source Separation ; phase coding},
PDF = {https://hal.archives-ouvertes.fr/hal-00807001/file/dafx12_NS_LD_LG_submitted.pdf},
HAL_ID = {hal-00807001},
HAL_VERSION = {v1},
}